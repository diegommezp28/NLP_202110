{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Punto 1\n",
    "## Automatic identification of “trending/viral” topics around COVID in time in the World using deep learning architectures. Type: Different approaches."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from stop_words import get_stop_words\n",
    "import umap.umap_ as umap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Files used\n",
    "The datasets and the embedings generated with a pretrained Sentence Bert model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#prefix = './drive/MyDrive/'\n",
    "prefix = ''\n",
    "spanish_path = prefix + 'datasets/spanish/spanish_out_hash_bien.json'\n",
    "italian_path = prefix + 'datasets/italian/italian_out_hash_bien.json'\n",
    "english_path = prefix + 'datasets/english/english_out_hash_bien.json'\n",
    "\n",
    "#prefix = './drive/MyDrive/'\n",
    "prefix = ''\n",
    "italian_embeddings_path = prefix + 'models_hpc/embeddings_ita_hash.pickle'\n",
    "spanish_embeddings_path = prefix + 'models_hpc/embeddings_es_hash.pickle'\n",
    "english_embeddings_path = prefix + 'models_hpc/embeddings_en_hash.pickle'\n",
    "\n",
    "#prefix = './drive/MyDrive/'\n",
    "prefix = ''\n",
    "umap_italian_embeddings_path = prefix + 'models_hpc/umap_ita_hash.pickle'\n",
    "umap_spanish_embeddings_path = prefix + 'models_hpc/umap_es_hash.pickle'\n",
    "umap_english_embeddings_path = prefix + 'models_hpc/umap_en_hash.pickle'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n------------------------ENGLISH---------------------------\\n\\n------------------------ENGLISH---------------------------\\n\\n------------------------ENGLISH---------------------------\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "------------------------ENGLISH---------------------------\n",
    "\n",
    "------------------------ENGLISH---------------------------\n",
    "\n",
    "------------------------ENGLISH---------------------------\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## English"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784932, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    id  publication_date   source  \\\n0  1295929115770593287      1.597809e+09  twitter   \n1  1296738518216011777      1.598002e+09  twitter   \n2  1252450676015198210      1.587442e+09  twitter   \n3  1380684968880406528      1.618016e+09  twitter   \n4  1368958702150156290      1.615220e+09  twitter   \n5  1317169175203401735      1.602873e+09  twitter   \n6  1288154256449708032      1.595955e+09  twitter   \n7  1283867253222502400      1.594933e+09  twitter   \n8  1286909343909240832      1.595658e+09  twitter   \n9  1235895985009811461      1.583496e+09  twitter   \n\n                                                text  \n0                                      Info Source:   \n1  #PostponeJEE_NEETSept #ProtestAgainstExamsInCO...  \n2  Coronavirus-spreader Chris Cuomo got a lecture...  \n3  Any military member that refuses to get vaccin...  \n4  #Covid19 is staying around for a while.  your ...  \n5                                 LIES!!!   LIES!!!   \n6  @GregMannarino Deborah BirxWhite House \"Expert\"    \n7  Kayleigh McEnany: ‘Science Should Not Stand in...  \n8  Amazing effort from the guys! Please donate if...  \n9  @SulaiOdus They said it was suspended due to c...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>publication_date</th>\n      <th>source</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1295929115770593287</td>\n      <td>1.597809e+09</td>\n      <td>twitter</td>\n      <td>Info Source:</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1296738518216011777</td>\n      <td>1.598002e+09</td>\n      <td>twitter</td>\n      <td>#PostponeJEE_NEETSept #ProtestAgainstExamsInCO...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1252450676015198210</td>\n      <td>1.587442e+09</td>\n      <td>twitter</td>\n      <td>Coronavirus-spreader Chris Cuomo got a lecture...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1380684968880406528</td>\n      <td>1.618016e+09</td>\n      <td>twitter</td>\n      <td>Any military member that refuses to get vaccin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1368958702150156290</td>\n      <td>1.615220e+09</td>\n      <td>twitter</td>\n      <td>#Covid19 is staying around for a while.  your ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1317169175203401735</td>\n      <td>1.602873e+09</td>\n      <td>twitter</td>\n      <td>LIES!!!   LIES!!!</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1288154256449708032</td>\n      <td>1.595955e+09</td>\n      <td>twitter</td>\n      <td>@GregMannarino Deborah BirxWhite House \"Expert\"</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1283867253222502400</td>\n      <td>1.594933e+09</td>\n      <td>twitter</td>\n      <td>Kayleigh McEnany: ‘Science Should Not Stand in...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1286909343909240832</td>\n      <td>1.595658e+09</td>\n      <td>twitter</td>\n      <td>Amazing effort from the guys! Please donate if...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1235895985009811461</td>\n      <td>1.583496e+09</td>\n      <td>twitter</td>\n      <td>@SulaiOdus They said it was suspended due to c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(english_path, 'r')\n",
    "data = []\n",
    "for line in file:\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "text_raw_df = pd.json_normalize(data)\n",
    "\n",
    "print(text_raw_df.shape)\n",
    "text_raw_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'Info Source: '"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Turn text to Numpy Array\n",
    "'''\n",
    "texts_column = text_raw_df.loc[:,'text']\n",
    "raw_texts = texts_column.values\n",
    "raw_texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "with open(english_embeddings_path, \"rb\") as output_file:\n",
    "    embeddings = pk.load(output_file)\n",
    "\n",
    "with open(umap_english_embeddings_path, \"rb\") as output_file:\n",
    "    umap_embeddings = pk.load(output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HDBSCAN para el clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=60,\n",
    "                          metric='euclidean',\n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisación de los clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-a33d32d8cc6e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Prepare data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mumap_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mumap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUMAP\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_neighbors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_components\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin_dist\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'cosine'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mumap_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'x'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'y'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'labels'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcluster\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/umap/umap_.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m   2632\u001B[0m             \u001B[0mLocal\u001B[0m \u001B[0mradii\u001B[0m \u001B[0mof\u001B[0m \u001B[0mdata\u001B[0m \u001B[0mpoints\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthe\u001B[0m \u001B[0membedding\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mtransformed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2633\u001B[0m         \"\"\"\n\u001B[0;32m-> 2634\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2635\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform_mode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"embedding\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2636\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput_dens\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/umap/umap_.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m   2551\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2552\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform_mode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"embedding\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2553\u001B[0;31m             self.embedding_, aux_data = self._fit_embed_data(\n\u001B[0m\u001B[1;32m   2554\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_raw_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# JH why raw data?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2555\u001B[0m             )\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/umap/umap_.py\u001B[0m in \u001B[0;36m_fit_embed_data\u001B[0;34m(self, X, n_epochs, init, random_state)\u001B[0m\n\u001B[1;32m   2578\u001B[0m         \u001B[0mreplaced\u001B[0m \u001B[0mby\u001B[0m \u001B[0msubclasses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2579\u001B[0m         \"\"\"\n\u001B[0;32m-> 2580\u001B[0;31m         return simplicial_set_embedding(\n\u001B[0m\u001B[1;32m   2581\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2582\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgraph_\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/umap/umap_.py\u001B[0m in \u001B[0;36msimplicial_set_embedding\u001B[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose)\u001B[0m\n\u001B[1;32m   1052\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0minit\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"spectral\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0;31m# We add a little noise to avoid local minima for optimization to come\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1054\u001B[0;31m         initialisation = spectral_layout(\n\u001B[0m\u001B[1;32m   1055\u001B[0m             \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1056\u001B[0m             \u001B[0mgraph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/umap/spectral.py\u001B[0m in \u001B[0;36mspectral_layout\u001B[0;34m(data, graph, dim, random_state, metric, metric_kwds)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_components\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m         return multi_component_layout(\n\u001B[0m\u001B[1;32m    302\u001B[0m             \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m             \u001B[0mgraph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/umap/spectral.py\u001B[0m in \u001B[0;36mmulti_component_layout\u001B[0;34m(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds)\u001B[0m\n\u001B[1;32m    236\u001B[0m         \u001B[0mnum_lanczos_vectors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mk\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcomponent_graph\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 238\u001B[0;31m             eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n\u001B[0m\u001B[1;32m    239\u001B[0m                 \u001B[0mL\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    240\u001B[0m                 \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001B[0m in \u001B[0;36meigsh\u001B[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001B[0m\n\u001B[1;32m   1688\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0m_ARPACK_LOCK\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1689\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverged\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1690\u001B[0;31m             \u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miterate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1691\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1692\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextract\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreturn_eigenvectors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001B[0m in \u001B[0;36miterate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    546\u001B[0m             \u001B[0;31m# compute y = Op*x\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    547\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 548\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkd\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0myslice\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOP\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkd\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mxslice\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    549\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    550\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkd\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mxslice\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOPb\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkd\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mxslice\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/linalg/interface.py\u001B[0m in \u001B[0;36mmatvec\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    230\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'dimension mismatch'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 232\u001B[0;31m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_matvec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    233\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatrix\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/linalg/interface.py\u001B[0m in \u001B[0;36m_matvec\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    197\u001B[0m         \u001B[0mwill\u001B[0m \u001B[0mdefine\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mvector\u001B[0m \u001B[0mmultiplication\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mwell\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m         \"\"\"\n\u001B[0;32m--> 199\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    200\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmatvec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/linalg/interface.py\u001B[0m in \u001B[0;36mmatmat\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    335\u001B[0m                              % (self.shape, X.shape))\n\u001B[1;32m    336\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 337\u001B[0;31m         \u001B[0mY\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_matmat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    338\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    339\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatrix\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/linalg/interface.py\u001B[0m in \u001B[0;36m_matmat\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    729\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    730\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_matmat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 731\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mA\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    732\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    733\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_adjoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/base.py\u001B[0m in \u001B[0;36mdot\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    357\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m         \"\"\"\n\u001B[0;32m--> 359\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    360\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    361\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/base.py\u001B[0m in \u001B[0;36m__mul__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    467\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mul_vector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    468\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 469\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mul_vector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    470\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mN\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    471\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mul_multivector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001B[0m in \u001B[0;36m_mul_vector\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    476\u001B[0m         \u001B[0;31m# csr_matvec or csc_matvec\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    477\u001B[0m         \u001B[0mfn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_sparsetools\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'_matvec'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 478\u001B[0;31m         \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindptr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    479\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    480\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "umap_data = umap.UMAP(n_neighbors=30, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c-TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(raw_texts, columns=[\"Doc\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelasarmiento/pythonProject/venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=get_stop_words('english')).fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "\n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(raw_texts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "    Topic    Size\n14     13  760927\n11     10   12321\n16     15    6655\n0      -1    2341\n15     14    1203\n9       8     303\n4       3     205\n3       2     164\n5       4     147\n1       0     110",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>760927</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>12321</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>6655</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>2341</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>1203</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>303</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covid', 'coronavirus', '19', 'covid19', 'new', 'cases', 'people', 'will', 'trump', 'can']\n",
      "\n",
      "['china', 'chinese', 'coronavirus', 'wuhan', 'virus', 'covid', 'outbreak', '19', 'world', 'beijing']\n",
      "\n",
      "['canada', 'ontario', 'canadian', '19', 'covid', 'canadians', 'toronto', 'cbc', 'alberta', 'trudeau']\n",
      "\n",
      "['ontario', 'cases', 'canada', 'new', 'deaths', '19', 'covid', 'reports', 'alberta', '000']\n",
      "\n",
      "['empower', '090', 'entertain', '0208', '2121', 'educate', 'hello', 'air', 'talk', 'fantasticradio']\n",
      "\n",
      "['appointments', '00', 'cvs', 'near', 'pa', '04', 'sign', 'available', 'vaccination', '2021']\n",
      "\n",
      "['spain', 'strict', 'worn', 'outdoors', 'masks', 'lockdown', 'must', 'inside', 'spanish', 'extremely']\n",
      "\n",
      "['dictates', 'boris', 'interact', 'normal', 'many', 'johnson', 'peacefully', 'can', 'new', 'dictate']\n",
      "\n",
      "['viruscases', 'projections', 'recovered', 'united', 'closed', 'corona', 'states', 'cases4', 'cases6', 'cases1']\n",
      "\n",
      "['fantasticradio', '2121', '0208', 'adding', 'value', 'hello', '90', 'air', 'talk', 'co']\n",
      "\n",
      "['visualizations', 'county', 'insight', '1k', 'provide', 'covid', '20', 'accurate', 'population', 'confirmed']\n",
      "\n",
      "['cvs', 'danville', '24540', 'emporia', '23847', 'alexandria', 'portsmouth', 'roanoke', 'abingdon', 'hampton']\n",
      "\n",
      "['african', 'nonstop', 'affairs', 'radio', 'tune', 'now', 'playing', 'music', 'live', 'chaka']\n",
      "\n",
      "['utc', 'update', 'health', '05', '09', '11', 'coronavirus', '06', '45', '08']\n",
      "\n",
      "['project', 'materialsget', 'chapter', 'topics', 'complete', 'fridaythoughts', 'sundaythoughts', 'mondaythoughts', 'saturdaythoughts', 'thursdaythoughts']\n",
      "\n",
      "['white', 'people', 'privilege', 'man', 'men', 'supremacy', 'hat', 'whiterose', 'hahaahhaaha', 'steez']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in topic_sizes['Topic']:\n",
    "  if topic == -1:\n",
    "    continue\n",
    "  print(str([t[0] for t in top_n_words[topic][:10]]) + '\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------SPANISH---------------------------\n",
    "\n",
    "------------------------SPANISH---------------------------\n",
    "\n",
    "------------------------SPANISH---------------------------\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SPANISH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(845125, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    id  publication_date   source  \\\n0  1304391319972790274      1.599826e+09  twitter   \n1  1308823479077175297      1.600883e+09  twitter   \n2  1255929719893221377      1.588272e+09  twitter   \n3  1367024221319286784      1.614759e+09  twitter   \n4  1278689023087849480      1.593698e+09  twitter   \n5  1374234992969015297      1.616478e+09  twitter   \n6  1296604758732570625      1.597970e+09  twitter   \n7  1344926278592438272      1.609490e+09  twitter   \n8  1311046706809786372      1.601413e+09  twitter   \n9  1257004539875667971      1.588528e+09  twitter   \n\n                                                text  \n0  ORACIÓN DIARIAViernes 11 de Septiembre 2020#or...  \n1  Se pudrió todo. Acá la FIFA debe castigar a la...  \n2   Última  Publicación  en la Prensaldia -   @ca...  \n3  Australia = 0 positivos por coronavirus.¿Vacun...  \n4                   coronavirus esto ya es personal   \n5        #LadyZopilota, zopiloteando en la noticia.   \n6  La noticia que esperaban los mercados. Gracias...  \n7  No caigamos en la trampa.En México ya iniciaro...  \n8  El coronavirus se ha confirmado ya en más de 2...  \n9  @JaimeChincha @RPPNoticias Mi padre acaba de m...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>publication_date</th>\n      <th>source</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1304391319972790274</td>\n      <td>1.599826e+09</td>\n      <td>twitter</td>\n      <td>ORACIÓN DIARIAViernes 11 de Septiembre 2020#or...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1308823479077175297</td>\n      <td>1.600883e+09</td>\n      <td>twitter</td>\n      <td>Se pudrió todo. Acá la FIFA debe castigar a la...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1255929719893221377</td>\n      <td>1.588272e+09</td>\n      <td>twitter</td>\n      <td>Última  Publicación  en la Prensaldia -   @ca...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1367024221319286784</td>\n      <td>1.614759e+09</td>\n      <td>twitter</td>\n      <td>Australia = 0 positivos por coronavirus.¿Vacun...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1278689023087849480</td>\n      <td>1.593698e+09</td>\n      <td>twitter</td>\n      <td>coronavirus esto ya es personal</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1374234992969015297</td>\n      <td>1.616478e+09</td>\n      <td>twitter</td>\n      <td>#LadyZopilota, zopiloteando en la noticia.</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1296604758732570625</td>\n      <td>1.597970e+09</td>\n      <td>twitter</td>\n      <td>La noticia que esperaban los mercados. Gracias...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1344926278592438272</td>\n      <td>1.609490e+09</td>\n      <td>twitter</td>\n      <td>No caigamos en la trampa.En México ya iniciaro...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1311046706809786372</td>\n      <td>1.601413e+09</td>\n      <td>twitter</td>\n      <td>El coronavirus se ha confirmado ya en más de 2...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1257004539875667971</td>\n      <td>1.588528e+09</td>\n      <td>twitter</td>\n      <td>@JaimeChincha @RPPNoticias Mi padre acaba de m...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(spanish_path, 'r')\n",
    "data = []\n",
    "for line in file:\n",
    "    data.append(json.loads(line))\n",
    "text_raw_df = pd.json_normalize(data)\n",
    "\n",
    "print(text_raw_df.shape)\n",
    "text_raw_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'ORACIÓN DIARIAViernes 11 de Septiembre 2020#oraciondiaria #11DeSeptiembre #BuenosDias #BuenosDiasATodos… '"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Turn text to Numpy Array\n",
    "'''\n",
    "texts_column = text_raw_df.loc[:,'text']\n",
    "raw_texts = texts_column.values\n",
    "raw_texts[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open(spanish_embeddings_path, \"rb\") as output_file:\n",
    "    embeddings = pk.load(output_file)\n",
    "\n",
    "with open(umap_spanish_embeddings_path, \"rb\") as output_file:\n",
    "    umap_embeddings = pk.load(output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HDBSCAN para el clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=60,\n",
    "                          metric='euclidean',\n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisación de los clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "umap_data = umap.UMAP(n_neighbors=30, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c-TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (784932) does not match length of index (845125)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-3a9b0305b7bd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mdocs_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_texts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Doc\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdocs_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Topic'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcluster\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mdocs_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Doc_ID'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocs_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mdocs_per_topic\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdocs_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupby\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Topic'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0magg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'Doc'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m' '\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   3161\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3162\u001B[0m             \u001B[0;31m# set column\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3163\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_item\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3164\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3165\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_setitem_slice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mslice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_set_item\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   3237\u001B[0m         \"\"\"\n\u001B[1;32m   3238\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ensure_valid_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3239\u001B[0;31m         \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sanitize_column\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3240\u001B[0m         \u001B[0mNDFrame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_item\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3241\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_sanitize_column\u001B[0;34m(self, key, value, broadcast)\u001B[0m\n\u001B[1;32m   3894\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3895\u001B[0m             \u001B[0;31m# turn me into an ndarray\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3896\u001B[0;31m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msanitize_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3897\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3898\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonProject/venv/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001B[0m in \u001B[0;36msanitize_index\u001B[0;34m(data, index)\u001B[0m\n\u001B[1;32m    749\u001B[0m     \"\"\"\n\u001B[1;32m    750\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 751\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    752\u001B[0m             \u001B[0;34m\"Length of values \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    753\u001B[0m             \u001B[0;34mf\"({len(data)}) \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Length of values (784932) does not match length of index (845125)"
     ]
    }
   ],
   "source": [
    "docs_df = pd.DataFrame(raw_texts, columns=[\"Doc\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=get_stop_words('spanish')).fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "\n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(raw_texts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for topic in topic_sizes['Topic']:\n",
    "  if topic == -1:\n",
    "    continue\n",
    "  print(str([t[0] for t in top_n_words[topic][:10]]) + '\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------ITALIAN---------------------------\n",
    "\n",
    "------------------------ITALIAN---------------------------\n",
    "\n",
    "------------------------ITALIAN---------------------------\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ITALIAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(814485, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    id  publication_date   source  \\\n0  1324811856859533313      1.604695e+09  twitter   \n1  1288746494368124928      1.596096e+09  twitter   \n2  1326191597785059329      1.605024e+09  twitter   \n3  1275134048722132993      1.592851e+09  twitter   \n4  1243118079091118080      1.585217e+09  twitter   \n5  1267645840455278594      1.591065e+09  twitter   \n6  1233340720460726272      1.582886e+09  twitter   \n7  1279712208612667393      1.593942e+09  twitter   \n8  1271709738301095936      1.592034e+09  twitter   \n9  1296853994686513152      1.598029e+09  twitter   \n\n                                                text  \n0  Il prof. #Galli è molto preoccupato da quanto ...  \n1  Il COVID-19 coincide con un momento cruciale n...  \n2  Muoviamoci #vaccinoCovid #coronavirus #COVID19...  \n3  @mosllerdd @Cartabellotta Si sarebbero potute ...  \n4  @morzo6 @CNN Purtroppo sì. State a casa. Disin...  \n5  @orticArya * \"il coronavirus non c'è più, ma c...  \n6  Coronavirus, l’ultima trovata: mascherine grif...  \n7  \"Penne in quarantena\". Tredici #racconti di al...  \n8  Cina, torna l’incubo Coronavirus: alcuni quart...  \n9                                 Questo è il punto   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>publication_date</th>\n      <th>source</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1324811856859533313</td>\n      <td>1.604695e+09</td>\n      <td>twitter</td>\n      <td>Il prof. #Galli è molto preoccupato da quanto ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1288746494368124928</td>\n      <td>1.596096e+09</td>\n      <td>twitter</td>\n      <td>Il COVID-19 coincide con un momento cruciale n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1326191597785059329</td>\n      <td>1.605024e+09</td>\n      <td>twitter</td>\n      <td>Muoviamoci #vaccinoCovid #coronavirus #COVID19...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1275134048722132993</td>\n      <td>1.592851e+09</td>\n      <td>twitter</td>\n      <td>@mosllerdd @Cartabellotta Si sarebbero potute ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1243118079091118080</td>\n      <td>1.585217e+09</td>\n      <td>twitter</td>\n      <td>@morzo6 @CNN Purtroppo sì. State a casa. Disin...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1267645840455278594</td>\n      <td>1.591065e+09</td>\n      <td>twitter</td>\n      <td>@orticArya * \"il coronavirus non c'è più, ma c...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1233340720460726272</td>\n      <td>1.582886e+09</td>\n      <td>twitter</td>\n      <td>Coronavirus, l’ultima trovata: mascherine grif...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1279712208612667393</td>\n      <td>1.593942e+09</td>\n      <td>twitter</td>\n      <td>\"Penne in quarantena\". Tredici #racconti di al...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1271709738301095936</td>\n      <td>1.592034e+09</td>\n      <td>twitter</td>\n      <td>Cina, torna l’incubo Coronavirus: alcuni quart...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1296853994686513152</td>\n      <td>1.598029e+09</td>\n      <td>twitter</td>\n      <td>Questo è il punto</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(italian_path, 'r')\n",
    "data = []\n",
    "for line in file:\n",
    "    data.append(json.loads(line))\n",
    "text_raw_df = pd.json_normalize(data)\n",
    "\n",
    "print(text_raw_df.shape)\n",
    "text_raw_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Turn text to Numpy Array\n",
    "'''\n",
    "texts_column = text_raw_df.loc[:,'text']\n",
    "raw_texts = texts_column.values\n",
    "raw_texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open(english_embeddings_path, \"rb\") as output_file:\n",
    "    embeddings = pk.load(output_file)\n",
    "\n",
    "with open(umap_english_embeddings_path, \"rb\") as output_file:\n",
    "    umap_embeddings = pk.load(output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HDBSCAN para el clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=60,\n",
    "                          metric='euclidean',\n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisación de los clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "umap_data = umap.UMAP(n_neighbors=30, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c-TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(raw_texts, columns=[\"Doc\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=get_stop_words('italian')).fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "\n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(raw_texts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for topic in topic_sizes['Topic']:\n",
    "  if topic == -1:\n",
    "    continue\n",
    "  print(str([t[0] for t in top_n_words[topic][:10]]) + '\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}