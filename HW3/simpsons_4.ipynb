{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "name": "python3710jvsc74a57bd06c70104609522f67cb30e8200dfa6f77a5bec0e1b1538a23f62dccdf26f51f37",
      "display_name": "Python 3.7.10 64-bit ('TF-Keras': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "metadata": {
      "interpreter": {
        "hash": "055d6687a903af6a4d9b4e34cc4a28379165765e2776fc398dbe998782ca591f"
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "simpsons2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3pck_-pEY9Qz",
        "XS1UQJv4Y9Q2",
        "xxtU_jHiY9Q8",
        "kdJBVCtkY9Q9",
        "8MZ57yzLY9Q9",
        "rkyC8G67Y9Q_",
        "EuAQVFVxY9RA",
        "Q8DzHZIpY9RB",
        "LcS99qvDY9RD",
        "UGGXs-6qY9RE"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TSG6Guf8Y9RE"
      },
      "source": [
        "# 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tWyVNYDjY9RE"
      },
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\diego\\anaconda3\\envs\\TF-Keras\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lqjG9DKXY9RF"
      },
      "source": [
        "Readind the raw data and enconding the main characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "ruta = './docs/'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NNKY6n1SY9RF",
        "outputId": "0309fd82-af1e-4b4e-9d34-0750e12a624a"
      },
      "source": [
        "'''\n",
        "Aquí se filtra el dataset para que solo queden los dialogos relevantes, los de ls personajes principales.\n",
        "'''\n",
        "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "df_0 = pd.read_csv(ruta+'simpsons_dataset.csv').dropna()\n",
        "target_simpsons = [\n",
        "    'Lisa Simpson',\n",
        "    'Bart Simpson',\n",
        "    'Homer Simpson',\n",
        "    'Marge Simpson',\n",
        "    'Maggie Simpson',\n",
        "    'Grampa Simpson'\n",
        "]\n",
        "df = df_0.loc[df_0['raw_character_text'].isin(target_simpsons)]\n",
        "\n",
        "\n",
        "'''\n",
        "Se realiza un Encoding de los nombres de los personajes principales.\n",
        "La idea es que cada categoría de personaje este codificada por un vector\n",
        "1x6 binario.\n",
        "'''\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(df[['raw_character_text']])\n",
        "print(enc.categories_)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array(['Bart Simpson', 'Grampa Simpson', 'Homer Simpson', 'Lisa Simpson',\n       'Maggie Simpson', 'Marge Simpson'], dtype=object)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-kxqXUI_Y9RF"
      },
      "source": [
        "Dataset Spliting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RtYlcE1oY9RF"
      },
      "source": [
        "'''\n",
        "Se dividen los datos en 60 training, 20 validación y 20 testing\n",
        "'''\n",
        "# df_yelp = df[df['source'] == 'yelp']\n",
        "sentences = df['spoken_words'].values\n",
        "y = enc.transform(df[['raw_character_text']]).toarray()\n",
        "sentences_train_val, sentences_test, y_train_val, y_test = train_test_split(sentences, y, test_size=0.20, random_state=1000)\n",
        "sentences_train, sentences_val, y_train, y_val = train_test_split(sentences_train_val, y_train_val, test_size=0.25, random_state=1000)\n",
        "\n",
        "# format: a tuple of the form (text_data, label).\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((sentences_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((sentences_test, y_test))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((sentences_val, y_val))\n",
        "\n",
        "# We also create a dataset with only the textual data in it. This will be used to build our vocabulary later on.\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices((sentences_train))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Gf8Er9Y6Y9RF"
      },
      "source": [
        "Building the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "H2cAaMHsY9RG",
        "outputId": "1d111f25-0500-40cb-ad13-63744e4d590e"
      },
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    ngrams=None, max_tokens=None, vocabulary=None,\n",
        "    output_mode='binary', output_sequence_length=None, pad_to_max_tokens=True,\n",
        ")\n",
        "\n",
        "vectorize_layer.adapt(text_dataset.batch(32))\n",
        "print(len(vectorize_layer.get_vocabulary()))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "x_train = vectorize_layer(np.array([[s] for s in sentences_train])).numpy()\n",
        "x_val = vectorize_layer(np.array([[s] for s in sentences_val])).numpy()\n",
        "x_test = vectorize_layer(np.array([[s] for s in sentences_test])).numpy()\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pGGI8BrUY9RG"
      },
      "source": [
        "Define model genereting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MfRoZjoyY9RG"
      },
      "source": [
        "def generateInplaceEmbbedingModel(embedding_dim, vectorize_layer, output_length = len(target_simpsons), architecture_id = 1):\n",
        "    batch_size = 32\n",
        "    # epochs = 10\n",
        "    num_tokens = len(vectorize_layer.get_vocabulary())\n",
        "    embedding_layer = layers.Embedding(\n",
        "        num_tokens,\n",
        "        embedding_dim,\n",
        "        name=\"embedding_Trainable\"\n",
        "    )\n",
        "    model = Sequential()\n",
        "    model.add(vectorize_layer)\n",
        "    model.add(embedding_layer)\n",
        "    model.add(layers.GlobalAveragePooling1D())\n",
        "\n",
        "    if architecture_id == 1:\n",
        "        model.add(layers.Dense(10, activation='relu'))\n",
        "    elif architecture_id == 2:\n",
        "        model.add(layers.Dense(80, activation='relu'))\n",
        "        model.add(layers.Dense(250, activation='relu'))\n",
        "    elif architecture_id == 3:\n",
        "        model.add(layers.Dense(80, activation='relu'))\n",
        "        model.add(layers.Dropout(0.3))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dense(250, activation='relu'))\n",
        "        model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(output_length, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "liEVSljgY9RG"
      },
      "source": [
        "Definition of vectorization layer generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3JStV7qGY9RG"
      },
      "source": [
        "def getVectorizeLayer(output_mode, text_dataset):\n",
        "    batch_size = 32\n",
        "    vectorize_layer = TextVectorization(\n",
        "        ngrams=None,\n",
        "        max_tokens=None, vocabulary=None,\n",
        "        output_mode=output_mode, output_sequence_length=None, pad_to_max_tokens=True,\n",
        "    )\n",
        "    vectorize_layer.adapt(text_dataset.batch(batch_size))\n",
        "    print( f'Output mode: {output_mode}', 'Vocab length:', len(vectorize_layer.get_vocabulary()))\n",
        "    return vectorize_layer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cP1dFTIJY9RG"
      },
      "source": [
        "Get All 3 vectorize layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ccbU5E1ZY9RH"
      },
      "source": [
        "vectorize_bin = getVectorizeLayer('binary', text_dataset)\n",
        "vectorize_int = getVectorizeLayer('int', text_dataset)\n",
        "vectorize_tfidf = getVectorizeLayer('tf-idf', text_dataset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output mode: binary Vocab length: 20742\n",
            "Output mode: int Vocab length: 20743\n",
            "Output mode: tf-idf Vocab length: 20742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xMCuTyCmY9RH"
      },
      "source": [
        "Definition of constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jGvIvXjGY9RH"
      },
      "source": [
        "embedding_dim = 100\n",
        "epochs = 10\n",
        "batch_size = 32"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "86WBMVQeY9RH"
      },
      "source": [
        "#### Architecture 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tKabJry9Y9RH"
      },
      "source": [
        "model1_bin = generateInplaceEmbbedingModel(embedding_dim, vectorize_bin, architecture_id = 1)\n",
        "model1_int = generateInplaceEmbbedingModel(embedding_dim, vectorize_int, architecture_id = 1)\n",
        "model1_tfidf = generateInplaceEmbbedingModel(embedding_dim, vectorize_tfidf, architecture_id = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "t9Y9kSzbY9RH"
      },
      "source": [
        "Compile models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3sujsGDyY9RI"
      },
      "source": [
        "model1_bin.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
        "model1_int.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
        "model1_tfidf.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "6RRMr0LyY9RI"
      },
      "source": [
        "Architecture 1 Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2n3LCv-MY9RI"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jtXhUq10Y9RI"
      },
      "source": [
        "model1_bin.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=epochs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1249/1249 [==============================] - 183s 146ms/step - loss: 1.6667 - accuracy: 0.4153 - val_loss: 1.4757 - val_accuracy: 0.4155\n",
            "Epoch 2/10\n",
            "1249/1249 [==============================] - 189s 151ms/step - loss: 1.4540 - accuracy: 0.4186 - val_loss: 1.4287 - val_accuracy: 0.4155\n",
            "Epoch 3/10\n",
            "1249/1249 [==============================] - 181s 145ms/step - loss: 1.4190 - accuracy: 0.4186 - val_loss: 1.4158 - val_accuracy: 0.4155\n",
            "Epoch 4/10\n",
            "1249/1249 [==============================] - 178s 143ms/step - loss: 1.4082 - accuracy: 0.4186 - val_loss: 1.4101 - val_accuracy: 0.4155\n",
            "Epoch 5/10\n",
            "1249/1249 [==============================] - 179s 143ms/step - loss: 1.4032 - accuracy: 0.4186 - val_loss: 1.4070 - val_accuracy: 0.4155\n",
            "Epoch 6/10\n",
            "1249/1249 [==============================] - 181s 145ms/step - loss: 1.4005 - accuracy: 0.4186 - val_loss: 1.4053 - val_accuracy: 0.4155\n",
            "Epoch 7/10\n",
            "1249/1249 [==============================] - 185s 148ms/step - loss: 1.3989 - accuracy: 0.4186 - val_loss: 1.4043 - val_accuracy: 0.4155\n",
            "Epoch 8/10\n",
            "1249/1249 [==============================] - 194s 155ms/step - loss: 1.3981 - accuracy: 0.4186 - val_loss: 1.4038 - val_accuracy: 0.4155\n",
            "Epoch 9/10\n",
            "1249/1249 [==============================] - 192s 153ms/step - loss: 1.3976 - accuracy: 0.4186 - val_loss: 1.4035 - val_accuracy: 0.4155\n",
            "Epoch 10/10\n",
            "1249/1249 [==============================] - 192s 154ms/step - loss: 1.3973 - accuracy: 0.4186 - val_loss: 1.4034 - val_accuracy: 0.4155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2184b37c5c8>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eImMyZldY9RI"
      },
      "source": [
        "model1_int.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=epochs)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 1.1221 - accuracy: 0.5436 - val_loss: 1.2578 - val_accuracy: 0.4845\n",
            "Epoch 2/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 1.0397 - accuracy: 0.5920 - val_loss: 1.2754 - val_accuracy: 0.4865\n",
            "Epoch 3/10\n",
            "1249/1249 [==============================] - 26s 21ms/step - loss: 0.9722 - accuracy: 0.6267 - val_loss: 1.3077 - val_accuracy: 0.4814\n",
            "Epoch 4/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.9133 - accuracy: 0.6516 - val_loss: 1.3438 - val_accuracy: 0.4785\n",
            "Epoch 5/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.8586 - accuracy: 0.6721 - val_loss: 1.3866 - val_accuracy: 0.4733\n",
            "Epoch 6/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.8110 - accuracy: 0.6888 - val_loss: 1.4323 - val_accuracy: 0.4721\n",
            "Epoch 7/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.7705 - accuracy: 0.7025 - val_loss: 1.4803 - val_accuracy: 0.4679\n",
            "Epoch 8/10\n",
            "1249/1249 [==============================] - 24s 19ms/step - loss: 0.7367 - accuracy: 0.7151 - val_loss: 1.5293 - val_accuracy: 0.4644\n",
            "Epoch 9/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.7091 - accuracy: 0.7243 - val_loss: 1.5787 - val_accuracy: 0.4618\n",
            "Epoch 10/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.6863 - accuracy: 0.7309 - val_loss: 1.6273 - val_accuracy: 0.4581\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x219ff02f2c8>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BaCgbnjcY9RI"
      },
      "source": [
        "model1_tfidf.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=epochs)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1249/1249 [==============================] - 195s 156ms/step - loss: 1.4875 - accuracy: 0.4130 - val_loss: 1.4041 - val_accuracy: 0.4155\n",
            "Epoch 2/10\n",
            "1249/1249 [==============================] - 193s 155ms/step - loss: 1.3982 - accuracy: 0.4186 - val_loss: 1.4036 - val_accuracy: 0.4155\n",
            "Epoch 3/10\n",
            "1249/1249 [==============================] - 197s 158ms/step - loss: 1.3980 - accuracy: 0.4186 - val_loss: 1.4035 - val_accuracy: 0.4155\n",
            "Epoch 4/10\n",
            "1249/1249 [==============================] - 207s 166ms/step - loss: 1.3979 - accuracy: 0.4186 - val_loss: 1.4034 - val_accuracy: 0.4155\n",
            "Epoch 5/10\n",
            "1249/1249 [==============================] - 198s 158ms/step - loss: 1.3978 - accuracy: 0.4186 - val_loss: 1.4034 - val_accuracy: 0.4155\n",
            "Epoch 6/10\n",
            "1249/1249 [==============================] - 199s 159ms/step - loss: 1.3978 - accuracy: 0.4186 - val_loss: 1.4033 - val_accuracy: 0.4155\n",
            "Epoch 7/10\n",
            "1249/1249 [==============================] - 187s 150ms/step - loss: 1.3977 - accuracy: 0.4186 - val_loss: 1.4033 - val_accuracy: 0.4155\n",
            "Epoch 8/10\n",
            "1249/1249 [==============================] - 185s 148ms/step - loss: 1.3977 - accuracy: 0.4186 - val_loss: 1.4033 - val_accuracy: 0.4155\n",
            "Epoch 9/10\n",
            "1249/1249 [==============================] - 193s 155ms/step - loss: 1.3977 - accuracy: 0.4186 - val_loss: 1.4033 - val_accuracy: 0.4155\n",
            "Epoch 10/10\n",
            "1249/1249 [==============================] - 196s 157ms/step - loss: 1.3976 - accuracy: 0.4186 - val_loss: 1.4033 - val_accuracy: 0.4155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2184af004c8>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vNMVvNT6Y9RJ"
      },
      "source": [
        "model1_bin.summary()\n",
        "model1_int.summary()\n",
        "model1_tfidf.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_1 (TextVe (None, 20742)             0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, 20742, 100)        2074200   \n_________________________________________________________________\nglobal_average_pooling1d (Gl (None, 100)               0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                1010      \n_________________________________________________________________\ndense_1 (Dense)              (None, 6)                 66        \n=================================================================\nTotal params: 2,075,276\nTrainable params: 2,075,276\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_2 (TextVe (None, None)              0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, None, 100)         2074300   \n_________________________________________________________________\nglobal_average_pooling1d_1 ( (None, 100)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                1010      \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 66        \n=================================================================\nTotal params: 2,075,376\nTrainable params: 2,075,376\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_3 (TextVe (None, 20742)             0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, 20742, 100)        2074200   \n_________________________________________________________________\nglobal_average_pooling1d_2 ( (None, 100)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                1010      \n_________________________________________________________________\ndense_5 (Dense)              (None, 6)                 66        \n=================================================================\nTotal params: 2,075,276\nTrainable params: 2,075,276\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqCheA1lbkaF"
      },
      "source": [
        "# model1_bin.save(ruta)\n",
        "# model1_int.save(ruta+ 'simp_model1_int')\n",
        "# model1_tfidf.save( ruta+'simp_model1_tfidf')\n",
        "\n",
        "# del model1_bin\n",
        "# del model1_int\n",
        "# del model1_tfidf"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./docs/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pvwWklp-Y9RJ"
      },
      "source": [
        "Architecture 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DKHqNxgoY9RJ"
      },
      "source": [
        "model2_bin = generateInplaceEmbbedingModel(embedding_dim, vectorize_bin, architecture_id = 2)\n",
        "model2_int = generateInplaceEmbbedingModel(embedding_dim, vectorize_int, architecture_id = 2)\n",
        "model2_tfidf = generateInplaceEmbbedingModel(embedding_dim, vectorize_tfidf, architecture_id = 2)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "klCGsNaYY9RJ"
      },
      "source": [
        "Compile models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rnkr8sY5Y9RJ"
      },
      "source": [
        "model2_bin.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
        "model2_int.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
        "model2_tfidf.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CCx0XUmLY9RJ"
      },
      "source": [
        "Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QTAlue7ZY9RJ"
      },
      "source": [
        "model2_bin.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1249/1249 [==============================] - 190s 152ms/step - loss: 1.4305 - accuracy: 0.4134 - val_loss: 1.4076 - val_accuracy: 0.4155\n",
            "Epoch 2/5\n",
            "1249/1249 [==============================] - 185s 148ms/step - loss: 1.4000 - accuracy: 0.4186 - val_loss: 1.4059 - val_accuracy: 0.4155\n",
            "Epoch 3/5\n",
            "1249/1249 [==============================] - 190s 152ms/step - loss: 1.3993 - accuracy: 0.4186 - val_loss: 1.4050 - val_accuracy: 0.4155\n",
            "Epoch 4/5\n",
            "1249/1249 [==============================] - 194s 155ms/step - loss: 1.3988 - accuracy: 0.4186 - val_loss: 1.4043 - val_accuracy: 0.4155\n",
            "Epoch 5/5\n",
            "1249/1249 [==============================] - 193s 155ms/step - loss: 1.3985 - accuracy: 0.4186 - val_loss: 1.4039 - val_accuracy: 0.4155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x219fd4b6848>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XFZmg5EOY9RK"
      },
      "source": [
        "model2_int.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=10)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1249/1249 [==============================] - 26s 21ms/step - loss: 0.7054 - accuracy: 0.7266 - val_loss: 1.6815 - val_accuracy: 0.4685\n",
            "Epoch 2/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.6542 - accuracy: 0.7470 - val_loss: 1.8669 - val_accuracy: 0.4610\n",
            "Epoch 3/10\n",
            "1249/1249 [==============================] - 26s 21ms/step - loss: 0.6058 - accuracy: 0.7646 - val_loss: 2.1383 - val_accuracy: 0.4549\n",
            "Epoch 4/10\n",
            "1249/1249 [==============================] - 26s 21ms/step - loss: 0.5633 - accuracy: 0.7777 - val_loss: 2.4012 - val_accuracy: 0.4441\n",
            "Epoch 5/10\n",
            "1249/1249 [==============================] - 25s 20ms/step - loss: 0.5269 - accuracy: 0.7930 - val_loss: 2.6530 - val_accuracy: 0.4432\n",
            "Epoch 6/10\n",
            "1249/1249 [==============================] - 26s 21ms/step - loss: 0.4929 - accuracy: 0.8066 - val_loss: 2.9147 - val_accuracy: 0.4255\n",
            "Epoch 7/10\n",
            "1249/1249 [==============================] - 26s 21ms/step - loss: 0.4594 - accuracy: 0.8181 - val_loss: 3.2666 - val_accuracy: 0.4268\n",
            "Epoch 8/10\n",
            "1249/1249 [==============================] - 27s 22ms/step - loss: 0.4346 - accuracy: 0.8293 - val_loss: 3.7183 - val_accuracy: 0.4204\n",
            "Epoch 9/10\n",
            "1249/1249 [==============================] - 27s 21ms/step - loss: 0.4131 - accuracy: 0.8368 - val_loss: 3.8441 - val_accuracy: 0.4257\n",
            "Epoch 10/10\n",
            "1249/1249 [==============================] - 27s 21ms/step - loss: 0.3930 - accuracy: 0.8447 - val_loss: 4.0122 - val_accuracy: 0.4287\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x219fed97e48>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8n5XR3UBY9RK"
      },
      "source": [
        "model2_tfidf.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1249/1249 [==============================] - 188s 150ms/step - loss: 1.4317 - accuracy: 0.4156 - val_loss: 1.4071 - val_accuracy: 0.4155\n",
            "Epoch 2/5\n",
            "1249/1249 [==============================] - 193s 155ms/step - loss: 1.4000 - accuracy: 0.4186 - val_loss: 1.4056 - val_accuracy: 0.4155\n",
            "Epoch 3/5\n",
            "1249/1249 [==============================] - 181s 145ms/step - loss: 1.3993 - accuracy: 0.4186 - val_loss: 1.4048 - val_accuracy: 0.4155\n",
            "Epoch 4/5\n",
            "1249/1249 [==============================] - 177s 142ms/step - loss: 1.3988 - accuracy: 0.4186 - val_loss: 1.4043 - val_accuracy: 0.4155\n",
            "Epoch 5/5\n",
            "1249/1249 [==============================] - 179s 143ms/step - loss: 1.3984 - accuracy: 0.4186 - val_loss: 1.4039 - val_accuracy: 0.4155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x219f2261948>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQSGrDOEbzbm"
      },
      "source": [
        "# saveModel(model2_bin, 'simp_model2_bin')\n",
        "# saveModel(model2_int, 'simp_model2_int')\n",
        "# saveModel(model2_tfidf, 'simp_model2_tfidf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LPrsMXopY9RK"
      },
      "source": [
        "Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3Crt6aLnY9RK"
      },
      "source": [
        "model2_bin.summary()\n",
        "model2_int.summary()\n",
        "model2_tfidf.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_1 (TextVe (None, 20742)             0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, 20742, 100)        2074200   \n_________________________________________________________________\nglobal_average_pooling1d_3 ( (None, 100)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 80)                8080      \n_________________________________________________________________\ndense_7 (Dense)              (None, 250)               20250     \n_________________________________________________________________\ndense_8 (Dense)              (None, 6)                 1506      \n=================================================================\nTotal params: 2,104,036\nTrainable params: 2,104,036\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_2 (TextVe (None, None)              0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, None, 100)         2074300   \n_________________________________________________________________\nglobal_average_pooling1d_4 ( (None, 100)               0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 80)                8080      \n_________________________________________________________________\ndense_10 (Dense)             (None, 250)               20250     \n_________________________________________________________________\ndense_11 (Dense)             (None, 6)                 1506      \n=================================================================\nTotal params: 2,104,136\nTrainable params: 2,104,136\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_3 (TextVe (None, 20742)             0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, 20742, 100)        2074200   \n_________________________________________________________________\nglobal_average_pooling1d_5 ( (None, 100)               0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 80)                8080      \n_________________________________________________________________\ndense_13 (Dense)             (None, 250)               20250     \n_________________________________________________________________\ndense_14 (Dense)             (None, 6)                 1506      \n=================================================================\nTotal params: 2,104,036\nTrainable params: 2,104,036\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gjAOCfjCY9RK"
      },
      "source": [
        "Architecture 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-4bF4FD6Y9RK"
      },
      "source": [
        "model3_bin = generateInplaceEmbbedingModel(embedding_dim, vectorize_bin, architecture_id = 3)\n",
        "model3_int = generateInplaceEmbbedingModel(embedding_dim, vectorize_int, architecture_id = 3)\n",
        "model3_tfidf = generateInplaceEmbbedingModel(embedding_dim, vectorize_tfidf, architecture_id = 3)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5abwrcz4Y9RL"
      },
      "source": [
        "Compile models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5JQOeMZXY9RL"
      },
      "source": [
        "model3_bin.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
        "model3_int.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
        "model3_tfidf.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jyUbDMZ6Y9RL"
      },
      "source": [
        "Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RYgOXUFYY9RL"
      },
      "source": [
        "model3_bin.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=epochs)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1249/1249 [==============================] - 183s 146ms/step - loss: 1.4483 - accuracy: 0.3996 - val_loss: 1.4049 - val_accuracy: 0.4155\n",
            "Epoch 2/10\n",
            "1249/1249 [==============================] - 183s 147ms/step - loss: 1.4029 - accuracy: 0.4186 - val_loss: 1.4041 - val_accuracy: 0.4155\n",
            "Epoch 3/10\n",
            "1249/1249 [==============================] - 182s 146ms/step - loss: 1.4005 - accuracy: 0.4186 - val_loss: 1.4038 - val_accuracy: 0.4155\n",
            "Epoch 4/10\n",
            "1249/1249 [==============================] - 182s 146ms/step - loss: 1.3997 - accuracy: 0.4186 - val_loss: 1.4034 - val_accuracy: 0.4155\n",
            "Epoch 5/10\n",
            "1249/1249 [==============================] - 182s 146ms/step - loss: 1.3994 - accuracy: 0.4186 - val_loss: 1.4034 - val_accuracy: 0.4155\n",
            "Epoch 6/10\n",
            "1249/1249 [==============================] - 184s 147ms/step - loss: 1.3994 - accuracy: 0.4186 - val_loss: 1.4034 - val_accuracy: 0.4155\n",
            "Epoch 7/10\n",
            "1249/1249 [==============================] - 183s 147ms/step - loss: 1.3987 - accuracy: 0.4186 - val_loss: 1.4034 - val_accuracy: 0.4155\n",
            "Epoch 8/10\n",
            "1249/1249 [==============================] - 184s 147ms/step - loss: 1.3993 - accuracy: 0.4186 - val_loss: 1.4035 - val_accuracy: 0.4155\n",
            "Epoch 9/10\n",
            "1249/1249 [==============================] - 184s 147ms/step - loss: 1.3990 - accuracy: 0.4186 - val_loss: 1.4037 - val_accuracy: 0.4155\n",
            "Epoch 10/10\n",
            "1249/1249 [==============================] - 186s 149ms/step - loss: 1.3992 - accuracy: 0.4186 - val_loss: 1.4035 - val_accuracy: 0.4155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x219fe5fd888>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yp99BayZY9RL"
      },
      "source": [
        "model3_int.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=10)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1249/1249 [==============================] - 28s 22ms/step - loss: 0.4967 - accuracy: 0.8056 - val_loss: 3.2164 - val_accuracy: 0.4143\n",
            "Epoch 2/10\n",
            "1249/1249 [==============================] - 27s 22ms/step - loss: 0.4789 - accuracy: 0.8127 - val_loss: 3.2977 - val_accuracy: 0.4352\n",
            "Epoch 3/10\n",
            "1249/1249 [==============================] - 28s 22ms/step - loss: 0.4702 - accuracy: 0.8158 - val_loss: 3.1451 - val_accuracy: 0.4143\n",
            "Epoch 4/10\n",
            "1249/1249 [==============================] - 27s 22ms/step - loss: 0.4583 - accuracy: 0.8182 - val_loss: 3.6846 - val_accuracy: 0.4549\n",
            "Epoch 5/10\n",
            "1249/1249 [==============================] - 28s 22ms/step - loss: 0.4566 - accuracy: 0.8204 - val_loss: 3.4131 - val_accuracy: 0.4472\n",
            "Epoch 6/10\n",
            "1249/1249 [==============================] - 27s 22ms/step - loss: 0.4441 - accuracy: 0.8254 - val_loss: 3.5354 - val_accuracy: 0.4471\n",
            "Epoch 7/10\n",
            "1249/1249 [==============================] - 28s 22ms/step - loss: 0.4380 - accuracy: 0.8269 - val_loss: 3.5897 - val_accuracy: 0.4366\n",
            "Epoch 8/10\n",
            "1249/1249 [==============================] - 28s 23ms/step - loss: 0.4251 - accuracy: 0.8320 - val_loss: 3.3939 - val_accuracy: 0.4469\n",
            "Epoch 9/10\n",
            "1249/1249 [==============================] - 27s 22ms/step - loss: 0.4113 - accuracy: 0.8357 - val_loss: 3.7563 - val_accuracy: 0.4444\n",
            "Epoch 10/10\n",
            "1249/1249 [==============================] - 27s 22ms/step - loss: 0.4108 - accuracy: 0.8388 - val_loss: 3.6853 - val_accuracy: 0.4352\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x219fed9bd88>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nlCrEclaY9RL"
      },
      "source": [
        "model3_tfidf.fit(train_dataset.batch(batch_size), validation_data=test_dataset.batch(batch_size), epochs=5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1249/1249 [==============================] - 178s 142ms/step - loss: 1.4492 - accuracy: 0.3989 - val_loss: 1.4055 - val_accuracy: 0.4155\n",
            "Epoch 2/5\n",
            "1249/1249 [==============================] - 180s 144ms/step - loss: 1.4016 - accuracy: 0.4186 - val_loss: 1.4047 - val_accuracy: 0.4155\n",
            "Epoch 3/5\n",
            "1249/1249 [==============================] - 184s 148ms/step - loss: 1.4009 - accuracy: 0.4186 - val_loss: 1.4037 - val_accuracy: 0.4155\n",
            "Epoch 4/5\n",
            "1249/1249 [==============================] - 179s 143ms/step - loss: 1.4009 - accuracy: 0.4186 - val_loss: 1.4036 - val_accuracy: 0.4155\n",
            "Epoch 5/5\n",
            "1249/1249 [==============================] - 180s 144ms/step - loss: 1.4002 - accuracy: 0.4186 - val_loss: 1.4035 - val_accuracy: 0.4155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x219f422dec8>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Mfpa7T7NY9RM"
      },
      "source": [
        "Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d0-3LkGwY9RM"
      },
      "source": [
        "model3_bin.summary()\n",
        "model3_int.summary()\n",
        "model3_tfidf.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_1 (TextVe (None, 20742)             0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, 20742, 100)        2074200   \n_________________________________________________________________\nglobal_average_pooling1d_6 ( (None, 100)               0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 80)                8080      \n_________________________________________________________________\ndropout (Dropout)            (None, 80)                0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 80)                320       \n_________________________________________________________________\ndense_16 (Dense)             (None, 250)               20250     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 250)               0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 6)                 1506      \n=================================================================\nTotal params: 2,104,356\nTrainable params: 2,104,196\nNon-trainable params: 160\n_________________________________________________________________\nModel: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_2 (TextVe (None, None)              0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, None, 100)         2074300   \n_________________________________________________________________\nglobal_average_pooling1d_7 ( (None, 100)               0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 80)                8080      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 80)                0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 80)                320       \n_________________________________________________________________\ndense_19 (Dense)             (None, 250)               20250     \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 250)               0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 6)                 1506      \n=================================================================\nTotal params: 2,104,456\nTrainable params: 2,104,296\nNon-trainable params: 160\n_________________________________________________________________\nModel: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntext_vectorization_3 (TextVe (None, 20742)             0         \n_________________________________________________________________\nembedding_Trainable (Embeddi (None, 20742, 100)        2074200   \n_________________________________________________________________\nglobal_average_pooling1d_8 ( (None, 100)               0         \n_________________________________________________________________\ndense_21 (Dense)             (None, 80)                8080      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 80)                0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 80)                320       \n_________________________________________________________________\ndense_22 (Dense)             (None, 250)               20250     \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 250)               0         \n_________________________________________________________________\ndense_23 (Dense)             (None, 6)                 1506      \n=================================================================\nTotal params: 2,104,356\nTrainable params: 2,104,196\nNon-trainable params: 160\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtsIMF9zb4kC"
      },
      "source": [
        "# saveModel(model3_bin, 'simp_model3_bin')\n",
        "# saveModel(model3_int, 'simp_model3_int')\n",
        "# saveModel(model3_tfidf, 'simp_model3_tfidf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_YnoIVF8Y9RM"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def get_metrics_by_class(model, x,y):\n",
        "  y_pred = model.predict(x.batch(64), verbose=0)\n",
        "  y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "  y_label = np.argmax(y, axis=1)\n",
        "  print(classification_report(y_label, y_pred_bool))"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "id": "q16vM2QrY9RM"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "source": [
        "Evaluate 1st Architecture"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture 1 binary Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2621\n",
            "           1       0.00      0.00      0.00       381\n",
            "           2       0.42      1.00      0.59      5533\n",
            "           3       0.00      0.00      0.00      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00      2635\n",
            "\n",
            "    accuracy                           0.42     13318\n",
            "   macro avg       0.07      0.17      0.10     13318\n",
            "weighted avg       0.17      0.42      0.24     13318\n",
            "\n",
            "Architecture 1 int Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.27      0.32      2621\n",
            "           1       0.29      0.08      0.13       381\n",
            "           2       0.54      0.64      0.59      5533\n",
            "           3       0.36      0.30      0.33      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.39      0.47      0.43      2635\n",
            "\n",
            "    accuracy                           0.46     13318\n",
            "   macro avg       0.33      0.29      0.30     13318\n",
            "weighted avg       0.45      0.46      0.45     13318\n",
            "\n",
            "Architecture 1 tfidf Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2621\n",
            "           1       0.00      0.00      0.00       381\n",
            "           2       0.42      1.00      0.59      5533\n",
            "           3       0.00      0.00      0.00      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00      2635\n",
            "\n",
            "    accuracy                           0.42     13318\n",
            "   macro avg       0.07      0.17      0.10     13318\n",
            "weighted avg       0.17      0.42      0.24     13318\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Architecture 1 binary Embedding')\n",
        "get_metrics_by_class(model1_bin, test_dataset, y_test)\n",
        "print('Architecture 1 int Embedding')\n",
        "get_metrics_by_class(model1_int, test_dataset, y_test)\n",
        "print('Architecture 1 tfidf Embedding')\n",
        "get_metrics_by_class(model1_tfidf, test_dataset, y_test)"
      ]
    },
    {
      "source": [
        "Evaluate Second Architecture"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture 2 binary Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2621\n",
            "           1       0.00      0.00      0.00       381\n",
            "           2       0.42      1.00      0.59      5533\n",
            "           3       0.00      0.00      0.00      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00      2635\n",
            "\n",
            "    accuracy                           0.42     13318\n",
            "   macro avg       0.07      0.17      0.10     13318\n",
            "weighted avg       0.17      0.42      0.24     13318\n",
            "\n",
            "Architecture 2 int Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.22      0.28      2621\n",
            "           1       0.23      0.11      0.15       381\n",
            "           2       0.55      0.56      0.55      5533\n",
            "           3       0.31      0.38      0.34      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.38      0.46      0.41      2635\n",
            "\n",
            "    accuracy                           0.43     13318\n",
            "   macro avg       0.30      0.29      0.29     13318\n",
            "weighted avg       0.43      0.43      0.42     13318\n",
            "\n",
            "Architecture 2 tfidf Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2621\n",
            "           1       0.00      0.00      0.00       381\n",
            "           2       0.42      1.00      0.59      5533\n",
            "           3       0.00      0.00      0.00      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00      2635\n",
            "\n",
            "    accuracy                           0.42     13318\n",
            "   macro avg       0.07      0.17      0.10     13318\n",
            "weighted avg       0.17      0.42      0.24     13318\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Architecture 2 binary Embedding')\n",
        "get_metrics_by_class(model2_bin, test_dataset, y_test)\n",
        "print('Architecture 2 int Embedding')\n",
        "get_metrics_by_class(model2_int, test_dataset, y_test)\n",
        "print('Architecture 2 tfidf Embedding')\n",
        "get_metrics_by_class(model2_tfidf, test_dataset, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture 3 binary Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2621\n",
            "           1       0.00      0.00      0.00       381\n",
            "           2       0.42      1.00      0.59      5533\n",
            "           3       0.00      0.00      0.00      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00      2635\n",
            "\n",
            "    accuracy                           0.42     13318\n",
            "   macro avg       0.07      0.17      0.10     13318\n",
            "weighted avg       0.17      0.42      0.24     13318\n",
            "\n",
            "Architecture 3 int Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.38      0.35      2621\n",
            "           1       0.12      0.17      0.14       381\n",
            "           2       0.50      0.70      0.58      5533\n",
            "           3       0.37      0.14      0.21      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.51      0.20      0.29      2635\n",
            "\n",
            "    accuracy                           0.44     13318\n",
            "   macro avg       0.30      0.27      0.26     13318\n",
            "weighted avg       0.44      0.44      0.41     13318\n",
            "\n",
            "Architecture 3 tfidf Embedding\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2621\n",
            "           1       0.00      0.00      0.00       381\n",
            "           2       0.42      1.00      0.59      5533\n",
            "           3       0.00      0.00      0.00      2145\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00      2635\n",
            "\n",
            "    accuracy                           0.42     13318\n",
            "   macro avg       0.07      0.17      0.10     13318\n",
            "weighted avg       0.17      0.42      0.24     13318\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Architecture 3 binary Embedding')\n",
        "get_metrics_by_class(model3_bin, test_dataset, y_test)\n",
        "print('Architecture 3 int Embedding')\n",
        "get_metrics_by_class(model3_int, test_dataset, y_test)\n",
        "print('Architecture 3 tfidf Embedding')\n",
        "get_metrics_by_class(model3_tfidf, test_dataset, y_test)"
      ]
    }
  ]
}