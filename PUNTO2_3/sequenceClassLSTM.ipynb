{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta = '../datasets/'\n",
    "# df_0 = pd.read_csv(ruta+'simpsons/simpsons_dataset.csv').dropna()\n",
    "# target_simpsons = [\n",
    "#     'Lisa Simpson',\n",
    "#     'Bart Simpson',\n",
    "#     'Homer Simpson',\n",
    "#     'Marge Simpson',\n",
    "#     'Maggie Simpson',\n",
    "#     'Grampa Simpson'\n",
    "# ]\n",
    "# data = df_0.loc[df_0['raw_character_text'].isin(target_simpsons)]\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_path = './datasets/en.jsonl'\n",
    "\n",
    "file = open(english_path, \"r\")\n",
    "data = []\n",
    "for index, line in enumerate(file):\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "text_raw_df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        index            author_id  \\\n",
       "0     1169503            117418104   \n",
       "1     1088588            726456608   \n",
       "2     1229144            191092262   \n",
       "3     1041354           2985792143   \n",
       "4     1190556             19809471   \n",
       "...       ...                  ...   \n",
       "5864   796383  1371495185767526413   \n",
       "5865   779950            203824292   \n",
       "5866   680034            429541970   \n",
       "5867   382165  1154783639378583553   \n",
       "5868   875357            295108729   \n",
       "\n",
       "                                                   text lang  \\\n",
       "0     #Bucks: Milwaukee Bucks and Milwaukee Health D...   en   \n",
       "1     Youth Ages 12-15 Now Eligible for Pfizer COVID...   en   \n",
       "2     Fighting Stigma: Young people should be free t...   en   \n",
       "3     Second jab done! Although by the state of Tesc...   en   \n",
       "4     4/27 - Vaccination and Testing Update - 2020-2...   en   \n",
       "...                                                 ...  ...   \n",
       "5864  families are burdened, students are burned out...   en   \n",
       "5865  What happens when everyone who is now vaccinat...   en   \n",
       "5866  duh. some countries already do...ha!\\nDufus Dr...   en   \n",
       "5867  A year into pandemic, professor mental health ...   en   \n",
       "5868  Leading BJP's campaign, PM Modi has so far add...   en   \n",
       "\n",
       "                                    context_annotations                   id  \\\n",
       "0     [{'domain': {'id': '3', 'name': 'TV Shows', 'd...  1387163086981898240   \n",
       "1     [{'domain': {'id': '65', 'name': 'Interests an...  1392964893469511681   \n",
       "2     [{'domain': {'id': '123', 'name': 'Ongoing New...  1387110938088677376   \n",
       "3     [{'domain': {'id': '123', 'name': 'Ongoing New...  1391014287565545477   \n",
       "4     [{'domain': {'id': '123', 'name': 'Ongoing New...  1387142140606648320   \n",
       "...                                                 ...                  ...   \n",
       "5864  [{'domain': {'id': '123', 'name': 'Ongoing New...  1379007009454911492   \n",
       "5865  [{'domain': {'id': '123', 'name': 'Ongoing New...  1379030125191254018   \n",
       "5866  [{'domain': {'id': '123', 'name': 'Ongoing New...  1379120339943268354   \n",
       "5867  [{'domain': {'id': '65', 'name': 'Interests an...  1379163452166578187   \n",
       "5868  [{'domain': {'id': '123', 'name': 'Ongoing New...  1378873895105789959   \n",
       "\n",
       "                    created_at    date_str  \\\n",
       "0     2021-04-27T21:53:46.000Z  2021-04-27   \n",
       "1     2021-05-13T22:08:05.000Z  2021-05-13   \n",
       "2     2021-04-27T18:26:33.000Z  2021-04-27   \n",
       "3     2021-05-08T12:57:04.000Z  2021-05-08   \n",
       "4     2021-04-27T20:30:32.000Z  2021-04-27   \n",
       "...                        ...         ...   \n",
       "5864  2021-04-05T09:44:26.000Z  2021-04-05   \n",
       "5865  2021-04-05T11:16:17.000Z  2021-04-05   \n",
       "5866  2021-04-05T17:14:46.000Z  2021-04-05   \n",
       "5867  2021-04-05T20:06:05.000Z  2021-04-05   \n",
       "5868  2021-04-05T00:55:29.000Z  2021-04-05   \n",
       "\n",
       "                                        hashtag               tag  \n",
       "0                                       [Bucks]       vaccination  \n",
       "1                                            []       vaccination  \n",
       "2                                            []       vaccination  \n",
       "3                                            []  school-reopening  \n",
       "4                                            []          vaccines  \n",
       "...                                         ...               ...  \n",
       "5864                                         []  school-reopening  \n",
       "5865  [COVIDー19, Coronavirus, VaccinePassports]       vaccination  \n",
       "5866                     [vaccine, vaccination]              NONE  \n",
       "5867                             [mentalhealth]     mental-health  \n",
       "5868                                         []       vaccination  \n",
       "\n",
       "[5869 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>author_id</th>\n      <th>text</th>\n      <th>lang</th>\n      <th>context_annotations</th>\n      <th>id</th>\n      <th>created_at</th>\n      <th>date_str</th>\n      <th>hashtag</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1169503</td>\n      <td>117418104</td>\n      <td>#Bucks: Milwaukee Bucks and Milwaukee Health D...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '3', 'name': 'TV Shows', 'd...</td>\n      <td>1387163086981898240</td>\n      <td>2021-04-27T21:53:46.000Z</td>\n      <td>2021-04-27</td>\n      <td>[Bucks]</td>\n      <td>vaccination</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1088588</td>\n      <td>726456608</td>\n      <td>Youth Ages 12-15 Now Eligible for Pfizer COVID...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '65', 'name': 'Interests an...</td>\n      <td>1392964893469511681</td>\n      <td>2021-05-13T22:08:05.000Z</td>\n      <td>2021-05-13</td>\n      <td>[]</td>\n      <td>vaccination</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1229144</td>\n      <td>191092262</td>\n      <td>Fighting Stigma: Young people should be free t...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n      <td>1387110938088677376</td>\n      <td>2021-04-27T18:26:33.000Z</td>\n      <td>2021-04-27</td>\n      <td>[]</td>\n      <td>vaccination</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1041354</td>\n      <td>2985792143</td>\n      <td>Second jab done! Although by the state of Tesc...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n      <td>1391014287565545477</td>\n      <td>2021-05-08T12:57:04.000Z</td>\n      <td>2021-05-08</td>\n      <td>[]</td>\n      <td>school-reopening</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1190556</td>\n      <td>19809471</td>\n      <td>4/27 - Vaccination and Testing Update - 2020-2...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n      <td>1387142140606648320</td>\n      <td>2021-04-27T20:30:32.000Z</td>\n      <td>2021-04-27</td>\n      <td>[]</td>\n      <td>vaccines</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5864</th>\n      <td>796383</td>\n      <td>1371495185767526413</td>\n      <td>families are burdened, students are burned out...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n      <td>1379007009454911492</td>\n      <td>2021-04-05T09:44:26.000Z</td>\n      <td>2021-04-05</td>\n      <td>[]</td>\n      <td>school-reopening</td>\n    </tr>\n    <tr>\n      <th>5865</th>\n      <td>779950</td>\n      <td>203824292</td>\n      <td>What happens when everyone who is now vaccinat...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n      <td>1379030125191254018</td>\n      <td>2021-04-05T11:16:17.000Z</td>\n      <td>2021-04-05</td>\n      <td>[COVIDー19, Coronavirus, VaccinePassports]</td>\n      <td>vaccination</td>\n    </tr>\n    <tr>\n      <th>5866</th>\n      <td>680034</td>\n      <td>429541970</td>\n      <td>duh. some countries already do...ha!\\nDufus Dr...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n      <td>1379120339943268354</td>\n      <td>2021-04-05T17:14:46.000Z</td>\n      <td>2021-04-05</td>\n      <td>[vaccine, vaccination]</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>5867</th>\n      <td>382165</td>\n      <td>1154783639378583553</td>\n      <td>A year into pandemic, professor mental health ...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '65', 'name': 'Interests an...</td>\n      <td>1379163452166578187</td>\n      <td>2021-04-05T20:06:05.000Z</td>\n      <td>2021-04-05</td>\n      <td>[mentalhealth]</td>\n      <td>mental-health</td>\n    </tr>\n    <tr>\n      <th>5868</th>\n      <td>875357</td>\n      <td>295108729</td>\n      <td>Leading BJP's campaign, PM Modi has so far add...</td>\n      <td>en</td>\n      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n      <td>1378873895105789959</td>\n      <td>2021-04-05T00:55:29.000Z</td>\n      <td>2021-04-05</td>\n      <td>[]</td>\n      <td>vaccination</td>\n    </tr>\n  </tbody>\n</table>\n<p>5869 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "text_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text_raw_df['text'].values\n",
    "y = text_raw_df['tag'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.2, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "top_words = 5000\n",
    "vectorize_layer = TextVectorization(\n",
    "    ngrams=None, max_tokens=top_words, vocabulary=None,\n",
    "    output_mode='int', output_sequence_length=None, pad_to_max_tokens=True,\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(sentences_train)\n",
    "print(len(vectorize_layer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_layer(np.array([[s] for s in sentences_train])).numpy()\n",
    "x_test = vectorize_layer(np.array([[s] for s in sentences_test])).numpy()\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=top_words)\n",
    "# Parece que te tira el dataset como 25 mil train, 25 mil test, con cada entrada el embedding 'int' del doc.\n",
    "# Esto nos tocaría usar un vectorizze layer sobre nuestros docs con output mode 'int'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n1174\n"
     ]
    }
   ],
   "source": [
    "# len(X_train[3])\n",
    "print(type(x_train))\n",
    "len(x_test)\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad or truncate all sequences to half of max lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Máximo tamaño de documento en train: 94\n"
     ]
    }
   ],
   "source": [
    "# Podriamos usar esto o simplemente definir un número 'bueno' y truncar o paddear todo a ese número\n",
    "# Con twitter depronto sí sirve un número de 25 por ejemplo.\n",
    "max_doc_length = np.max([len(doc) for doc in x_train])\n",
    "\n",
    "print('Máximo tamaño de documento en train:', max_doc_length)\n",
    "x_train_padded = sequence.pad_sequences(x_train, maxlen=(max_doc_length))\n",
    "x_test_padded = sequence.pad_sequences(x_test, maxlen=(max_doc_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enconding classification classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "\n",
    "encoder.fit(y_train)\n",
    "y_train_bin = encoder.transform(y_train)\n",
    "y_test_bin = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Número de clases: 6\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(encoder.classes_)\n",
    "print('Número de clases:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá hay que tener cuidado porque nuestro problema de clasificación No es binario\n",
    "# Con los datos reales el Compile debe ser con 'categorical_crossentropy'\n",
    "# Además el tamaño de la última softmax debe ser el mismo que el número de categorias\n",
    "# Se tiene también que pasar los datos en Y a oneHotvectors, ese código lo podemos sacar del notebool model_V1\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 256\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_doc_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 94, 256)           1280000   \n_________________________________________________________________\nlstm (LSTM)                  (None, 100)               142800    \n_________________________________________________________________\ndense (Dense)                (None, 6)                 606       \n=================================================================\nTotal params: 1,423,406\nTrainable params: 1,423,406\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "74/74 [==============================] - 13s 54ms/step - loss: 1.5010 - accuracy: 0.4425 - val_loss: 1.4157 - val_accuracy: 0.4472\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 1.4201 - accuracy: 0.4396 - val_loss: 1.4168 - val_accuracy: 0.4472\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 1.4085 - accuracy: 0.4445 - val_loss: 1.4226 - val_accuracy: 0.4472\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 1.4146 - accuracy: 0.4351 - val_loss: 1.4150 - val_accuracy: 0.4472\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 1.3993 - accuracy: 0.4418 - val_loss: 1.4193 - val_accuracy: 0.4472\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1d2b7eb48>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train_bin, validation_data=(x_test_padded, y_test_bin), epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def get_metrics_by_class(model, x, y):\n",
    "  y_pred = model.predict(x, batch_size=64, verbose=1)\n",
    "  y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "  y_label = np.argmax(y, axis=1)\n",
    "  #print(confusion_matrix(y_pred_bool, y_label))\n",
    "  print(classification_report(y_label, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19/19 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       247\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        72\n",
      "           3       0.00      0.00      0.00       129\n",
      "           4       0.45      1.00      0.62       525\n",
      "           5       0.00      0.00      0.00       199\n",
      "\n",
      "    accuracy                           0.45      1174\n",
      "   macro avg       0.07      0.17      0.10      1174\n",
      "weighted avg       0.20      0.45      0.28      1174\n",
      "\n",
      "C:\\Users\\diego\\anaconda3\\envs\\TF-Keras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\diego\\anaconda3\\envs\\TF-Keras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\diego\\anaconda3\\envs\\TF-Keras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_metrics_by_class(model, x_test_padded, y_test_bin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd06c70104609522f67cb30e8200dfa6f77a5bec0e1b1538a23f62dccdf26f51f37",
   "display_name": "Python 3.7.10 64-bit ('TF-Keras': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}