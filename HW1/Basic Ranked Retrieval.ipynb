{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basic Ranked Retrieval (RRI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/isabelasarmiento/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/isabelasarmiento/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/isabelasarmiento/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xml.dom import minidom\n",
    "from xml.etree import cElementTree as ElementTree\n",
    "import os\n",
    "import nltk\n",
    "import ssl\n",
    "import math\n",
    "import csv\n",
    "\n",
    "try:\n",
    "     _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "     pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading of Inverted Index file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def indexReader():\n",
    "    \"\"\"\n",
    "    Reads the inverted index created in the distributed_inverted_index.ipynb notebook\n",
    "    The path from where it reads the file is docs/inverted_index.pkl\n",
    "    :return: the inverted index, represented in a dictionary where the keys are the terms\n",
    "    and the values is also a dictionary that contains the frecuency of documents\n",
    "    that contain the term, and the posting. The posting is an array itself\n",
    "    that contains the document id, and the term's frequency in that document.\n",
    "    {'term': {'freq': df, 'posting':[[doc1, tf1],[doc2, tf2],...,[docn, tfn]}}\n",
    "    \"\"\"\n",
    "    with open('docs/inverted_index.pkl', 'rb') as index:\n",
    "        return pickle.load(index)\n",
    "\n",
    "invertedIndex = indexReader()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Documents and Queries Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', 'William Beaumont and the Human Digestion William Beaumont and the Human Digestion.  William Beaumont: Physiology of digestion Image Source.  On November 21, 1785, US-American surgeon William Beaumont was born. He became best known as “Father of Gastric Physiology” following his research on human digestion. William Beaumont was born in Lebanon, Connecticut and became a physician. He served as a surgeon’s mate in the Army during the War of 1812. He opened a private practice in Plattsburgh, New York, but rejoined the Army as a surgeon in 1819. Beaumont was stationed at Fort Mackinac on Mackinac Island in Michigan in the early 1820s when it existed to protect the interests of the American Fur Company. The fort became the refuge for a wounded 19-year-old French-Canadian fur trader named Alexis St. Martin when a shotgun went off by accident in the American Fur Company store at close range June 6th, 1822. St. Martin’s wound was quite serious because his stomach was perforated and several ribs were broken. Nobody really expected that the young man would survive but he really did. The skin around St. Martin’s wound fused to the hole in his stomach, leaving a permanent opening – a gastric fistula. [1] Beaumont quickly noticed that there was much research potential. Back then, not too much was known about the digestive system. In order to gain more information, Beaumont performed numerous experiments on St. Martin over a period of eight years. The experiments must have been really uncomfortable for the man, who was inserted bits of different foods tied to strings through the hole in his stomach, pulling them out periodically to observe digestion. Beaumont also removed gastric juice, examining it to better understand its nature. Beaumont became the “Father of Gastric Physiology” and his findings were published in the book “Experiments and Observations on the Gastric Juice and the Physiology of Digestion” in 1833. The work is now considered as the basis of much of the early knowledge on digestion. William Beaumont discovered that hydrochloric acid is the main chemical responsible for breaking down food and he suggested that another important digestive chemical, which is now known as pepsin. He suggested that digestion is a chemical process, not merely a mechanical one caused by stomach muscle movement. Also, Beaumont gave insights on how emotions, temperature, and physical activity can affect digestion. Beaumont’s famous patient, St. Martin, outlived the scientist even though his wound never completely healed. He had several children and died at the age of 83. [2] At yovisto, you may be interested in a video lecture on The Digestive System.')\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "def documentReader():\n",
    "    \"\"\"\n",
    "    This method reads the documents\n",
    "    :return: Dictionary of documents {dXXX: content of document dXXX}\n",
    "    \"\"\"\n",
    "    documents_path = os.path.join(os.getcwd(), 'docs/docs-raw-texts')\n",
    "    documentos = {}\n",
    "    documents_paths = os.listdir(documents_path)\n",
    "    documents_paths.sort()\n",
    "    #print(documents_paths)\n",
    "    for filename in documents_paths:\n",
    "        file_path = os.path.join(documents_path, filename)\n",
    "        #print(filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        title = xmldoc.getElementsByTagName('fileDesc')[0].attributes['title'].value\n",
    "        data = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        documentos[id] = (title + ' ' + data).replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "    return documentos\n",
    "\n",
    "documentos = documentReader()\n",
    "print(list(documentos.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', 'Fabrication of music instruments')\n"
     ]
    }
   ],
   "source": [
    "def queries_reader():\n",
    "    \"\"\"\n",
    "    This method reads the queries\n",
    "    :return: Dictionary of queries {qYY: content of query qYY}\n",
    "    \"\"\"\n",
    "    queries_path = os.path.join(os.getcwd(), 'docs/queries-raw-texts')\n",
    "    queries = {}\n",
    "    queries_paths = os.listdir(queries_path)\n",
    "    queries_paths.sort()\n",
    "    #print(documents_paths)\n",
    "    queries_index = []\n",
    "    for filename in queries_paths:\n",
    "        file_path = os.path.join(queries_path, filename)\n",
    "        #print(filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        query = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        queries[id] = query.replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "        queries_index.append(id)\n",
    "    return queries, queries_index\n",
    "\n",
    "queries, queries_index = queries_reader()\n",
    "print(list(queries.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', ['Fabrication', 'music', 'instrument'])\n"
     ]
    }
   ],
   "source": [
    "def queries_tokenization(queries):\n",
    "    \"\"\"\n",
    "    Queries tokenization using nltk. The returned dictionary,\n",
    "    :param queries in a dictionary, {qYY: content of query qYY}\n",
    "    :return: Dictionary of tokenized queries {qYY: [\"term1\",\"term2\",...,\"termn\"]}\n",
    "    \"\"\"\n",
    "    nltk_stop_words_en = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    #print(\"items\", queries.items())\n",
    "    tokenized_queries = {}\n",
    "    for key,doc in queries.items():\n",
    "        word_tok = nltk.word_tokenize(doc)\n",
    "        word_tok_sw = [token for token in word_tok if (token.isalnum()) and (token not in nltk_stop_words_en)\n",
    "                       ]\n",
    "        nltk_lemmaList = [wordnet_lemmatizer.lemmatize(word) for word in word_tok_sw]\n",
    "        #print(nltk_lemmaList)\n",
    "        tokenized_queries[key] = nltk_lemmaList\n",
    "\n",
    "    return tokenized_queries\n",
    "\n",
    "\n",
    "\n",
    "tokenized_queries = queries_tokenization(queries)\n",
    "print(list(tokenized_queries.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def score(query, document_id, invertedIndex, N):\n",
    "    \"\"\"\n",
    "    Computes to score for a query, document pair\n",
    "    :param query: tokenized query in a document,  {qYY: [\"term1\",\"term2\",...,\"termn\"]}\n",
    "    :param document_id: id of the document in \"dxxx\" notation\n",
    "    :param invertedIndex: inverted index in a dictionary, {'term': {'freq': df, 'posting':[[doc1, tf1],[doc2, tf2],...,[docn, tfn]}}\n",
    "    :param N: the amount of documents\n",
    "    :return: the score of the query (decimal)\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "\n",
    "    tokens = query[1]\n",
    "    for token in tokens:\n",
    "        token_in_index = invertedIndex.get(token, \"unknown_token\")\n",
    "        if token_in_index != \"unknown_token\":\n",
    "            token_posting = token_in_index[\"posting\"]\n",
    "            tf = 0\n",
    "            tf_w = 0\n",
    "            for doc_freq_pair in token_posting:\n",
    "                if doc_freq_pair[0] == document_id:\n",
    "                    tf = doc_freq_pair[1]\n",
    "                    tf_w = math.log10(1 + tf)\n",
    "                    break\n",
    "            df = token_in_index[\"freq\"]\n",
    "            idf = math.log10( N / df )\n",
    "            score += tf_w*idf\n",
    "    return  score\n",
    "\n",
    "\n",
    "query1 = list(tokenized_queries.items())[3]\n",
    "\n",
    "scoreQ1 = score(query1, 'd001', invertedIndex, len(documentos))\n",
    "print(scoreQ1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score function alternative"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The start time is : 8506.557397442\n",
      "The stop time is : 8506.572125416\n",
      "The time difference is : 0.014727973999470123 seconds\n"
     ]
    }
   ],
   "source": [
    "def basic_ranked_retrieval(queries,invertedIndex,documents,N):\n",
    "    \"\"\"\n",
    "    Computes the score for all the queries\n",
    "    :param queries: tokenized queries in a dictorionary {qYY: [\"term1\",\"term2\",...,\"termn\"]}\n",
    "    :param invertedIndex: inverted index in a dictionary {'term': {'freq': df, 'posting':[[doc1, tf1],[doc2, tf2],...,[docn, tfn]}}\n",
    "    :param documents: tokenized documents in a dictionary {dXXX: content of document dXXX}\n",
    "    :param N: total number of documents\n",
    "    :return: a dictionary with the scores for all the queries for each document\n",
    "    {'qYY': {'dXXX': score1, 'dXXX': score2, ..., 'dXXX': score3 } }\n",
    "    \"\"\"\n",
    "\n",
    "    scores= {}\n",
    "    query_scores_template = {}\n",
    "    for key, doc in documents.items():\n",
    "        query_scores_template[key] = 0\n",
    "\n",
    "    for query,tokens in queries.items():\n",
    "        query_scores = query_scores_template.copy()\n",
    "        for token in tokens:\n",
    "            if token in invertedIndex:\n",
    "                df = invertedIndex[token][\"freq\"]\n",
    "                idf = math.log10( N / df )\n",
    "                for docs in invertedIndex[token][\"posting\"]:\n",
    "                    tf = docs[1]\n",
    "                    tf_w = math.log10(1 + tf)\n",
    "                    #if docs[0] not in query_scores:\n",
    "                    #    query_scores[docs[0]] = 0\n",
    "                    docId = \"d{0:0=3d}\".format(docs[0])\n",
    "                    query_scores[docId] += tf_w*idf\n",
    "        clean_query_scores = { k : v for k,v in query_scores.items() if v != 0}\n",
    "        clean_query_scores = dict(sorted(clean_query_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "        scores[query] = clean_query_scores#query_scores\n",
    "\n",
    "    return scores\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "print(\"The start time is :\",start_time)\n",
    "RRI = basic_ranked_retrieval(tokenized_queries,invertedIndex, documentos, len(documentos))\n",
    "stop_time = timeit.default_timer()\n",
    "print(\"The stop time is :\", stop_time)\n",
    "print(\"The time difference is :\", stop_time - start_time, 'seconds')\n",
    "\n",
    "#print(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Método\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo escrito\n"
     ]
    }
   ],
   "source": [
    "def writeScoreFile(RRI):\n",
    "    \"\"\"\n",
    "    Writes the RRI-queries_results.tsv that contains the score of each query\n",
    "    :param RRI: Dictionary with the scores, {'qYY': {'dXXX': score1, 'dXXX': score2, ..., 'dXXX': score3 } }\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(os.getcwd(), 'docs/answer_files/RRI-queries_results.tsv')\n",
    "    with open(file_path, 'wt') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        for query_id,scores in RRI.items():\n",
    "            scores_list = \"\"\n",
    "            for doc,score in scores.items():\n",
    "                scores_list+= doc +\":\"+str(round(score,4))+\",\"\n",
    "            tsv_writer.writerow([query_id,scores_list[:-1]])\n",
    "\n",
    "\n",
    "writeScoreFile(RRI)\n",
    "print(\"Archivo escrito\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "['d016', 'd254', 'd186', 'd153', 'd209']"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def RRI_simplifier(RRI):\n",
    "    \"\"\"\n",
    "    Simplifica los resultados, eliminando los puntajes.\n",
    "    :param RRI: Dictionary with scores {'qYY': {'dXXX': score1, 'dXXX': score2, ..., 'dXXX': score3 } }\n",
    "    :return: {'qXX':['dXXX','dYYY',...]}\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for qid,scores in RRI.items():\n",
    "        docs = []\n",
    "        for k,v in scores.items():\n",
    "            docs.append(k)\n",
    "        result[qid]=docs\n",
    "    return result\n",
    "\n",
    "\n",
    "results = RRI_simplifier(RRI)\n",
    "results['q01'][:5]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d016': '5', 'd186': '4', 'd254': '5'}\n"
     ]
    }
   ],
   "source": [
    "def read_judgemnts_file():\n",
    "    \"\"\"\n",
    "    Lee el archivo de relevancia de los jueces\n",
    "    :return: Diccionario con pares key: value, donde el key es el id de cada query y el value\n",
    "    es otro doccionario con las ids de los docs relevantes para esa query ordenados en forma creciente.\n",
    "    \"\"\"\n",
    "    document_path = os.path.join(os.getcwd(), 'docs/relevance-judgments.tsv')\n",
    "    tsv_file = open(document_path)\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    relevance = {}\n",
    "    for row in read_tsv:\n",
    "        documents = row[1].split(',')\n",
    "        query_relevance = {pair.split(':')[0] : pair.split(':')[1] for pair in documents }\n",
    "        query_relevance = dict(sorted(query_relevance.items(), key=lambda item: item[0]))\n",
    "        relevance[row[0]] = query_relevance\n",
    "    return relevance\n",
    "\n",
    "\n",
    "relevance = read_judgemnts_file()\n",
    "print(relevance['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Maping of results to numeric and binary vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "[5, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "def make_binary_result(results, relevant_res):\n",
    "    \"\"\"\n",
    "    Este método toma los resultados crudos obtenidos para las queries (Para cada query la lista de documentos ordenaos\n",
    "    por relevancia), devuelve 3 representaciones de estos resultados. La primera es la representacion binaria at K.\n",
    "    Que es del mismo tamaño que el número de documentos relevantes. La segunda es esta misma lista pero con la escala\n",
    "    dada por el archivo de evaluación. La tercera está destinada al cálculo del MAP, tiene la representación binaria\n",
    "    hasta que salgan todos los documentos relevantes o simplemente de todos los documentos, además en su segundo\n",
    "    componente tiene el número de documentos relevantes que deberían salir en los resultados según el archivo de\n",
    "    evaluación.\n",
    "    :param results: Diccionario con resultados crudos de cada query. Ej: {'q01': ['d254', 'd016', 'd153', ...]}\n",
    "    :param relevant_res: Las 3 representaciones antes mencionadas\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bin_relevant = {}\n",
    "    rel_scale_repr = {}\n",
    "    map_relevant_docs = {}\n",
    "    for query, relevant_docs in relevant_res.items():\n",
    "        bin_repr = []\n",
    "        scaled_repr = []\n",
    "        map_repr = []\n",
    "        M = len(relevant_docs)\n",
    "        for doc_id, rel_scale in relevant_docs.items():\n",
    "            bin = 1 if doc_id in results[query][:M] else 0\n",
    "            bin_repr.append(bin)\n",
    "            scaled_repr.append(bin * int(rel_scale))\n",
    "        i = 0\n",
    "        for doc_id in results[query]:\n",
    "            if i < M:\n",
    "                map_bin = 1 if doc_id in relevant_res[query] else 0\n",
    "                i += map_bin\n",
    "                map_repr.append(map_bin)\n",
    "        bin_relevant[query] = bin_repr\n",
    "        rel_scale_repr[query] = scaled_repr\n",
    "        map_relevant_docs[query] = [map_repr, M]\n",
    "    return bin_relevant, rel_scale_repr, map_relevant_docs\n",
    "\n",
    "bin_results, scaled_results, map_relevant_docs = make_binary_result(results, relevance)\n",
    "print(bin_results['q01'])\n",
    "print(scaled_results['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 5 documentos devueltos como relevantes para q01: \n",
      " ['d016', 'd254', 'd186', 'd153', 'd209']\n",
      "Documentos relevantes para q01 según jueces: \n",
      " {'d016': '5', 'd186': '4', 'd254': '5'}\n",
      "Representación binaria de q01, hasta el último doc relevante: \n",
      " [[1, 1, 1], 3]\n"
     ]
    }
   ],
   "source": [
    "print('Primeros 5 documentos devueltos como relevantes para q01: \\n', results['q01'][:5])\n",
    "print('Documentos relevantes para q01 según jueces: \\n' , relevance['q01'])\n",
    "print('Representación binaria de q01, hasta el último doc relevante: \\n' ,map_relevant_docs['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of IR metrics functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "0.35468253968253965"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_at_k(relevance: list, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    l = np.array(relevance[:k]).sum()/k\n",
    "    return l\n",
    "\n",
    "def recall_at_k(relevance: list, nr_relevant: int, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    l = np.array(relevance[:k]).sum()/nr_relevant\n",
    "    return l\n",
    "\n",
    "def average_precision(relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    length = len(relevance[0])\n",
    "    sum = 0\n",
    "    for i in range(length):\n",
    "        if relevance[0][i]:\n",
    "            sum += precision_at_k(relevance[0], i+1)\n",
    "    if np.array(relevance[0]).sum()==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum / relevance[1]\n",
    "\n",
    "def mean_avg_precision(l):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    mean = np.array([ average_precision(lista) for lista in l]).mean()\n",
    "    return mean\n",
    "\n",
    "mean_avg_precision([[[0, 0, 0, 0, 0, 0, 1], 1], [[0, 0, 0, 1, 1], 2], [[0, 1, 0, 1, 1, 1, 1], 5]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7424602308163405"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dcg_at_k(relevance, k: int):\n",
    "    \"\"\"\n",
    "    Calcula el DCG at K de un vector binario representando los resultados relevantes para una query.\n",
    "    :param relevance: Vector binario\n",
    "    :return: DCG at K de nuestra query\n",
    "    \"\"\"\n",
    "\n",
    "    sum = 0\n",
    "    i =  0\n",
    "    for rel_i in relevance[: k]:\n",
    "        i+= 1\n",
    "        sum += rel_i/np.log2(max(i, 2))\n",
    "\n",
    "    return sum\n",
    "\n",
    "dcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)\n",
    "\n",
    "def ndcg_at_k(relevance, k):\n",
    "    \"\"\"\n",
    "    Calcula el ndcg at k de un vector binario\n",
    "    :return: NDCG at K.\n",
    "    \"\"\"\n",
    "    rel_sorted = sorted(relevance, reverse=True)\n",
    "    max = dcg_at_k(rel_sorted, k)\n",
    "    real = dcg_at_k(relevance, k)\n",
    "\n",
    "    return real/ max if max != 0 else 0\n",
    "\n",
    "\n",
    "ndcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(recall_at_k(bin_results['q01'], 3, 3))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Evaluation Metrics for each query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "          P@M       R@M      DCG@M    NDCG@M\nq01  1.000000  1.000000  12.154649  0.970530\nq02  0.000000  0.000000   0.000000  0.000000\nq03  0.000000  0.000000   0.000000  0.000000\nq04  0.000000  0.000000   0.000000  0.000000\nq06  0.000000  0.000000   0.000000  0.000000\nq07  0.000000  0.000000   0.000000  0.000000\nq08  0.666667  0.666667  14.386539  0.835863\nq09  0.000000  0.000000   0.000000  0.000000\nq10  0.125000  0.125000   2.000000  1.000000\nq12  0.000000  0.000000   0.000000  0.000000\nq13  0.000000  0.000000   0.000000  0.000000\nq14  0.000000  0.000000   0.000000  0.000000\nq16  0.000000  0.000000   0.000000  0.000000\nq17  0.000000  0.000000   0.000000  0.000000\nq18  0.000000  0.000000   0.000000  0.000000\nq19  0.000000  0.000000   0.000000  0.000000\nq22  0.000000  0.000000   0.000000  0.000000\nq23  0.000000  0.000000   0.000000  0.000000\nq24  0.000000  0.000000   0.000000  0.000000\nq25  0.750000  0.750000   6.892789  0.949177\nq26  0.000000  0.000000   0.000000  0.000000\nq27  0.250000  0.250000   2.861353  0.715338\nq28  0.000000  0.000000   0.000000  0.000000\nq29  0.083333  0.083333   5.000000  1.000000\nq32  0.000000  0.000000   0.000000  0.000000\nq34  0.000000  0.000000   0.000000  0.000000\nq36  0.200000  0.200000   4.547411  0.649630\nq37  0.000000  0.000000   0.000000  0.000000\nq38  0.500000  0.500000   7.198534  0.660853\nq40  0.000000  0.000000   0.000000  0.000000\nq41  0.000000  0.000000   0.000000  0.000000\nq42  0.000000  0.000000   0.000000  0.000000\nq44  0.000000  0.000000   0.000000  0.000000\nq45  0.000000  0.000000   0.000000  0.000000\nq46  0.166667  0.166667   1.292030  0.430677",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>P@M</th>\n      <th>R@M</th>\n      <th>DCG@M</th>\n      <th>NDCG@M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>q01</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>12.154649</td>\n      <td>0.970530</td>\n    </tr>\n    <tr>\n      <th>q02</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q03</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q04</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q06</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q07</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q08</th>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>14.386539</td>\n      <td>0.835863</td>\n    </tr>\n    <tr>\n      <th>q09</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q10</th>\n      <td>0.125000</td>\n      <td>0.125000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>q12</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q13</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q14</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q16</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q17</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q18</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q19</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q22</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q23</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q24</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q25</th>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>6.892789</td>\n      <td>0.949177</td>\n    </tr>\n    <tr>\n      <th>q26</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q27</th>\n      <td>0.250000</td>\n      <td>0.250000</td>\n      <td>2.861353</td>\n      <td>0.715338</td>\n    </tr>\n    <tr>\n      <th>q28</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q29</th>\n      <td>0.083333</td>\n      <td>0.083333</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>q32</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q34</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q36</th>\n      <td>0.200000</td>\n      <td>0.200000</td>\n      <td>4.547411</td>\n      <td>0.649630</td>\n    </tr>\n    <tr>\n      <th>q37</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q38</th>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>7.198534</td>\n      <td>0.660853</td>\n    </tr>\n    <tr>\n      <th>q40</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q41</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q42</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q44</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q45</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q46</th>\n      <td>0.166667</td>\n      <td>0.166667</td>\n      <td>1.292030</td>\n      <td>0.430677</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation_metric(bin_queries, query_index, scaled_results):\n",
    "    \"\"\"\n",
    "\n",
    "    :param bin_queries: Diccionario con valores {query Key: vector}, donde el vector corresponde a una lista\n",
    "    con la representación binaria de un de los resultados encontrados para una query con relación a los dados\n",
    "    en el archivo de evaluación. Ej, para q01, los relevantes son: d186,d254,d016. El RRDV devuelve d254, d016,\n",
    "    d153. Por ende, la representación binaria de q01, en el orden del archivo de evaluación es: [0, 1, 1]\n",
    "    :param query_index: Lista con los ids de las queries. ['qo1', 'qo2', ...]\n",
    "    :param scaled_results: Representación escalada de los resultados de las queries usando la escala dada en el\n",
    "    archivo de evaluación. Ej, q01 pasa de [0, 1, 1] a [0, 5, 5]\n",
    "    :return: Un dataframe con el cálculo del P@M, r@M y NDCG@M para cada query\n",
    "    \"\"\"\n",
    "    COLUMNS = ['P@M', 'R@M', 'DCG@M', 'NDCG@M']\n",
    "    records = []\n",
    "    for query, bin_vec in bin_queries.items():\n",
    "        scaled = scaled_results[query]\n",
    "        M = len(bin_vec)\n",
    "        pm = precision_at_k(bin_vec, M)\n",
    "        rm = recall_at_k(bin_vec, M, M)\n",
    "        dcg = dcg_at_k(scaled, M)\n",
    "        ndcg = ndcg_at_k(scaled, M)\n",
    "        records.append([pm, rm,dcg, ndcg])\n",
    "\n",
    "    return pd.DataFrame.from_records(records, index=query_index, columns=COLUMNS)\n",
    "\n",
    "metrics = evaluation_metric(bin_results, queries_index, scaled_results)\n",
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP resultante de todas las queries: 0.10064463676195876\n"
     ]
    }
   ],
   "source": [
    "def overall_map(map_relevant_docs):\n",
    "    \"\"\"\n",
    "    Función que calcula el MAP de los resultados de las queries.\n",
    "    :param map_relevant_docs: Vector binario de las queries asegurandose de que aparezcan todos los documentos relevantes\n",
    "    :return: El Mean average precision de los resultados de las queries.\n",
    "    \"\"\"\n",
    "    matrix = [vector for key, vector in map_relevant_docs.items() ]\n",
    "    return mean_avg_precision(matrix)\n",
    "\n",
    "print(f'MAP resultante de todas las queries: {overall_map(map_relevant_docs)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}