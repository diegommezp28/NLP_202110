{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/isabelasarmiento/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/isabelasarmiento/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/isabelasarmiento/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Ranked Retrieval (RRI)\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xml.dom import minidom\n",
    "from xml.etree import cElementTree as ElementTree\n",
    "import os\n",
    "import nltk\n",
    "import ssl\n",
    "import math\n",
    "import csv\n",
    "\n",
    "try:\n",
    "     _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "     pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def indexReader():\n",
    "    with open('docs/inverted_index.pkl', 'rb') as index:\n",
    "        return pickle.load(index)\n",
    "\n",
    "index2 = indexReader()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', 'William Beaumont and the Human Digestion William Beaumont and the Human Digestion.  William Beaumont: Physiology of digestion Image Source.  On November 21, 1785, US-American surgeon William Beaumont was born. He became best known as “Father of Gastric Physiology” following his research on human digestion. William Beaumont was born in Lebanon, Connecticut and became a physician. He served as a surgeon’s mate in the Army during the War of 1812. He opened a private practice in Plattsburgh, New York, but rejoined the Army as a surgeon in 1819. Beaumont was stationed at Fort Mackinac on Mackinac Island in Michigan in the early 1820s when it existed to protect the interests of the American Fur Company. The fort became the refuge for a wounded 19-year-old French-Canadian fur trader named Alexis St. Martin when a shotgun went off by accident in the American Fur Company store at close range June 6th, 1822. St. Martin’s wound was quite serious because his stomach was perforated and several ribs were broken. Nobody really expected that the young man would survive but he really did. The skin around St. Martin’s wound fused to the hole in his stomach, leaving a permanent opening – a gastric fistula. [1] Beaumont quickly noticed that there was much research potential. Back then, not too much was known about the digestive system. In order to gain more information, Beaumont performed numerous experiments on St. Martin over a period of eight years. The experiments must have been really uncomfortable for the man, who was inserted bits of different foods tied to strings through the hole in his stomach, pulling them out periodically to observe digestion. Beaumont also removed gastric juice, examining it to better understand its nature. Beaumont became the “Father of Gastric Physiology” and his findings were published in the book “Experiments and Observations on the Gastric Juice and the Physiology of Digestion” in 1833. The work is now considered as the basis of much of the early knowledge on digestion. William Beaumont discovered that hydrochloric acid is the main chemical responsible for breaking down food and he suggested that another important digestive chemical, which is now known as pepsin. He suggested that digestion is a chemical process, not merely a mechanical one caused by stomach muscle movement. Also, Beaumont gave insights on how emotions, temperature, and physical activity can affect digestion. Beaumont’s famous patient, St. Martin, outlived the scientist even though his wound never completely healed. He had several children and died at the age of 83. [2] At yovisto, you may be interested in a video lecture on The Digestive System.')\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "def documentReader():\n",
    "    \"\"\"\n",
    "    This method reads the documents\n",
    "    :return: Dictionary of documents (di: content of document i)\n",
    "    \"\"\"\n",
    "    documents_path = os.path.join(os.getcwd(), 'docs/docs-raw-texts')\n",
    "    documentos = {}\n",
    "    documents_paths = os.listdir(documents_path)\n",
    "    documents_paths.sort()\n",
    "    #print(documents_paths)\n",
    "    for filename in documents_paths:\n",
    "        file_path = os.path.join(documents_path, filename)\n",
    "        #print(filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        title = xmldoc.getElementsByTagName('fileDesc')[0].attributes['title'].value\n",
    "        data = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        documentos[id] = (title + ' ' + data).replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "    return documentos\n",
    "\n",
    "documentos = documentReader()\n",
    "print(list(documentos.items())[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', ['William', 'Beaumont', 'Human', 'Digestion', 'William', 'Beaumont', 'Human', 'Digestion', '.', 'William', 'Beaumont', ':', 'Physiology', 'digestion', 'Image', 'Source', '.', 'On', 'November', '21', ',', '1785', ',', 'US-American', 'surgeon', 'William', 'Beaumont', 'born', '.', 'He', 'became', 'best', 'known', '“', 'Father', 'Gastric', 'Physiology', '”', 'following', 'research', 'human', 'digestion', '.', 'William', 'Beaumont', 'born', 'Lebanon', ',', 'Connecticut', 'became', 'physician', '.', 'He', 'served', 'surgeon', '’', 'mate', 'Army', 'War', '1812', '.', 'He', 'opened', 'private', 'practice', 'Plattsburgh', ',', 'New', 'York', ',', 'rejoined', 'Army', 'surgeon', '1819', '.', 'Beaumont', 'stationed', 'Fort', 'Mackinac', 'Mackinac', 'Island', 'Michigan', 'early', '1820s', 'existed', 'protect', 'interest', 'American', 'Fur', 'Company', '.', 'The', 'fort', 'became', 'refuge', 'wounded', '19-year-old', 'French-Canadian', 'fur', 'trader', 'named', 'Alexis', 'St.', 'Martin', 'shotgun', 'went', 'accident', 'American', 'Fur', 'Company', 'store', 'close', 'range', 'June', '6th', ',', '1822', '.', 'St.', 'Martin', '’', 'wound', 'quite', 'serious', 'stomach', 'perforated', 'several', 'rib', 'broken', '.', 'Nobody', 'really', 'expected', 'young', 'man', 'would', 'survive', 'really', '.', 'The', 'skin', 'around', 'St.', 'Martin', '’', 'wound', 'fused', 'hole', 'stomach', ',', 'leaving', 'permanent', 'opening', '–', 'gastric', 'fistula', '.', '[', '1', ']', 'Beaumont', 'quickly', 'noticed', 'much', 'research', 'potential', '.', 'Back', ',', 'much', 'known', 'digestive', 'system', '.', 'In', 'order', 'gain', 'information', ',', 'Beaumont', 'performed', 'numerous', 'experiment', 'St.', 'Martin', 'period', 'eight', 'year', '.', 'The', 'experiment', 'must', 'really', 'uncomfortable', 'man', ',', 'inserted', 'bit', 'different', 'food', 'tied', 'string', 'hole', 'stomach', ',', 'pulling', 'periodically', 'observe', 'digestion', '.', 'Beaumont', 'also', 'removed', 'gastric', 'juice', ',', 'examining', 'better', 'understand', 'nature', '.', 'Beaumont', 'became', '“', 'Father', 'Gastric', 'Physiology', '”', 'finding', 'published', 'book', '“', 'Experiments', 'Observations', 'Gastric', 'Juice', 'Physiology', 'Digestion', '”', '1833', '.', 'The', 'work', 'considered', 'basis', 'much', 'early', 'knowledge', 'digestion', '.', 'William', 'Beaumont', 'discovered', 'hydrochloric', 'acid', 'main', 'chemical', 'responsible', 'breaking', 'food', 'suggested', 'another', 'important', 'digestive', 'chemical', ',', 'known', 'pepsin', '.', 'He', 'suggested', 'digestion', 'chemical', 'process', ',', 'merely', 'mechanical', 'one', 'caused', 'stomach', 'muscle', 'movement', '.', 'Also', ',', 'Beaumont', 'gave', 'insight', 'emotion', ',', 'temperature', ',', 'physical', 'activity', 'affect', 'digestion', '.', 'Beaumont', '’', 'famous', 'patient', ',', 'St.', 'Martin', ',', 'outlived', 'scientist', 'even', 'though', 'wound', 'never', 'completely', 'healed', '.', 'He', 'several', 'child', 'died', 'age', '83', '.', '[', '2', ']', 'At', 'yovisto', ',', 'may', 'interested', 'video', 'lecture', 'The', 'Digestive', 'System', '.'])\n"
     ]
    }
   ],
   "source": [
    "def tokenization(documentos):\n",
    "    \"\"\"\n",
    "    :param documentos:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nltk_stop_words_en = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    p_stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    word_tok = {key: nltk.word_tokenize(doc) for key, doc in documentos.items()}\n",
    "    word_tok_sw = {key: [token for token in doc if token not in nltk_stop_words_en] for key, doc in word_tok.items()}\n",
    "    # nltk_stemedList_en = {key: [p_stemmer.stem(word) for word in doc] for key, doc in word_tok_sw.items()}\n",
    "    nltk_lemmaList = {key: [wordnet_lemmatizer.lemmatize(word) for word in doc] for key, doc in word_tok_sw.items()}\n",
    "\n",
    "    return nltk_lemmaList\n",
    "\n",
    "tokenized_docs = tokenization(documentos)\n",
    "print(list(tokenized_docs.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('William', {'posting': [['d001', 6], ['d015', 6], ['d028', 4], ['d035', 2], ['d055', 4], ['d056', 5], ['d069', 6], ['d088', 3], ['d091', 1], ['d092', 1], ['d095', 1], ['d098', 2], ['d102', 5], ['d106', 1], ['d109', 1], ['d111', 1], ['d129', 1], ['d136', 8], ['d138', 3], ['d147', 1], ['d175', 1], ['d179', 2], ['d180', 1], ['d189', 2], ['d190', 1], ['d191', 1], ['d197', 1], ['d212', 1], ['d230', 1], ['d241', 2], ['d254', 1], ['d257', 1], ['d266', 2], ['d272', 1], ['d273', 8], ['d274', 1], ['d289', 1], ['d291', 1], ['d294', 1], ['d299', 1], ['d300', 1], ['d309', 1], ['d310', 5], ['d320', 6], ['d323', 1], ['d330', 7]], 'freq': 46})\n"
     ]
    }
   ],
   "source": [
    "def makeInvertedIndex(tokenized_docs):\n",
    "\n",
    "    index = {}\n",
    "\n",
    "    for id, doc in tokenized_docs.items():\n",
    "        #id = int(id[-3:]) #paasa dnjk al entero njk.\n",
    "        for token in doc:\n",
    "            if token in index :\n",
    "                if index[token]['posting'][-1][0] == id:\n",
    "                    index[token]['posting'][-1][1] += 1\n",
    "                else:\n",
    "                    index[token]['posting'].append([id, 1])\n",
    "                    index[token]['freq'] += 1\n",
    "\n",
    "            else:\n",
    "                index[token] = {\n",
    "                    'posting': [[id, 1]],\n",
    "                    'freq': 1\n",
    "                }\n",
    "    return index\n",
    "\n",
    "\n",
    "invertedIndex = makeInvertedIndex(tokenized_docs)\n",
    "print(list(invertedIndex.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', 'Fabrication of music instruments')\n"
     ]
    }
   ],
   "source": [
    "def queries_reader():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    queries_path = os.path.join(os.getcwd(), 'docs/queries-raw-texts')\n",
    "    queries = {}\n",
    "    queries_paths = os.listdir(queries_path)\n",
    "    queries_paths.sort()\n",
    "    #print(documents_paths)\n",
    "    for filename in queries_paths:\n",
    "        file_path = os.path.join(queries_path, filename)\n",
    "        #print(filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        query = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        queries[id] = query.replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "    return queries\n",
    "\n",
    "queries = queries_reader()\n",
    "print(list(queries.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', ['Fabrication', 'music', 'instrument'])\n"
     ]
    }
   ],
   "source": [
    "def queries_tokenization(queries):\n",
    "    \"\"\"\n",
    "    :param documentos:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nltk_stop_words_en = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    #print(\"items\", queries.items())\n",
    "    tokenized_queries = {}\n",
    "    for key,doc in queries.items():\n",
    "        word_tok = nltk.word_tokenize(doc)\n",
    "        word_tok_sw = [token for token in word_tok if token not in nltk_stop_words_en]\n",
    "        nltk_lemmaList = [wordnet_lemmatizer.lemmatize(word) for word in word_tok_sw]\n",
    "        #print(nltk_lemmaList)\n",
    "        tokenized_queries[key] = nltk_lemmaList\n",
    "\n",
    "    return tokenized_queries\n",
    "\n",
    "\n",
    "\n",
    "tokenized_queries = queries_tokenization(queries)\n",
    "print(list(tokenized_queries.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', {'d254': 1.3322084124448144, 'd016': 1.280133266247014, 'd085': 0.7608038472948082, 'd185': 0.7210322829593981, 'd209': 0.7210322829593981, 'd060': 0.6881765238016224, 'd100': 0.6881765238016224, 'd153': 0.6881765238016224, 'd186': 0.6553207646438466, 'd006': 0.571404565150006, 'd215': 0.571404565150006, 'd099': 0.5193294189522057, 'd243': 0.5193294189522057, 'd004': 0.36051614147969907, 'd039': 0.36051614147969907, 'd065': 0.36051614147969907, 'd094': 0.36051614147969907, 'd130': 0.36051614147969907, 'd136': 0.36051614147969907, 'd152': 0.36051614147969907, 'd162': 0.36051614147969907, 'd164': 0.36051614147969907, 'd184': 0.36051614147969907, 'd195': 0.36051614147969907, 'd312': 0.36051614147969907, 'd316': 0.36051614147969907, 'd028': 0.3276603823219233, 'd038': 0.3276603823219233, 'd074': 0.3276603823219233, 'd082': 0.3276603823219233, 'd116': 0.3276603823219233, 'd170': 0.3276603823219233, 'd172': 0.3276603823219233, 'd212': 0.3276603823219233, 'd229': 0.3276603823219233, 'd234': 0.3276603823219233, 'd255': 0.3276603823219233, 'd265': 0.3276603823219233, 'd281': 0.3276603823219233, 'd284': 0.3276603823219233, 'd299': 0.3276603823219233, 'd315': 0.3276603823219233, 'd317': 0.3276603823219233, 'd329': 0.3276603823219233})\n"
     ]
    }
   ],
   "source": [
    "def basic_ranked_retrieval(queries,invertedIndex,documents,N):\n",
    "    \"\"\"\n",
    "    :param queries: tokenied queries in a dictorionary\n",
    "    :param invertedIndex: inverted index in a dictionary\n",
    "    :param documents: tokenized documents in a dictionary\n",
    "    :param N: total number of documents\n",
    "    :return: a dictionary with the scores for all the queries for each document\n",
    "    \"\"\"\n",
    "    scores= {}\n",
    "    query_scores_template = {}\n",
    "    for key, doc in documents.items():\n",
    "        query_scores_template[key] = 0\n",
    "\n",
    "    for query,tokens in queries.items():\n",
    "        query_scores = query_scores_template.copy()\n",
    "        for token in tokens:\n",
    "            if token in invertedIndex:\n",
    "                df = invertedIndex[token][\"freq\"]\n",
    "                idf = math.log10( N / df )\n",
    "                for docs in invertedIndex[token][\"posting\"]:\n",
    "                    tf = docs[1]\n",
    "                    tf_w = math.log10(1 + tf)\n",
    "                    #if docs[0] not in query_scores:\n",
    "                    #    query_scores[docs[0]] = 0\n",
    "                    docId = \"d{0:0=3d}\".format(docs[0])\n",
    "                    query_scores[docId] += tf_w*idf\n",
    "        clean_query_scores = { k : v for k,v in query_scores.items() if v != 0}\n",
    "        clean_query_scores = dict(sorted(clean_query_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "        scores[query] = clean_query_scores#query_scores\n",
    "\n",
    "    return scores\n",
    "\n",
    "RRI = basic_ranked_retrieval(tokenized_queries,index2, documentos, len(documentos))\n",
    "print(list(RRI.items())[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Método\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeScoreFile(RRI):\n",
    "    file_path = os.path.join(os.getcwd(), 'docs/answer_files/RRI-queries_results.tsv')\n",
    "    with open(file_path, 'wt') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        for query_id,scores in RRI.items():\n",
    "            scores_list = \"\"\n",
    "            for doc,score in scores.items():\n",
    "                scores_list+= doc +\":\"+str(round(score,4))+\",\"\n",
    "            tsv_writer.writerow([query_id,scores_list[:-1]])\n",
    "\n",
    "\n",
    "writeScoreFile(RRI)\n",
    "print(\"Archivo escrito\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def score(query, document_id, invertedIndex, documents):\n",
    "    \"\"\"\n",
    "    Computes to score for a query, document pair\n",
    "    :param query: tokenized query in a document\n",
    "    :param document_id: id of the doucument in \"dxxx\" notation\n",
    "    :param invertedIndex: inverted index in a dictionary\n",
    "    :param documents: tokenized documents in a dictionary\n",
    "    :return: the score of the query (decimal)\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    N = len(documents)\n",
    "\n",
    "    tokens = query[1]\n",
    "    for token in tokens:\n",
    "        token_in_index = invertedIndex.get(token, \"unknown_token\")\n",
    "        if token_in_index != \"unknown_token\":\n",
    "            token_posting = token_in_index[\"posting\"]\n",
    "            tf = 0\n",
    "            tf_w = 0\n",
    "            for doc_freq_pair in token_posting:\n",
    "                if doc_freq_pair[0] == document_id:\n",
    "                    tf = doc_freq_pair[1]\n",
    "                    tf_w = math.log10(1 + tf)\n",
    "                    break\n",
    "            df = token_in_index[\"freq\"]\n",
    "            idf = math.log10( N / df )\n",
    "            score += tf_w*idf\n",
    "    return  score\n",
    "\n",
    "\n",
    "query1 = list(tokenized_queries.items())[3]\n",
    "\n",
    "scoreQ1 = score(query1, 'd001', invertedIndex, documentos)\n",
    "print(scoreQ1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q01': {'d016': 5, 'd186': 4, 'd254': 5}, 'q02': {'d136': 2, 'd139': 2, 'd143': 4, 'd147': 2, 'd149': 2, 'd164': 4, 'd228': 4, 'd283': 4, 'd291': 4, 'd293': 4, 'd318': 2}, 'q03': {'d105': 2, 'd147': 3, 'd152': 3, 'd283': 4, 'd291': 4, 'd318': 2}, 'q04': {'d010': 3, 'd019': 2, 'd049': 2, 'd270': 3, 'd275': 3, 'd286': 2, 'd330': 2}, 'q06': {'d026': 4, 'd069': 2, 'd233': 3, 'd257': 2, 'd297': 3, 'd329': 5}, 'q07': {'d004': 3, 'd077': 3, 'd179': 3, 'd266': 2}, 'q08': {'d005': 4, 'd028': 3, 'd081': 2, 'd108': 3, 'd110': 4, 'd117': 3, 'd121': 2, 'd180': 2, 'd205': 2, 'd251': 5, 'd271': 3, 'd292': 2}, 'q09': {'d177': 2, 'd198': 3, 'd199': 5, 'd205': 3, 'd217': 2, 'd223': 2}, 'q10': {'d052': 2, 'd065': 3, 'd068': 2, 'd076': 3, 'd100': 2, 'd199': 4, 'd215': 2, 'd231': 4}, 'q12': {'d239': 4, 'd250': 4, 'd258': 3, 'd277': 4}, 'q13': {'d049': 4, 'd056': 4, 'd239': 2, 'd258': 2, 'd277': 2}, 'q14': {'d002': 2, 'd005': 3, 'd041': 3, 'd081': 4, 'd091': 4, 'd093': 3, 'd117': 2, 'd130': 3, 'd142': 2, 'd180': 3, 'd280': 3, 'd314': 3}, 'q16': {'d132': 3, 'd229': 2}, 'q17': {'d091': 2, 'd121': 4, 'd271': 4, 'd280': 2}, 'q18': {'d192': 4, 'd194': 3, 'd201': 3, 'd207': 2, 'd210': 3, 'd216': 2, 'd222': 2}, 'q19': {'d077': 2, 'd179': 5}, 'q22': {'d011': 3, 'd049': 2, 'd132': 2, 'd250': 2, 'd258': 2, 'd277': 2, 'd331': 2}, 'q23': {'d194': 2, 'd202': 2, 'd205': 2, 'd211': 3, 'd215': 2, 'd216': 2, 'd219': 5, 'd276': 4}, 'q24': {'d060': 2, 'd098': 2, 'd129': 3, 'd196': 2, 'd221': 2}, 'q25': {'d020': 3, 'd023': 2, 'd166': 3, 'd167': 3}, 'q26': {'d152': 5}, 'q27': {'d017': 2, 'd051': 2, 'd054': 5, 'd103': 5, 'd107': 2, 'd143': 2, 'd158': 2, 'd293': 4}, 'q28': {'d094': 3, 'd136': 5, 'd316': 3}, 'q29': {'d001': 3, 'd037': 5, 'd046': 3, 'd062': 4, 'd093': 2, 'd113': 4, 'd120': 3, 'd130': 3, 'd133': 4, 'd261': 3, 'd294': 2, 'd314': 4}, 'q32': {'d025': 5, 'd031': 2, 'd067': 3, 'd090': 4, 'd139': 3}, 'q34': {'d248': 5}, 'q36': {'d020': 3, 'd023': 3, 'd150': 3, 'd167': 2, 'd247': 4, 'd257': 4, 'd265': 4, 'd277': 4, 'd321': 3, 'd328': 3}, 'q37': {'d116': 3, 'd169': 5, 'd256': 2}, 'q38': {'d015': 2, 'd039': 3, 'd229': 2, 'd235': 4, 'd250': 2, 'd263': 2, 'd294': 4, 'd317': 2}, 'q40': {'d042': 5, 'd047': 5, 'd098': 3, 'd112': 3, 'd122': 3, 'd242': 4, 'd252': 2, 'd262': 3, 'd307': 3}, 'q41': {'d121': 3, 'd128': 3, 'd150': 5, 'd174': 3, 'd268': 2, 'd291': 4, 'd318': 5}, 'q42': {'d014': 2, 'd298': 5, 'd314': 2}, 'q44': {'d003': 2, 'd029': 4, 'd085': 2, 'd105': 2, 'd126': 2, 'd148': 2, 'd164': 2, 'd170': 2, 'd185': 3, 'd254': 2}, 'q45': {'d085': 4, 'd105': 5, 'd126': 3, 'd148': 2, 'd164': 3, 'd170': 3, 'd185': 3, 'd254': 2}, 'q46': {'d002': 2, 'd005': 2, 'd093': 2, 'd121': 3, 'd133': 3, 'd314': 2}}\n"
     ]
    }
   ],
   "source": [
    "def read_judgemnts_file():\n",
    "    \"\"\"\n",
    "    :return: the query scores in a dictionary\n",
    "    \"\"\"\n",
    "    document_path = os.path.join(os.getcwd(), 'docs/relevance-judgments.tsv')\n",
    "    tsv_file = open(document_path)\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    relevance = {}\n",
    "    for row in read_tsv:\n",
    "        documents = row[1].split(',')\n",
    "        query_relevance = {pair.split(':')[0] : int(pair.split(':')[1]) for pair in documents }\n",
    "        query_relevance = dict(sorted(query_relevance.items(), key=lambda item: item[0]))\n",
    "        relevance[row[0]] = query_relevance\n",
    "    return relevance\n",
    "\n",
    "\n",
    "relevance = read_judgemnts_file()\n",
    "print(relevance)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def precision_at_k(relevance: list, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    l = np.array(relevance[:k]).sum()/k\n",
    "    return l\n",
    "\n",
    "def recall_at_k(relevance: list, nr_relevant: int, k: int):\n",
    "    \"\"\"\n",
    "    :param relevance:\n",
    "    :param nr_relevant:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    l = np.array(relevance[:k]).sum()/nr_relevant\n",
    "    return l\n",
    "\n",
    "def average_precision(relevance,R):\n",
    "\n",
    "    length = len(relevance)\n",
    "    sum = 0\n",
    "    for i in range(length):\n",
    "        if relevance[i]:\n",
    "            sum += precision_at_k(relevance, i+1)\n",
    "    return sum / R if R!=0 else 0\n",
    "\n",
    "def mean_avg_precision(l):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    average = 0\n",
    "    i = 1\n",
    "    for lista,R in l:\n",
    "        print(i)\n",
    "        i+=1\n",
    "        print(\"lista\", lista)\n",
    "        print(\"R:\", R)\n",
    "        print(\"Encontró todos\", R==np.array(lista).sum())\n",
    "        print(\"precisionav\", average_precision(lista,R))\n",
    "        average+= average_precision(lista,R)\n",
    "    print(average)\n",
    "    mean = average / len(l)\n",
    "    return mean\n",
    "\n",
    "#l = [1,0,1,1,1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,1]\n",
    "#print(type(l))\n",
    "#prueba = average_precision(l)\n",
    "#print(prueba)\n",
    "\n",
    "def dcg_at_k(relevance, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    i =  0\n",
    "    for rel_i in relevance[: k]:\n",
    "        i+= 1\n",
    "        sum += rel_i/np.log2(max(i, 2))\n",
    "\n",
    "    return sum\n",
    "\n",
    "def ndcg_at_k(relevance, rel_sorted, k):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    #rel_sorted = sorted(relevance, reverse=True)\n",
    "    max = dcg_at_k(rel_sorted, k)\n",
    "    real = dcg_at_k(relevance, k)\n",
    "\n",
    "    return real/ max if max != 0 else 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_binary_score(query_tuple,relevance):\n",
    "    query = query_tuple[0]\n",
    "    ranking = query_tuple[1]\n",
    "    binary_score = []\n",
    "    M = len(relevance[query])\n",
    "    i=1;\n",
    "    for document, score in ranking.items():\n",
    "        if i>M:\n",
    "            break\n",
    "        if document in relevance[query]:\n",
    "            binary_score.append(1)\n",
    "        else:\n",
    "            binary_score.append(0)\n",
    "        i += 1\n",
    "    #print(binary_score)\n",
    "    return binary_score, M"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_binary_score_extended(query_tuple,relevance):\n",
    "    query = query_tuple[0]\n",
    "    ranking = query_tuple[1]\n",
    "    binary_score = []\n",
    "    M = len(relevance[query])\n",
    "    i=0;\n",
    "    for document, score in ranking.items():\n",
    "        if i==M:\n",
    "            break\n",
    "        if document in relevance[query]:\n",
    "            binary_score.append(1)\n",
    "            i += 1\n",
    "        else:\n",
    "            binary_score.append(0)\n",
    "    #print(binary_score)\n",
    "    return binary_score, M\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def precision_for_RRI(RRI,relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    precisions = {}\n",
    "    for query in RRI.items():\n",
    "        binary_score, M = make_binary_score(query,relevance)\n",
    "        precisions[query[0]] = precision_at_k(binary_score,M)\n",
    "    return precisions\n",
    "\n",
    "precisions = precision_for_RRI(RRI,relevance)\n",
    "print(precisions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recall_for_RRI(RRI,relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    recalls = {}\n",
    "    for query in RRI.items():\n",
    "        binary_score, M = make_binary_score(query,relevance)\n",
    "        recalls[query[0]] = recall_at_k(binary_score,M,M)\n",
    "    return recalls\n",
    "\n",
    "recalls = recall_for_RRI(RRI,relevance)\n",
    "print(recalls)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 1, 0, 0, 0, 0, 0, 0, 1], 3), ([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 11), ([1, 1, 1, 1, 1, 1], 6), ([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1], 7), ([1, 1, 1, 1, 1, 0, 1], 6), ([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 4), ([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 12), ([1, 1, 1, 1, 0, 1, 1], 6), ([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 8), ([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 4), ([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], 5), ([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], 12), ([0, 1, 0, 0, 1], 2), ([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 4), ([1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 7), ([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 2), ([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 7), ([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 8), ([0, 0], 5), ([1, 0, 1, 1, 0, 0, 0, 1], 4), ([1], 1), ([1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 8), ([1, 1, 0, 0, 0, 0, 0, 0, 0, 1], 3), ([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 12), ([1, 1, 1, 1, 1], 5), ([1], 1), ([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], 10), ([1, 0, 0, 1, 0, 0, 0, 0, 0], 3), ([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], 8), ([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1], 9), ([1, 1, 1, 1, 1, 1], 7), ([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 3), ([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1], 10), ([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 8), ([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], 6)]\n",
      "1\n",
      "lista [1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 3\n",
      "Encontró todos True\n",
      "precisionav 0.7777777777777778\n",
      "2\n",
      "lista [1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 11\n",
      "Encontró todos True\n",
      "precisionav 0.6923180429196472\n",
      "3\n",
      "lista [1, 1, 1, 1, 1, 1]\n",
      "R: 6\n",
      "Encontró todos True\n",
      "precisionav 1.0\n",
      "4\n",
      "lista [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 7\n",
      "Encontró todos True\n",
      "precisionav 0.9285714285714286\n",
      "5\n",
      "lista [1, 1, 1, 1, 1, 0, 1]\n",
      "R: 6\n",
      "Encontró todos True\n",
      "precisionav 0.9761904761904762\n",
      "6\n",
      "lista [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R: 4\n",
      "Encontró todos False\n",
      "precisionav 0.25\n",
      "7\n",
      "lista [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R: 12\n",
      "Encontró todos False\n",
      "precisionav 0.813893577686681\n",
      "8\n",
      "lista [1, 1, 1, 1, 0, 1, 1]\n",
      "R: 6\n",
      "Encontró todos True\n",
      "precisionav 0.9484126984126983\n",
      "9\n",
      "lista [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 8\n",
      "Encontró todos True\n",
      "precisionav 0.4073759573759574\n",
      "10\n",
      "lista [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 4\n",
      "Encontró todos True\n",
      "precisionav 0.7954545454545454\n",
      "11\n",
      "lista [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "R: 5\n",
      "Encontró todos True\n",
      "precisionav 0.6589247311827957\n",
      "12\n",
      "lista [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 12\n",
      "Encontró todos True\n",
      "precisionav 0.443230441056528\n",
      "13\n",
      "lista [0, 1, 0, 0, 1]\n",
      "R: 2\n",
      "Encontró todos True\n",
      "precisionav 0.45\n",
      "14\n",
      "lista [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R: 4\n",
      "Encontró todos False\n",
      "precisionav 0.6875\n",
      "15\n",
      "lista [1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R: 7\n",
      "Encontró todos False\n",
      "precisionav 0.8129251700680271\n",
      "16\n",
      "lista [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R: 2\n",
      "Encontró todos False\n",
      "precisionav 0.5\n",
      "17\n",
      "lista [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 7\n",
      "Encontró todos True\n",
      "precisionav 0.5390168970814132\n",
      "18\n",
      "lista [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
      "R: 8\n",
      "Encontró todos True\n",
      "precisionav 0.29173325478915074\n",
      "19\n",
      "lista [0, 0]\n",
      "R: 5\n",
      "Encontró todos False\n",
      "precisionav 0.0\n",
      "20\n",
      "lista [1, 0, 1, 1, 0, 0, 0, 1]\n",
      "R: 4\n",
      "Encontró todos True\n",
      "precisionav 0.7291666666666666\n",
      "21\n",
      "lista [1]\n",
      "R: 1\n",
      "Encontró todos True\n",
      "precisionav 1.0\n",
      "22\n",
      "lista [1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R: 8\n",
      "Encontró todos False\n",
      "precisionav 0.5311898749398749\n",
      "23\n",
      "lista [1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 3\n",
      "Encontró todos True\n",
      "precisionav 0.7666666666666666\n",
      "24\n",
      "lista [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R: 12\n",
      "Encontró todos False\n",
      "precisionav 0.46327160493827163\n",
      "25\n",
      "lista [1, 1, 1, 1, 1]\n",
      "R: 5\n",
      "Encontró todos True\n",
      "precisionav 1.0\n",
      "26\n",
      "lista [1]\n",
      "R: 1\n",
      "Encontró todos True\n",
      "precisionav 1.0\n",
      "27\n",
      "lista [1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 10\n",
      "Encontró todos False\n",
      "precisionav 0.4072216790584518\n",
      "28\n",
      "lista [1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "R: 3\n",
      "Encontró todos False\n",
      "precisionav 0.5\n",
      "29\n",
      "lista [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 8\n",
      "Encontró todos True\n",
      "precisionav 0.3839949633699634\n",
      "30\n",
      "lista [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1]\n",
      "R: 9\n",
      "Encontró todos True\n",
      "precisionav 0.8491181657848323\n",
      "31\n",
      "lista [1, 1, 1, 1, 1, 1]\n",
      "R: 7\n",
      "Encontró todos False\n",
      "precisionav 0.8571428571428571\n",
      "32\n",
      "lista [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 3\n",
      "Encontró todos True\n",
      "precisionav 0.7023809523809524\n",
      "33\n",
      "lista [1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1]\n",
      "R: 10\n",
      "Encontró todos True\n",
      "precisionav 0.8045328282828283\n",
      "34\n",
      "lista [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 8\n",
      "Encontró todos True\n",
      "precisionav 0.8771645021645023\n",
      "35\n",
      "lista [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "R: 6\n",
      "Encontró todos True\n",
      "precisionav 0.6263227513227513\n",
      "23.47149851128574\n",
      "0.6706142431795926\n"
     ]
    }
   ],
   "source": [
    "def map_for_RRI(RRI,relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    for query in RRI.items():\n",
    "        binary_score, M = make_binary_score_extended(query,relevance)\n",
    "        precisions.append((binary_score,M))\n",
    "    print(precisions)\n",
    "    map = mean_avg_precision(precisions)\n",
    "    return map\n",
    "\n",
    "map = map_for_RRI(RRI,relevance)\n",
    "print(map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_non_binary_score(query_tuple,relevance):\n",
    "    query = query_tuple[0]\n",
    "    ranking = query_tuple[1]\n",
    "    non_binary_score = []\n",
    "    M = len(relevance[query])\n",
    "    i=1;\n",
    "    for document, score in ranking.items():\n",
    "        if i>M:\n",
    "            break\n",
    "        if document in relevance[query]:\n",
    "            non_binary_score.append(relevance[query][document])\n",
    "        else:\n",
    "            non_binary_score.append(0)\n",
    "        i += 1\n",
    "    rel_sorted = [rel for doc,rel in relevance[query].items() ]\n",
    "    rel_sorted = sorted(rel_sorted, reverse=True)\n",
    "    return non_binary_score, rel_sorted, M\n",
    "\n",
    "query1 = list(RRI.items())[0]\n",
    "prueba = make_non_binary_score(query1,relevance)\n",
    "print(prueba)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ndcg_for_RRI(RRI,relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    ndcgs = {}\n",
    "    for query in RRI.items():\n",
    "        non_binary_score, rel_sorted, M  = make_non_binary_score(query,relevance)\n",
    "        #print(non_binary_score)\n",
    "        ndcgs[query[0]] = ndcg_at_k(non_binary_score, rel_sorted, M)\n",
    "    return ndcgs\n",
    "\n",
    "ndcg = ndcg_for_RRI(RRI,relevance)\n",
    "print(ndcg)\n",
    "\n",
    "av_ndgc = 0\n",
    "for key,val in ndcg.items():\n",
    "    av_ndgc += val\n",
    "print(av_ndgc/len(ndcg))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}