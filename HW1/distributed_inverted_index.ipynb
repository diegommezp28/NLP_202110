{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T01:24:24.836800Z",
     "start_time": "2021-03-13T01:24:24.821118Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import findspark\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:50:01.484675Z",
     "start_time": "2021-03-12T22:49:58.220222Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización de SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:50:06.431885Z",
     "start_time": "2021-03-12T22:50:01.486480Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "localizacion_spark = '/opt/spark-2.4.5'\n",
    "findspark.init(localizacion_spark)\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# numero de cores: 4, memoria ram que se le permite a spark usar: 7GB\n",
    "spark_configurations = SparkConf()\\\n",
    "    .setMaster('local[4]')\\\n",
    "    .setAppName('Tarea_1')\\\n",
    "    .set(\"spark.driver.memory\", \"7g\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf = spark_configurations)\n",
    "\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master('local[4]')\\\n",
    "    .appName(\"Tarea_1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T23:18:58.230289Z",
     "start_time": "2021-03-12T23:18:52.763807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 'Well, I Didn’t Know it was Hard – Happy Birthday Ivan Sutherland.Ivan Sutherland’s Sketchpad (1963) Happy Birthday 74th Ivan Sutherland! The American computer scientist and Internet pioneer has received the Turing Award from the Association for Computing Machinery in 1988 for his invention of Sketchpad, an early predecessor to the sort of graphical user interface that has become ubiquitous in personal computers today. Sketchpad could accept constraints and specified relationships among segments and arcs, including the diameter of arcs. It could draw both horizontal and vertical lines and combine them into figures and shapes. Figures could be copied, moved, rotated, or resized, retaining their basic properties. Sketchpad also had the first window-drawing program and clipping algorithm, which allowed zooming. When asked, “How could you possibly have done the first interactive graphics program, the first non-procedural programming language, the first object oriented software system, all in one year?” Ivan replied: “Well, I didn’t know it was hard.” (Alan Kay, Doing with Images Makes Symbols, 1987) In 1968 he co-founded Evans and Sutherland with his friend and colleague David C. Evans. The company has done pioneering work in the field of real-time hardware, accelerated 3D computer graphics, and printer languages. At yovisto, you might watch Ivan Sutherland together with his brother Bert reminiscing about their collective 100 plus years with computers and electronics in an interview from 2004.')\n"
     ]
    }
   ],
   "source": [
    "def documentReaderSpark(data_path:str, sparkContext):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    documents = sc\\\n",
    "        .wholeTextFiles(data_path,\n",
    "                        minPartitions=None, \n",
    "                        use_unicode=True)\\\n",
    "        .map(lambda s: (re.search('<public publicId=\"(.*?)\" uri=\"(.*?)\" />',s[1]).group(1),\n",
    "                        s[1].replace(\"\\n\",\"\")\\\n",
    "                            .replace(\"\\xa0\",\" \"))\n",
    "            )\\\n",
    "        .map(lambda s: (int(s[0].replace('d','')),re.search('<raw><!\\[CDATA\\[(.*?)\\]\\]></raw>',s[1]).group(1)))\n",
    "    print(documents.collect()[0])\n",
    "    return documents\n",
    "documents_path = os.path.join('docs', 'docs-raw-texts')\n",
    "documents = documentReaderSpark(documents_path, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T23:19:23.029289Z",
     "start_time": "2021-03-12T23:19:19.448964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('Well', 223), 1), (('I', 223), 1), (('Didn', 223), 1), (('Know', 223), 1), (('Hard', 223), 1), (('Happy', 223), 1), (('Birthday', 223), 1), (('Ivan', 223), 1), (('Sutherland', 223), 1), (('Sketchpad', 223), 1), (('1963', 223), 1), (('Happy', 223), 1), (('Birthday', 223), 1), (('74th', 223), 1), (('Ivan', 223), 1), (('Sutherland', 223), 1), (('The', 223), 1), (('American', 223), 1), (('computer', 223), 1), (('scientist', 223), 1), (('Internet', 223), 1), (('pioneer', 223), 1), (('received', 223), 1), (('Turing', 223), 1), (('Award', 223), 1), (('Association', 223), 1), (('Computing', 223), 1), (('Machinery', 223), 1), (('1988', 223), 1), (('invention', 223), 1), (('Sketchpad', 223), 1), (('early', 223), 1), (('predecessor', 223), 1), (('sort', 223), 1), (('graphical', 223), 1), (('user', 223), 1), (('interface', 223), 1), (('become', 223), 1), (('ubiquitous', 223), 1), (('personal', 223), 1), (('computer', 223), 1), (('today', 223), 1), (('Sketchpad', 223), 1), (('could', 223), 1), (('accept', 223), 1), (('constraint', 223), 1), (('specified', 223), 1), (('relationship', 223), 1), (('among', 223), 1), (('segment', 223), 1), (('arc', 223), 1), (('including', 223), 1), (('diameter', 223), 1), (('arc', 223), 1), (('It', 223), 1), (('could', 223), 1), (('draw', 223), 1), (('horizontal', 223), 1), (('vertical', 223), 1), (('line', 223), 1), (('combine', 223), 1), (('figure', 223), 1), (('shape', 223), 1), (('Figures', 223), 1), (('could', 223), 1), (('copied', 223), 1), (('moved', 223), 1), (('rotated', 223), 1), (('resized', 223), 1), (('retaining', 223), 1), (('basic', 223), 1), (('property', 223), 1), (('Sketchpad', 223), 1), (('also', 223), 1), (('first', 223), 1), (('program', 223), 1), (('clipping', 223), 1), (('algorithm', 223), 1), (('allowed', 223), 1), (('zooming', 223), 1), (('When', 223), 1), (('asked', 223), 1), (('How', 223), 1), (('could', 223), 1), (('possibly', 223), 1), (('done', 223), 1), (('first', 223), 1), (('interactive', 223), 1), (('graphic', 223), 1), (('program', 223), 1), (('first', 223), 1), (('programming', 223), 1), (('language', 223), 1), (('first', 223), 1), (('object', 223), 1), (('oriented', 223), 1), (('software', 223), 1), (('system', 223), 1), (('one', 223), 1), (('year', 223), 1), (('Ivan', 223), 1), (('replied', 223), 1), (('Well', 223), 1), (('I', 223), 1), (('know', 223), 1), (('Alan', 223), 1), (('Kay', 223), 1), (('Doing', 223), 1), (('Images', 223), 1), (('Makes', 223), 1), (('Symbols', 223), 1), (('1987', 223), 1), (('In', 223), 1), (('1968', 223), 1), (('Evans', 223), 1), (('Sutherland', 223), 1), (('friend', 223), 1), (('colleague', 223), 1), (('David', 223), 1), (('Evans', 223), 1), (('The', 223), 1), (('company', 223), 1), (('done', 223), 1), (('pioneering', 223), 1), (('work', 223), 1), (('field', 223), 1), (('hardware', 223), 1), (('accelerated', 223), 1), (('3D', 223), 1), (('computer', 223), 1), (('graphic', 223), 1), (('printer', 223), 1), (('language', 223), 1), (('At', 223), 1), (('yovisto', 223), 1), (('might', 223), 1), (('watch', 223), 1), (('Ivan', 223), 1), (('Sutherland', 223), 1), (('together', 223), 1), (('brother', 223), 1), (('Bert', 223), 1), (('reminiscing', 223), 1), (('collective', 223), 1), (('100', 223), 1), (('plus', 223), 1), (('year', 223), 1), (('computer', 223), 1), (('electronics', 223), 1), (('interview', 223), 1), (('2004', 223), 1)]\n"
     ]
    }
   ],
   "source": [
    "def tokenizationSpark(documents_rdd, use_spacy=False):\n",
    "    \"\"\"\n",
    "    :param documentos:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if use_spacy:\n",
    "        nlp_spacy_en = spacy.load('en_core_web_sm')\n",
    "        nltk_lemmaList = documents_rdd\\\n",
    "            .map(lambda s : (s[0], nlp_spacy_en(s[1])))\\\n",
    "            .flatMap(lambda s : [(lemma,s[0]) for lemma in [token.lemma_ for token in s[1]]\n",
    "                                 if nlp_spacy_en.vocab[lemma].is_stop == False\n",
    "                                 and nlp_spacy_en.vocab[lemma].is_punct == False])\\\n",
    "            .map(lambda t : ((t[0], t[1]),1))\n",
    "    else:\n",
    "        nltk_stop_words_en = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "        p_stemmer = nltk.stem.porter.PorterStemmer()\n",
    "        wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "        nltk_lemmaList = documents_rdd\\\n",
    "            .map(lambda s : (s[0], [word for word in nltk.word_tokenize(s[1]) \n",
    "                                    if word.isalnum()]))\\\n",
    "            .flatMap(lambda s : [(token,s[0]) for token in s[1] \n",
    "                                 if token not in nltk_stop_words_en])\\\n",
    "            .map(lambda s : ((wordnet_lemmatizer.lemmatize(s[0]), s[1]),1))\n",
    "    \n",
    "    print(nltk_lemmaList.filter(lambda x : 223==x[0][1]).collect())\n",
    "    return nltk_lemmaList\n",
    "tokenized_docs = tokenizationSpark(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T23:08:38.079471Z",
     "start_time": "2021-03-12T23:08:37.997230Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_docs.saveAsPickleFile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T01:26:08.694451Z",
     "start_time": "2021-03-13T01:25:56.863248Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def makeInvertedIndexSpark(tokenized_documents_rdd):\n",
    "    \"\"\"\n",
    "    :param documentos:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    inverted_index = tokenized_documents_rdd\\\n",
    "        .reduceByKey(lambda a, b : a+b )\\\n",
    "        .map(lambda s : (s[0][0], [[s[0][1],s[1]]]))\\\n",
    "        .reduceByKey(lambda a, b : sorted(a+b) )\\\n",
    "        .sortBy(lambda s : s[0])\\\n",
    "        .map(lambda s :  { s[0]: {'freq' : len(s[1]), 'posting':s[1]}})\\\n",
    "        .collect()\n",
    "    respuesta = {}\n",
    "    for item in inverted_index:\n",
    "        respuesta.update(item)\n",
    "    with open(os.path.join('docs','inverted_index.pkl'), 'wb') as handle:\n",
    "        pickle.dump(respuesta, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return respuesta\n",
    "inverted_index = makeInvertedIndexSpark(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T01:29:51.453449Z",
     "start_time": "2021-03-13T01:29:50.713054Z"
    }
   },
   "outputs": [],
   "source": [
    "# se termina la sesion de spark\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "410px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
