{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from smart_open import smart_open\n",
    "import nltk\n",
    "from xml.dom import minidom\n",
    "from xml.etree import cElementTree as ElementTree\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gensim Corpus and Tf.idf Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Corpus and Tf.Idf Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', 'William Beaumont and the Human Digestion William Beaumont and the Human Digestion.  William Beaumont: Physiology of digestion Image Source.  On November 21, 1785, US-American surgeon William Beaumont was born. He became best known as “Father of Gastric Physiology” following his research on human digestion. William Beaumont was born in Lebanon, Connecticut and became a physician. He served as a surgeon’s mate in the Army during the War of 1812. He opened a private practice in Plattsburgh, New York, but rejoined the Army as a surgeon in 1819. Beaumont was stationed at Fort Mackinac on Mackinac Island in Michigan in the early 1820s when it existed to protect the interests of the American Fur Company. The fort became the refuge for a wounded 19-year-old French-Canadian fur trader named Alexis St. Martin when a shotgun went off by accident in the American Fur Company store at close range June 6th, 1822. St. Martin’s wound was quite serious because his stomach was perforated and several ribs were broken. Nobody really expected that the young man would survive but he really did. The skin around St. Martin’s wound fused to the hole in his stomach, leaving a permanent opening – a gastric fistula. [1] Beaumont quickly noticed that there was much research potential. Back then, not too much was known about the digestive system. In order to gain more information, Beaumont performed numerous experiments on St. Martin over a period of eight years. The experiments must have been really uncomfortable for the man, who was inserted bits of different foods tied to strings through the hole in his stomach, pulling them out periodically to observe digestion. Beaumont also removed gastric juice, examining it to better understand its nature. Beaumont became the “Father of Gastric Physiology” and his findings were published in the book “Experiments and Observations on the Gastric Juice and the Physiology of Digestion” in 1833. The work is now considered as the basis of much of the early knowledge on digestion. William Beaumont discovered that hydrochloric acid is the main chemical responsible for breaking down food and he suggested that another important digestive chemical, which is now known as pepsin. He suggested that digestion is a chemical process, not merely a mechanical one caused by stomach muscle movement. Also, Beaumont gave insights on how emotions, temperature, and physical activity can affect digestion. Beaumont’s famous patient, St. Martin, outlived the scientist even though his wound never completely healed. He had several children and died at the age of 83. [2] At yovisto, you may be interested in a video lecture on The Digestive System.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def documentReader(path, queries = False):\n",
    "    \"\"\"\n",
    "    This method reads the documents\n",
    "    :return: Dictionary of documents {dXXX: content of document dXXX}\n",
    "    \"\"\"\n",
    "    documents_path = os.path.join(os.getcwd(), path)\n",
    "    documentos = {}\n",
    "    for filename in os.listdir(documents_path):\n",
    "        file_path = os.path.join(documents_path, filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        title = '' if queries else xmldoc.getElementsByTagName('fileDesc')[0].attributes['title'].value\n",
    "        data = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        documentos[id] = (title + ' ' + data).replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "    return documentos\n",
    "\n",
    "documentos = documentReader('docs/docs-raw-texts')\n",
    "NRO_DOCS = len(documentos)\n",
    "DOCS_IDs = list(documentos.keys())\n",
    "\n",
    "print(list(documentos.items())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documentos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-693ebe3ab754>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mdocDict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdoc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdocumentos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m     \u001B[0mdocDict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'documentos' is not defined"
     ]
    }
   ],
   "source": [
    "p = PorterStemmer()\n",
    "def process(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the text with gensim. Removes stopwords and uses a\n",
    "    stemmer.\n",
    "    :param text: the text to be tokenized\n",
    "    :return: the tokenized token\n",
    "    \"\"\"\n",
    "    doc_nor = text.lower()\n",
    "    doc_sw = remove_stopwords(doc_nor)\n",
    "    doc_stem = p.stem_sentence(doc_sw)\n",
    "    return nltk.word_tokenize(doc_stem)\n",
    "\n",
    "docDict = []\n",
    "\n",
    "\"\"\"\n",
    "Tokenizes each document in the document lists, returns\n",
    "an array of tokenized documents.\n",
    "\"\"\"\n",
    "for key, doc in documentos.items():\n",
    "    docDict.append(process(doc))\n",
    "\n",
    "docDict[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creates the dictionary with the gensim corpora object\n",
    "\"\"\"\n",
    "dictionary = corpora.Dictionary(docDict)\n",
    "dictionary.save('docs/midict.dict')\n",
    "print(dictionary.token2id['information'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##  Market Matrix format\n",
    "# Builds the corpus from big file and saves it in a file\n",
    "class MyCorpus():\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "    def __iter__(self):\n",
    "        for key, doc in self.documents.items():\n",
    "            yield dictionary.doc2bow(process(doc))\n",
    "\n",
    "corpus_memory_friendly = MyCorpus(documentos)\n",
    "corpora.MmCorpus.serialize(\"docs/corpus.mm\",corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Read Maket Matrix format from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 20.0), (1, 21.0), (2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0), (8, 1.0), (9, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "corpus = corpora.MmCorpus(\"docs/corpus.mm\")\n",
    "for doc in corpus:\n",
    "    print(doc[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Build tf.idf model from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('docs/midict.dict')\n",
    "corpus = corpora.MmCorpus('docs/corpus.mm')\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(241, 1), (5809, 1)]\n",
      "[(241, 0.2642196547502339), (5809, 0.9644625311766483)]\n"
     ]
    }
   ],
   "source": [
    "#Test to verify correct reading\n",
    "query = \"Machine learning\"\n",
    "query_doc_bow = dictionary.doc2bow(process(query)) # Important: Same corpus preprocess\n",
    "print(query_doc_bow)\n",
    "print(tfidf[query_doc_bow])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Make similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(tfidf[corpus])\n",
    "index.save('docs/similmatrix.index')\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Querying and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity.load('docs/similmatrix.index')\n",
    "sims = index[tfidf[query_doc_bow]]\n",
    "print(list(enumerate(sims))[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read and proccess queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def queries_reader():\n",
    "    \"\"\"\n",
    "    This method reads the queries\n",
    "    :return: Dictionary of queries {qYY: content of query qYY}\n",
    "    \"\"\"\n",
    "    queries_path = os.path.join(os.getcwd(), 'docs/queries-raw-texts')\n",
    "    queries = {}\n",
    "    queries_paths = os.listdir(queries_path)\n",
    "    queries_paths.sort()\n",
    "    #print(documents_paths)\n",
    "    query_index = []\n",
    "    for filename in queries_paths:\n",
    "        file_path = os.path.join(queries_path, filename)\n",
    "        #print(filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        query = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        queries[id] = query.replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "        query_index.append(id)\n",
    "    return queries, query_index\n",
    "\n",
    "queries, query_index = queries_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d016', 'd259', 'd254', 'd186', 'd085', 'd209', 'd215', 'd170', 'd153', 'd008', 'd185', 'd154', 'd163', 'd315', 'd296', 'd060', 'd089', 'd243', 'd004', 'd006', 'd162', 'd100', 'd094', 'd179', 'd145', 'd059', 'd039', 'd329', 'd299', 'd273', 'd312', 'd028', 'd311', 'd082', 'd281', 'd255', 'd065', 'd074', 'd317', 'd265', 'd229', 'd275', 'd130', 'd021', 'd077', 'd152', 'd195', 'd052', 'd316', 'd038', 'd164', 'd024', 'd123', 'd136', 'd184']\n"
     ]
    }
   ],
   "source": [
    "def queries_evaluation(queries):\n",
    "    \"\"\"\n",
    "    Queries tokenization using gensim and queries evaluation with\n",
    "    created index and tfidf model.\n",
    "    :param queries in a dictionary, {qYY: content of query qYY}\n",
    "    :return: Dictionary of queries en the ranked relevant documents\n",
    "    {'qXX': ['dYYY', 'dZZZ',...]}\n",
    "    \"\"\"\n",
    "    queries_rank = {}\n",
    "    for idq, query in queries.items():\n",
    "        query_doc_bow = dictionary.doc2bow(process(query))\n",
    "        sims = index[tfidf[query_doc_bow]]\n",
    "        sorted_vals = sorted(list(enumerate(sims)), key=lambda x: x[1], reverse=True)\n",
    "        clean_query_scores = [ \"d{0:0=3d}\".format(id+1) for id,v in sorted_vals if v != 0]\n",
    "        queries_rank[idq] = clean_query_scores\n",
    "    return queries_rank\n",
    "\n",
    "\n",
    "queries_ranking = queries_evaluation(queries)\n",
    "print(queries_ranking[\"q01\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_judgemnts_file():\n",
    "    \"\"\"\n",
    "    Lee el archivo de relevancia de los jueces\n",
    "    :return: Diccionario con pares key: value, donde el key es el id de cada query y el value\n",
    "    es otro doccionario con las ids de los docs relevantes para esa query ordenados en forma creciente.\n",
    "    \"\"\"\n",
    "    document_path = os.path.join(os.getcwd(), 'docs/relevance-judgments.tsv')\n",
    "    tsv_file = open(document_path)\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    relevance = {}\n",
    "    for row in read_tsv:\n",
    "        documents = row[1].split(',')\n",
    "        query_relevance = {pair.split(':')[0] : pair.split(':')[1] for pair in documents }\n",
    "        query_relevance = dict(sorted(query_relevance.items(), key=lambda item: item[0]))\n",
    "        relevance[row[0]] = query_relevance\n",
    "    return relevance\n",
    "\n",
    "\n",
    "relevance = read_judgemnts_file()\n",
    "print(relevance['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def make_binary_result(results, relevant_res):\n",
    "    \"\"\"\n",
    "    Este método toma los resultados crudos obtenidos para las queries (Para cada query la lista de documentos ordenaos\n",
    "    por relevancia), devuelve 3 representaciones de estos resultados. La primera es la representacion binaria at K.\n",
    "    Que es del mismo tamaño que el número de documentos relevantes. La segunda es esta misma lista pero con la escala\n",
    "    dada por el archivo de evaluación. La tercera está destinada al cálculo del MAP, tiene la representación binaria\n",
    "    hasta que salgan todos los documentos relevantes o simplemente de todos los documentos, además en su segundo\n",
    "    componente tiene el número de documentos relevantes que deberían salir en los resultados según el archivo de\n",
    "    evaluación.\n",
    "    :param results: Diccionario con resultados crudos de cada query. Ej: {'q01': ['d254', 'd016', 'd153', ...]}\n",
    "    :param relevant_res: Las 3 representaciones antes mencionadas\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bin_relevant = {}\n",
    "    rel_scale_repr = {}\n",
    "    map_relevant_docs = {}\n",
    "    for query, relevant_docs in relevant_res.items():\n",
    "        bin_repr = []\n",
    "        scaled_repr = []\n",
    "        map_repr = []\n",
    "        M = len(relevant_docs)\n",
    "        for doc_id, rel_scale in relevant_docs.items():\n",
    "            bin = 1 if doc_id in results[query][:M] else 0\n",
    "            bin_repr.append(bin)\n",
    "            scaled_repr.append(bin * int(rel_scale))\n",
    "        i = 0\n",
    "        for doc_id in results[query]:\n",
    "            if i < M:\n",
    "                map_bin = 1 if doc_id in relevant_res[query] else 0\n",
    "                i += map_bin\n",
    "                map_repr.append(map_bin)\n",
    "        bin_relevant[query] = bin_repr\n",
    "        rel_scale_repr[query] = scaled_repr\n",
    "        map_relevant_docs[query] = [map_repr, M]\n",
    "    return bin_relevant, rel_scale_repr, map_relevant_docs\n",
    "\n",
    "bin_results, scaled_results, map_relevant_docs = make_binary_result(results, relevance)\n",
    "print(bin_results['q01'])\n",
    "print(scaled_results['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0.35468253968253965"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Primeros 5 documentos devueltos como relevantes para q01: \\n', results['q01'][:5])\n",
    "print('Documentos relevantes para q01 según jueces: \\n' , relevance['q01'])\n",
    "print('Representación binaria de q01, hasta el último doc relevante: \\n' ,map_relevant_docs['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of IR metrics functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(relevance: list, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    l = np.array(relevance[:k]).sum()/k\n",
    "    return l\n",
    "\n",
    "def recall_at_k(relevance: list, nr_relevant: int, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    l = np.array(relevance[:k]).sum()/nr_relevant\n",
    "    return l\n",
    "\n",
    "def average_precision(relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    length = len(relevance[0])\n",
    "    sum = 0\n",
    "    for i in range(length):\n",
    "        if relevance[0][i]:\n",
    "            sum += precision_at_k(relevance[0], i+1)\n",
    "    if np.array(relevance[0]).sum()==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum / relevance[1]\n",
    "\n",
    "def mean_avg_precision(l):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    mean = np.array([ average_precision(lista) for lista in l]).mean()\n",
    "    return mean\n",
    "\n",
    "mean_avg_precision([[[0, 0, 0, 0, 0, 0, 1], 1], [[0, 0, 0, 1, 1], 2], [[0, 1, 0, 1, 1, 1, 1], 5]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def dcg_at_k(relevance, k: int):\n",
    "    \"\"\"\n",
    "    Calcula el DCG at K de un vector binario representando los resultados relevantes para una query.\n",
    "    :param relevance: Vector binario\n",
    "    :return: DCG at K de nuestra query\n",
    "    \"\"\"\n",
    "\n",
    "    sum = 0\n",
    "    i =  0\n",
    "    for rel_i in relevance[: k]:\n",
    "        i+= 1\n",
    "        sum += rel_i/np.log2(max(i, 2))\n",
    "\n",
    "    return sum\n",
    "\n",
    "dcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)\n",
    "\n",
    "def ndcg_at_k(relevance, k):\n",
    "    \"\"\"\n",
    "    Calcula el ndcg at k de un vector binario\n",
    "    :return: NDCG at K.\n",
    "    \"\"\"\n",
    "    rel_sorted = sorted(relevance, reverse=True)\n",
    "    max = dcg_at_k(rel_sorted, k)\n",
    "    real = dcg_at_k(relevance, k)\n",
    "\n",
    "    return real/ max\n",
    "\n",
    "\n",
    "ndcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-b9586156bffd>:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return real/ max\n"
     ]
    },
    {
     "data": {
      "text/plain": "          P@M       R@M    NDCG@M\nq01  0.666667  0.666667  0.815465\nq02  0.363636  0.363636  0.428656\nq03  0.500000  0.500000  0.567635\nq04  0.714286  0.714286  0.928210\nq06  0.666667  0.666667  0.691704\nq07  0.500000  0.500000  0.800000\nq08  0.666667  0.666667  0.837297\nq09  0.833333  0.833333  0.880115\nq10  0.375000  0.375000  0.577633\nq12  1.000000  1.000000  0.989111",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>P@M</th>\n      <th>R@M</th>\n      <th>NDCG@M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>q01</th>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.815465</td>\n    </tr>\n    <tr>\n      <th>q02</th>\n      <td>0.363636</td>\n      <td>0.363636</td>\n      <td>0.428656</td>\n    </tr>\n    <tr>\n      <th>q03</th>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.567635</td>\n    </tr>\n    <tr>\n      <th>q04</th>\n      <td>0.714286</td>\n      <td>0.714286</td>\n      <td>0.928210</td>\n    </tr>\n    <tr>\n      <th>q06</th>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.691704</td>\n    </tr>\n    <tr>\n      <th>q07</th>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>q08</th>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.837297</td>\n    </tr>\n    <tr>\n      <th>q09</th>\n      <td>0.833333</td>\n      <td>0.833333</td>\n      <td>0.880115</td>\n    </tr>\n    <tr>\n      <th>q10</th>\n      <td>0.375000</td>\n      <td>0.375000</td>\n      <td>0.577633</td>\n    </tr>\n    <tr>\n      <th>q12</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.989111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(recall_at_k(bin_results['q01'], 3, 3))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Evaluation Metrics for each query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP resultante de todas las queries: 0.6533977342259655\n"
     ]
    }
   ],
   "source": [
    "def evaluation_metric(bin_queries, query_index, scaled_results):\n",
    "    \"\"\"\n",
    "\n",
    "    :param bin_queries: Diccionario con valores {query Key: vector}, donde el vector corresponde a una lista\n",
    "    con la representación binaria de un de los resultados encontrados para una query con relación a los dados\n",
    "    en el archivo de evaluación. Ej, para q01, los relevantes son: d186,d254,d016. El RRDV devuelve d254, d016,\n",
    "    d153. Por ende, la representación binaria de q01, en el orden del archivo de evaluación es: [0, 1, 1]\n",
    "    :param query_index: Lista con los ids de las queries. ['qo1', 'qo2', ...]\n",
    "    :param scaled_results: Representación escalada de los resultados de las queries usando la escala dada en el\n",
    "    archivo de evaluación. Ej, q01 pasa de [0, 1, 1] a [0, 5, 5]\n",
    "    :return: Un dataframe con el cálculo del P@M, r@M y NDCG@M para cada query\n",
    "    \"\"\"\n",
    "    COLUMNS = ['P@M', 'R@M', 'NDCG@M']\n",
    "    records = []\n",
    "    for query, bin_vec in bin_queries.items():\n",
    "        scaled = scaled_results[query]\n",
    "        M = len(bin_vec)\n",
    "        pm = precision_at_k(bin_vec, M)\n",
    "        rm = recall_at_k(bin_vec, M, M)\n",
    "        ndcg = ndcg_at_k(scaled, M)\n",
    "        records.append([pm, rm, ndcg])\n",
    "        \n",
    "    return pd.DataFrame.from_records(records, index=query_index, columns=COLUMNS)\n",
    "        \n",
    "metrics = evaluation_metric(bin_results, queries_index, scaled_results)\n",
    "metrics.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def overall_map(map_relevant_docs):\n",
    "    \"\"\"\n",
    "    Función que calcula el MAP de los resultados de las queries.\n",
    "    :param map_relevant_docs: Vector binario de las queries asegurandose de que aparezcan todos los documentos relevantes\n",
    "    :return: El Mean average precision de los resultados de las queries.\n",
    "    \"\"\"\n",
    "    matrix = [vector for key, vector in map_relevant_docs.items() ]\n",
    "    return mean_avg_precision(matrix)\n",
    "\n",
    "print(f'MAP resultante de todas las queries: {overall_map(map_relevant_docs)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}