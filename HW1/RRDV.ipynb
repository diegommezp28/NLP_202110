{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from xml.dom import minidom\n",
    "from xml.etree import cElementTree as ElementTree\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "import csv\n",
    "from scipy import linalg as LA\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# Ranked Retrieval and Document Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', 'William Beaumont and the Human Digestion William Beaumont and the Human Digestion.  William Beaumont: Physiology of digestion Image Source.  On November 21, 1785, US-American surgeon William Beaumont was born. He became best known as “Father of Gastric Physiology” following his research on human digestion. William Beaumont was born in Lebanon, Connecticut and became a physician. He served as a surgeon’s mate in the Army during the War of 1812. He opened a private practice in Plattsburgh, New York, but rejoined the Army as a surgeon in 1819. Beaumont was stationed at Fort Mackinac on Mackinac Island in Michigan in the early 1820s when it existed to protect the interests of the American Fur Company. The fort became the refuge for a wounded 19-year-old French-Canadian fur trader named Alexis St. Martin when a shotgun went off by accident in the American Fur Company store at close range June 6th, 1822. St. Martin’s wound was quite serious because his stomach was perforated and several ribs were broken. Nobody really expected that the young man would survive but he really did. The skin around St. Martin’s wound fused to the hole in his stomach, leaving a permanent opening – a gastric fistula. [1] Beaumont quickly noticed that there was much research potential. Back then, not too much was known about the digestive system. In order to gain more information, Beaumont performed numerous experiments on St. Martin over a period of eight years. The experiments must have been really uncomfortable for the man, who was inserted bits of different foods tied to strings through the hole in his stomach, pulling them out periodically to observe digestion. Beaumont also removed gastric juice, examining it to better understand its nature. Beaumont became the “Father of Gastric Physiology” and his findings were published in the book “Experiments and Observations on the Gastric Juice and the Physiology of Digestion” in 1833. The work is now considered as the basis of much of the early knowledge on digestion. William Beaumont discovered that hydrochloric acid is the main chemical responsible for breaking down food and he suggested that another important digestive chemical, which is now known as pepsin. He suggested that digestion is a chemical process, not merely a mechanical one caused by stomach muscle movement. Also, Beaumont gave insights on how emotions, temperature, and physical activity can affect digestion. Beaumont’s famous patient, St. Martin, outlived the scientist even though his wound never completely healed. He had several children and died at the age of 83. [2] At yovisto, you may be interested in a video lecture on The Digestive System.')\n"
     ]
    }
   ],
   "source": [
    "def documentReader(path, queries = False):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    documents_path = os.path.join(os.getcwd(), path)\n",
    "    documentos = {}\n",
    "    for filename in os.listdir(documents_path):\n",
    "        file_path = os.path.join(documents_path, filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        title = '' if queries else xmldoc.getElementsByTagName('fileDesc')[0].attributes['title'].value\n",
    "        data = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        documentos[id] = (title + ' ' + data).replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "\n",
    "    return documentos\n",
    "documentos = documentReader('docs/docs-raw-texts')\n",
    "NRO_DOCS = len(documentos)\n",
    "DOCS_IDs = list(documentos.keys())\n",
    "print(list(documentos.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', ['William', 'Beaumont', 'Human', 'Digestion', 'William', 'Beaumont', 'Human', 'Digestion', '.', 'William', 'Beaumont', ':', 'Physiology', 'digestion', 'Image', 'Source', '.', 'On', 'November', '21', ',', '1785', ',', 'US-American', 'surgeon', 'William', 'Beaumont', 'born', '.', 'He', 'became', 'best', 'known', '“', 'Father', 'Gastric', 'Physiology', '”', 'following', 'research', 'human', 'digestion', '.', 'William', 'Beaumont', 'born', 'Lebanon', ',', 'Connecticut', 'became', 'physician', '.', 'He', 'served', 'surgeon', '’', 'mate', 'Army', 'War', '1812', '.', 'He', 'opened', 'private', 'practice', 'Plattsburgh', ',', 'New', 'York', ',', 'rejoined', 'Army', 'surgeon', '1819', '.', 'Beaumont', 'stationed', 'Fort', 'Mackinac', 'Mackinac', 'Island', 'Michigan', 'early', '1820s', 'existed', 'protect', 'interest', 'American', 'Fur', 'Company', '.', 'The', 'fort', 'became', 'refuge', 'wounded', '19-year-old', 'French-Canadian', 'fur', 'trader', 'named', 'Alexis', 'St.', 'Martin', 'shotgun', 'went', 'accident', 'American', 'Fur', 'Company', 'store', 'close', 'range', 'June', '6th', ',', '1822', '.', 'St.', 'Martin', '’', 'wound', 'quite', 'serious', 'stomach', 'perforated', 'several', 'rib', 'broken', '.', 'Nobody', 'really', 'expected', 'young', 'man', 'would', 'survive', 'really', '.', 'The', 'skin', 'around', 'St.', 'Martin', '’', 'wound', 'fused', 'hole', 'stomach', ',', 'leaving', 'permanent', 'opening', '–', 'gastric', 'fistula', '.', '[', '1', ']', 'Beaumont', 'quickly', 'noticed', 'much', 'research', 'potential', '.', 'Back', ',', 'much', 'known', 'digestive', 'system', '.', 'In', 'order', 'gain', 'information', ',', 'Beaumont', 'performed', 'numerous', 'experiment', 'St.', 'Martin', 'period', 'eight', 'year', '.', 'The', 'experiment', 'must', 'really', 'uncomfortable', 'man', ',', 'inserted', 'bit', 'different', 'food', 'tied', 'string', 'hole', 'stomach', ',', 'pulling', 'periodically', 'observe', 'digestion', '.', 'Beaumont', 'also', 'removed', 'gastric', 'juice', ',', 'examining', 'better', 'understand', 'nature', '.', 'Beaumont', 'became', '“', 'Father', 'Gastric', 'Physiology', '”', 'finding', 'published', 'book', '“', 'Experiments', 'Observations', 'Gastric', 'Juice', 'Physiology', 'Digestion', '”', '1833', '.', 'The', 'work', 'considered', 'basis', 'much', 'early', 'knowledge', 'digestion', '.', 'William', 'Beaumont', 'discovered', 'hydrochloric', 'acid', 'main', 'chemical', 'responsible', 'breaking', 'food', 'suggested', 'another', 'important', 'digestive', 'chemical', ',', 'known', 'pepsin', '.', 'He', 'suggested', 'digestion', 'chemical', 'process', ',', 'merely', 'mechanical', 'one', 'caused', 'stomach', 'muscle', 'movement', '.', 'Also', ',', 'Beaumont', 'gave', 'insight', 'emotion', ',', 'temperature', ',', 'physical', 'activity', 'affect', 'digestion', '.', 'Beaumont', '’', 'famous', 'patient', ',', 'St.', 'Martin', ',', 'outlived', 'scientist', 'even', 'though', 'wound', 'never', 'completely', 'healed', '.', 'He', 'several', 'child', 'died', 'age', '83', '.', '[', '2', ']', 'At', 'yovisto', ',', 'may', 'interested', 'video', 'lecture', 'The', 'Digestive', 'System', '.'])\n"
     ]
    }
   ],
   "source": [
    "def tokenization(documentos):\n",
    "    \"\"\"\n",
    "    :param documentos:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nltk_stop_words_en = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    word_tok = {key: nltk.word_tokenize(doc) for key, doc in documentos.items()}\n",
    "    word_tok_sw = {key: [token for token in doc if token not in nltk_stop_words_en] for key, doc in word_tok.items()}\n",
    "    nltk_lemmaList = {key: [wordnet_lemmatizer.lemmatize(word) for word in doc] for key, doc in word_tok_sw.items()}\n",
    "\n",
    "    return nltk_lemmaList\n",
    "tokenized_docs = tokenization(documentos)\n",
    "print(list(tokenized_docs.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('William', {'posting': [[1, 6], [15, 6], [28, 4], [35, 2], [55, 4], [56, 5], [69, 6], [88, 3], [91, 1], [92, 1], [95, 1], [98, 2], [102, 5], [106, 1], [109, 1], [111, 1], [129, 1], [136, 8], [138, 3], [147, 1], [175, 1], [179, 2], [180, 1], [189, 2], [190, 1], [191, 1], [197, 1], [212, 1], [230, 1], [241, 2], [254, 1], [257, 1], [266, 2], [272, 1], [273, 8], [274, 1], [289, 1], [291, 1], [294, 1], [299, 1], [300, 1], [309, 1], [310, 5], [320, 6], [323, 1], [330, 7]], 'freq': 46})\n"
     ]
    }
   ],
   "source": [
    "def makeInvertedIndex(tokenized_docs):\n",
    "    index = {}\n",
    "\n",
    "    for id, doc in tokenized_docs.items():\n",
    "        id = int(id[-3:]) #paasa dnjk al entero njk.\n",
    "        for token in doc:\n",
    "            if token in index :\n",
    "                if index[token]['posting'][-1][0] == id:\n",
    "                    index[token]['posting'][-1][1] += 1\n",
    "                else:\n",
    "                    index[token]['posting'].append([id, 1])\n",
    "                    index[token]['freq'] += 1\n",
    "\n",
    "            else:\n",
    "                index[token] = {\n",
    "                    'posting': [[id, 1]],\n",
    "                    'freq': 1\n",
    "                }\n",
    "    return index\n",
    "\n",
    "invertedIndex = makeInvertedIndex(tokenized_docs)\n",
    "print(list(invertedIndex.items())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Beaumont', {'posting': [[1, 13]], 'freq': 1})\n",
      "20446\n"
     ]
    }
   ],
   "source": [
    "print(list(invertedIndex.items())[1])\n",
    "print(len(list(invertedIndex.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               d001      d002  d003  d004  d005  d006  d007  d008  d009  d010  \\\nWilliam    1.667782  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \nBeaumont   6.649971  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \nHuman      1.363460  0.860247   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \nDigestion  3.493223  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n.          0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n           ...  d322      d323  d324  d325  d326  d327  d328  d329      d330  \\\nWilliam    ...   0.0  0.594076   0.0   0.0   0.0   0.0   0.0   0.0  1.782227   \nBeaumont   ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   \nHuman      ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   \nDigestion  ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   \n.          ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   \n\n           d331  \nWilliam     0.0  \nBeaumont    0.0  \nHuman       0.0  \nDigestion   0.0  \n.           0.0  \n\n[5 rows x 331 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d001</th>\n      <th>d002</th>\n      <th>d003</th>\n      <th>d004</th>\n      <th>d005</th>\n      <th>d006</th>\n      <th>d007</th>\n      <th>d008</th>\n      <th>d009</th>\n      <th>d010</th>\n      <th>...</th>\n      <th>d322</th>\n      <th>d323</th>\n      <th>d324</th>\n      <th>d325</th>\n      <th>d326</th>\n      <th>d327</th>\n      <th>d328</th>\n      <th>d329</th>\n      <th>d330</th>\n      <th>d331</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>William</th>\n      <td>1.667782</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.594076</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.782227</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Beaumont</th>\n      <td>6.649971</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Human</th>\n      <td>1.363460</td>\n      <td>0.860247</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Digestion</th>\n      <td>3.493223</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>.</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 331 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidfWeightedVector(invertedIndex):\n",
    "\n",
    "    weightedVectorMatrix = []\n",
    "    index = []\n",
    "    columns = []\n",
    "    for term, term_dict in invertedIndex.items():\n",
    "        weighted_vector = np.zeros(NRO_DOCS)\n",
    "        freq = term_dict['freq']\n",
    "        index.append(term)\n",
    "        for id, t_freq in term_dict['posting']:\n",
    "            tfidf = np.log(1 + t_freq) * np.log10(NRO_DOCS / freq)\n",
    "            weighted_vector[ id - 1] = tfidf\n",
    "\n",
    "        weightedVectorMatrix.append(weighted_vector)\n",
    "\n",
    "\n",
    "    weighted_vector_df = pd.DataFrame.from_records(data=weightedVectorMatrix, index=index, columns=DOCS_IDs)\n",
    "    return weighted_vector_df, index\n",
    "\n",
    "weighted_vector_df, term_index = tfidfWeightedVector(invertedIndex)\n",
    "weighted_vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz tfidf de dimension (20446, 331)\n"
     ]
    }
   ],
   "source": [
    "print(f'Matriz tfidf de dimension {weighted_vector_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def norma(v):\n",
    "    suma = sum(v[i]**2 for i in range(len(v)))\n",
    "    return math.sqrt(suma)\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    product = sum( v1[0][i]*v2[i][0] for i in range(len(v2)) )\n",
    "    return product\n",
    "\n",
    "def cosine_Similarity(doc_vec1, doc_vec2):\n",
    "    # print('.')\n",
    "    return (dot_product(doc_vec1, doc_vec2)) / (norma(doc_vec1.flatten()) * norma(doc_vec2.flatten()))\n",
    "\n",
    "def cosine_Similarity_normQ(query, doc):\n",
    "    return dot_product(query, doc) / norma(doc.flatten())\n",
    "\n",
    "# HAcer ejemplo a mano a ver si sirve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', ' Fabrication of music instruments')\n"
     ]
    }
   ],
   "source": [
    "queries = documentReader('docs/queries-raw-texts', True)\n",
    "print(list(queries.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', ['Fabrication', 'music', 'instrument'])\n"
     ]
    }
   ],
   "source": [
    "tokenized_queries = tokenization(queries)\n",
    "print(list(tokenized_queries.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El término \"Fabrication\" de la query q01 no está en los docs\n",
      "El término \"Computers\" de la query q24 no está en los docs\n",
      "El término \"WWII\" de la query q25 no está en los docs\n",
      "El término \"Religious\" de la query q38 no está en los docs\n",
      "El término \"Personalities\" de la query q41 no está en los docs\n",
      "El término \"Campaign\" de la query q44 no está en los docs\n",
      "El término \"Friends\" de la query q45 no está en los docs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def vectorize_queries(queries, term_index):\n",
    "    vector_queries = []\n",
    "    queries_index = []\n",
    "    for id, query in queries.items():\n",
    "        queries_index.append(id)\n",
    "        query_vector = np.zeros(len(term_index)) #Vector de ceros de dimensión V\n",
    "        len_query = len(query)\n",
    "        for term in query:\n",
    "            try:\n",
    "                index = term_index.index(term)\n",
    "                query_vector[index] = 1 / math.sqrt(len_query) #Pone en 1 la dimensión del vector correpondiente al termino en term\n",
    "            except:\n",
    "                print(f'El término \"{term}\" de la query {id} no está en los docs')\n",
    "\n",
    "        vector_queries.append(query_vector)\n",
    "    return vector_queries, queries_index\n",
    "\n",
    "vector_queries, queries_index = vectorize_queries(tokenized_queries, term_index)\n",
    "\n",
    "# vector_queries[0][:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     William  Beaumont  Human  Digestion    .    :  Physiology  digestion  \\\nq01      0.0       0.0    0.0        0.0  0.0  0.0         0.0        0.0   \nq02      0.0       0.0    0.0        0.0  0.0  0.0         0.0        0.0   \nq03      0.0       0.0    0.0        0.0  0.0  0.0         0.0        0.0   \nq04      0.0       0.0    0.0        0.0  0.0  0.0         0.0        0.0   \nq06      0.0       0.0    0.0        0.0  0.0  0.0         0.0        0.0   \n\n     Image  Source  ...  Gila  Viceroy  Arcángel  247  presidio  Assisi  \\\nq01    0.0     0.0  ...   0.0      0.0       0.0  0.0       0.0     0.0   \nq02    0.0     0.0  ...   0.0      0.0       0.0  0.0       0.0     0.0   \nq03    0.0     0.0  ...   0.0      0.0       0.0  0.0       0.0     0.0   \nq04    0.0     0.0  ...   0.0      0.0       0.0  0.0       0.0     0.0   \nq06    0.0     0.0  ...   0.0      0.0       0.0  0.0       0.0     0.0   \n\n     Asiacutes  36.000  Commanche  Apache  \nq01        0.0     0.0        0.0     0.0  \nq02        0.0     0.0        0.0     0.0  \nq03        0.0     0.0        0.0     0.0  \nq04        0.0     0.0        0.0     0.0  \nq06        0.0     0.0        0.0     0.0  \n\n[5 rows x 20446 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>William</th>\n      <th>Beaumont</th>\n      <th>Human</th>\n      <th>Digestion</th>\n      <th>.</th>\n      <th>:</th>\n      <th>Physiology</th>\n      <th>digestion</th>\n      <th>Image</th>\n      <th>Source</th>\n      <th>...</th>\n      <th>Gila</th>\n      <th>Viceroy</th>\n      <th>Arcángel</th>\n      <th>247</th>\n      <th>presidio</th>\n      <th>Assisi</th>\n      <th>Asiacutes</th>\n      <th>36.000</th>\n      <th>Commanche</th>\n      <th>Apache</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>q01</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q02</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q03</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q04</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q06</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 20446 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_queries = pd.DataFrame.from_records(data=vector_queries, index=queries_index, columns=term_index)\n",
    "matrix_queries.head()\n",
    "# print(vector_queries)\n",
    "# print(term_index.index('computer'))\n",
    "\n",
    "# pdf = pd.DataFrame.from_records([[1, 2, 3], [5, 6, 7]], index=['a', 'b'], columns=['c', 'd', 'e'])\n",
    "# pdf2 = pd.DataFrame.from_records([[1, 2, 3], [5, 6, 7]], index=['a', 'b'], columns=['c', 'd', 'e'])\n",
    "# pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688776\n"
     ]
    }
   ],
   "source": [
    "print(matrix_queries.iloc[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q01\n",
      "q02\n",
      "q03\n",
      "q04\n",
      "q06\n",
      "q07\n",
      "q08\n",
      "q09\n",
      "q10\n",
      "q12\n",
      "q13\n",
      "q14\n",
      "q16\n",
      "q17\n",
      "q18\n",
      "q19\n",
      "q22\n",
      "q23\n",
      "q24\n",
      "q25\n",
      "q26\n",
      "q27\n",
      "q28\n",
      "q29\n",
      "q32\n",
      "q34\n",
      "q36\n",
      "q37\n",
      "q38\n",
      "q40\n",
      "q41\n",
      "q42\n",
      "q44\n",
      "q45\n",
      "q46\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "def getCosineSimilarity(queries, documents, query_index, docs_index):\n",
    "    similarity_matrix = []\n",
    "    col = []\n",
    "    row = []\n",
    "    for query in query_index:\n",
    "        print(query)\n",
    "        row_query = queries.loc[[query]].values\n",
    "        query_doc_sim = []\n",
    "        # row = row_query\n",
    "        # print(row_query.shape)\n",
    "        for document in docs_index:\n",
    "            col_document = documents[[document]].values\n",
    "            # col = col_document\n",
    "            # print(col_document)\n",
    "            cos_sim = cosine_Similarity_normQ(row_query, col_document)\n",
    "            # print(f'Cos sim: {cos_sim}')\n",
    "            query_doc_sim.append(cos_sim)\n",
    "            # break\n",
    "        # print(query_doc_sim)\n",
    "        # break\n",
    "        similarity_matrix.append(query_doc_sim)\n",
    "    # return pd.DataFrame.from_records(data=similarity_matrix, index=query_index, columns=docs_index)\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = getCosineSimilarity(matrix_queries, weighted_vector_df, queries_index, DOCS_IDs)\n",
    "# similarity_matrix.head()\n",
    "\n",
    "print(len(similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pre_dot = [row[0][i]*col[i] for i in range(len(col)) ]\n",
    "# sum(pre_dot)[0]\n",
    "# cosine_Similarity(row, col)\n",
    "# pdf = pd.DataFrame.from_records([[1, 2, 0], [5, 6, 0]], index=['a', 'b'], columns=['c', 'd', 'e'])\n",
    "# pdf2 = pd.DataFrame.from_records([[1, 2, 0], [5, 6, 0]], index=['a', 'b'], columns=['c', 'd', 'e'])\n",
    "# pdf\n",
    "# print('hello')\n",
    "# (pdf.loc[['b']].values @ pdf[['d']].values)\n",
    "# np.dot(row, col)\n",
    "# row.dot(col)\n",
    "# copy = pdf.loc[['a']].sort_values(by='a', axis=1, ascending=False, inplace=False)\n",
    "# copy.loc[:, (copy != 0 ).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# LA.norm(row.reshape(-1,1))\n",
    "# LA.norm(row.flatten())\n",
    "# norma(row.flatten())\n",
    "# np.dot(pdf.loc[['b']].values,  pdf[['d']].values).sum()\n",
    "# dot_product(pdf.loc[['b']].values,  pdf[['d']].values)\n",
    "# len(row[0])\n",
    "\n",
    "# cosine_Similarity(pdf.loc[['b']].values, pdf[['d']].values)\n",
    "# pdf.loc[['a']].values.shape\n",
    "# (10 + 36 )/((61)**(1/2)*(40)**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ## Save cosine similarity Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "with open('docs/cos_sim_matrix', 'wb') as picklefile:\n",
    "    pickle.dump(similarity_matrix,picklefile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read cosine similarity Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with open('docs/cos_sim_matrix', 'rb') as matrix:\n",
    "    similarity_matrix = pd.DataFrame.from_records(pickle.load(matrix), index=queries_index, columns=DOCS_IDs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "35"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarity_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve ordered docs per query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['d254', 'd016', 'd153', 'd209', 'd186']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_docs(similarity_matrix, query_index):\n",
    "    results = {}\n",
    "    for query in query_index:\n",
    "        order = similarity_matrix.loc[[query]].sort_values(by=query, axis=1, ascending=False, inplace=False)\n",
    "        relevant = order.loc[:, (order != 0 ).any(axis=0)]\n",
    "        results[query] = relevant.columns.values.tolist()\n",
    "    return results\n",
    "\n",
    "results = retrieve_docs(similarity_matrix, queries_index)\n",
    "results['q01'][:5]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "194"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['q02'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q01': {'d016': '5', 'd186': '4', 'd254': '5'}, 'q02': {'d136': '2', 'd139': '2', 'd143': '4', 'd147': '2', 'd149': '2', 'd164': '4', 'd228': '4', 'd283': '4', 'd291': '4', 'd293': '4', 'd318': '2'}, 'q03': {'d105': '2', 'd147': '3', 'd152': '3', 'd283': '4', 'd291': '4', 'd318': '2'}, 'q04': {'d010': '3', 'd019': '2', 'd049': '2', 'd270': '3', 'd275': '3', 'd286': '2', 'd330': '2'}, 'q06': {'d026': '4', 'd069': '2', 'd233': '3', 'd257': '2', 'd297': '3', 'd329': '5'}, 'q07': {'d004': '3', 'd077': '3', 'd179': '3', 'd266': '2'}, 'q08': {'d005': '4', 'd028': '3', 'd081': '2', 'd108': '3', 'd110': '4', 'd117': '3', 'd121': '2', 'd180': '2', 'd205': '2', 'd251': '5', 'd271': '3', 'd292': '2'}, 'q09': {'d177': '2', 'd198': '3', 'd199': '5', 'd205': '3', 'd217': '2', 'd223': '2'}, 'q10': {'d052': '2', 'd065': '3', 'd068': '2', 'd076': '3', 'd100': '2', 'd199': '4', 'd215': '2', 'd231': '4'}, 'q12': {'d239': '4', 'd250': '4', 'd258': '3', 'd277': '4'}, 'q13': {'d049': '4', 'd056': '4', 'd239': '2', 'd258': '2', 'd277': '2'}, 'q14': {'d002': '2', 'd005': '3', 'd041': '3', 'd081': '4', 'd091': '4', 'd093': '3', 'd117': '2', 'd130': '3', 'd142': '2', 'd180': '3', 'd280': '3', 'd314': '3'}, 'q16': {'d132': '3', 'd229': '2'}, 'q17': {'d091': '2', 'd121': '4', 'd271': '4', 'd280': '2'}, 'q18': {'d192': '4', 'd194': '3', 'd201': '3', 'd207': '2', 'd210': '3', 'd216': '2', 'd222': '2'}, 'q19': {'d077': '2', 'd179': '5'}, 'q22': {'d011': '3', 'd049': '2', 'd132': '2', 'd250': '2', 'd258': '2', 'd277': '2', 'd331': '2'}, 'q23': {'d194': '2', 'd202': '2', 'd205': '2', 'd211': '3', 'd215': '2', 'd216': '2', 'd219': '5', 'd276': '4'}, 'q24': {'d060': '2', 'd098': '2', 'd129': '3', 'd196': '2', 'd221': '2'}, 'q25': {'d020': '3', 'd023': '2', 'd166': '3', 'd167': '3'}, 'q26': {'d152': '5'}, 'q27': {'d017': '2', 'd051': '2', 'd054': '5', 'd103': '5', 'd107': '2', 'd143': '2', 'd158': '2', 'd293': '4'}, 'q28': {'d094': '3', 'd136': '5', 'd316': '3'}, 'q29': {'d001': '3', 'd037': '5', 'd046': '3', 'd062': '4', 'd093': '2', 'd113': '4', 'd120': '3', 'd130': '3', 'd133': '4', 'd261': '3', 'd294': '2', 'd314': '4'}, 'q32': {'d025': '5', 'd031': '2', 'd067': '3', 'd090': '4', 'd139': '3'}, 'q34': {'d248': '5'}, 'q36': {'d020': '3', 'd023': '3', 'd150': '3', 'd167': '2', 'd247': '4', 'd257': '4', 'd265': '4', 'd277': '4', 'd321': '3', 'd328': '3'}, 'q37': {'d116': '3', 'd169': '5', 'd256': '2'}, 'q38': {'d015': '2', 'd039': '3', 'd229': '2', 'd235': '4', 'd250': '2', 'd263': '2', 'd294': '4', 'd317': '2'}, 'q40': {'d042': '5', 'd047': '5', 'd098': '3', 'd112': '3', 'd122': '3', 'd242': '4', 'd252': '2', 'd262': '3', 'd307': '3'}, 'q41': {'d121': '3', 'd128': '3', 'd150': '5', 'd174': '3', 'd268': '2', 'd291': '4', 'd318': '5'}, 'q42': {'d014': '2', 'd298': '5', 'd314': '2'}, 'q44': {'d003': '2', 'd029': '4', 'd085': '2', 'd105': '2', 'd126': '2', 'd148': '2', 'd164': '2', 'd170': '2', 'd185': '3', 'd254': '2'}, 'q45': {'d085': '4', 'd105': '5', 'd126': '3', 'd148': '2', 'd164': '3', 'd170': '3', 'd185': '3', 'd254': '2'}, 'q46': {'d002': '2', 'd005': '2', 'd093': '2', 'd121': '3', 'd133': '3', 'd314': '2'}}\n"
     ]
    }
   ],
   "source": [
    "def read_judgemnts_file():\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    document_path = os.path.join(os.getcwd(), 'docs/relevance-judgments.tsv')\n",
    "    tsv_file = open(document_path)\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    relevance = {}\n",
    "    for row in read_tsv:\n",
    "        documents = row[1].split(',')\n",
    "        query_relevance = {pair.split(':')[0] : pair.split(':')[1] for pair in documents }\n",
    "        query_relevance = dict(sorted(query_relevance.items(), key=lambda item: item[0]))\n",
    "        relevance[row[0]] = query_relevance\n",
    "    return relevance\n",
    "\n",
    "\n",
    "relevance = read_judgemnts_file()\n",
    "print(relevance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'q01': [1, 0, 1],\n 'q02': [0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1],\n 'q03': [1, 1, 1, 1, 1, 1],\n 'q04': [1, 1, 1, 1, 1, 1, 0],\n 'q06': [1, 1, 1, 1, 1, 1],\n 'q07': [1, 0, 0, 0],\n 'q08': [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n 'q09': [1, 1, 1, 0, 1, 1],\n 'q10': [1, 0, 1, 0, 0, 0, 1, 1],\n 'q12': [0, 1, 1, 1],\n 'q13': [1, 1, 0, 0, 1],\n 'q14': [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n 'q16': [0, 0],\n 'q17': [1, 1, 1, 0],\n 'q18': [1, 1, 1, 1, 1, 1, 0],\n 'q19': [0, 1],\n 'q22': [1, 1, 0, 0, 1, 1, 0],\n 'q23': [0, 0, 0, 0, 0, 0, 1, 1],\n 'q24': [0, 0, 0, 0, 0],\n 'q25': [1, 0, 1, 0],\n 'q26': [1],\n 'q27': [1, 0, 1, 1, 0, 0, 0, 0],\n 'q28': [0, 1, 0],\n 'q29': [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n 'q32': [1, 1, 1, 1, 1],\n 'q34': [1],\n 'q36': [0, 1, 1, 0, 0, 1, 1, 0, 1, 0],\n 'q37': [1, 1, 0],\n 'q38': [0, 0, 0, 0, 0, 1, 0, 0],\n 'q40': [1, 1, 1, 1, 0, 0, 1, 1, 1],\n 'q41': [1, 1, 1, 1, 1, 1, 0],\n 'q42': [0, 1, 0],\n 'q44': [0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n 'q45': [1, 1, 1, 0, 1, 1, 1, 0],\n 'q46': [0, 0, 1, 1, 1, 0]}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_binary_result(results, relevant_res):\n",
    "    bin_relevant = {}\n",
    "    rel_scale_repr = {}\n",
    "    for query, relevant_docs in relevant_res.items():\n",
    "        bin_repr = []\n",
    "        scaled_repr = []\n",
    "        M = len(relevant_docs)\n",
    "        for doc_id, rel_scale in relevant_docs.items():\n",
    "            bin = 1 if doc_id in results[query][:M] else 0\n",
    "            bin_repr.append(bin)\n",
    "            scaled_repr.append(bin * int(rel_scale))\n",
    "        bin_relevant[query] = bin_repr\n",
    "        rel_scale_repr[query] = scaled_repr\n",
    "    return bin_relevant, rel_scale_repr\n",
    "\n",
    "bin_results, scaled_results = make_binary_result(results, relevance)\n",
    "bin_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[5, 0, 5]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_results['q01']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.35468253968253965"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_at_k(relevance: list, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    l = np.array(relevance[:k]).sum()/k\n",
    "    return l\n",
    "\n",
    "def recall_at_k(relevance: list, nr_relevant: int, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    l = np.array(relevance[:k]).sum()/nr_relevant\n",
    "    return l\n",
    "\n",
    "def average_precision(relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    length = len(relevance)\n",
    "    sum = 0\n",
    "    for i in range(length):\n",
    "        if relevance[i]:\n",
    "            sum += precision_at_k(relevance, i+1)\n",
    "    if np.array(relevance).sum()==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum / np.array(relevance).sum()\n",
    "\n",
    "def mean_avg_precision(l):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    average = 0\n",
    "    for lista in l:\n",
    "        #print(average_precision(lista))\n",
    "        average+= average_precision(lista)\n",
    "\n",
    "    mean = average / len(l)\n",
    "    return mean\n",
    "\n",
    "mean_avg_precision([[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 1], [0, 1, 0, 1, 1, 1, 1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7424602308163405"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dcg_at_k(relevance, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    sum = 0\n",
    "    i =  0\n",
    "    for rel_i in relevance[: k]:\n",
    "        i+= 1\n",
    "        sum += rel_i/np.log2(max(i, 2))\n",
    "\n",
    "    return sum\n",
    "\n",
    "dcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)\n",
    "\n",
    "def ndcg_at_k(relevance, k):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    rel_sorted = sorted(relevance, reverse=True)\n",
    "    max = dcg_at_k(rel_sorted, k)\n",
    "    real = dcg_at_k(relevance, k)\n",
    "\n",
    "    return real/ max\n",
    "\n",
    "\n",
    "ndcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(recall_at_k(bin_results['q01'], 3, 3))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Evaluation Metrics for each query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-59e306872ea1>:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return real/ max\n"
     ]
    },
    {
     "data": {
      "text/plain": "          P@M       R@M    NDCG@M\nq01  0.666667  0.666667  0.815465\nq02  0.545455  0.545455  0.570012\nq03  1.000000  1.000000  0.874220\nq04  0.857143  0.857143  0.933486\nq06  1.000000  1.000000  0.863930\nq07  0.250000  0.250000  1.000000\nq08  0.750000  0.750000  0.842140\nq09  0.833333  0.833333  0.880115\nq10  0.500000  0.500000  0.642423\nq12  0.750000  0.750000  0.797833",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>P@M</th>\n      <th>R@M</th>\n      <th>NDCG@M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>q01</th>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.815465</td>\n    </tr>\n    <tr>\n      <th>q02</th>\n      <td>0.545455</td>\n      <td>0.545455</td>\n      <td>0.570012</td>\n    </tr>\n    <tr>\n      <th>q03</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.874220</td>\n    </tr>\n    <tr>\n      <th>q04</th>\n      <td>0.857143</td>\n      <td>0.857143</td>\n      <td>0.933486</td>\n    </tr>\n    <tr>\n      <th>q06</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.863930</td>\n    </tr>\n    <tr>\n      <th>q07</th>\n      <td>0.250000</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>q08</th>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.842140</td>\n    </tr>\n    <tr>\n      <th>q09</th>\n      <td>0.833333</td>\n      <td>0.833333</td>\n      <td>0.880115</td>\n    </tr>\n    <tr>\n      <th>q10</th>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.642423</td>\n    </tr>\n    <tr>\n      <th>q12</th>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.797833</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation_metric(bin_queries, query_index, scaled_results):\n",
    "    COLUMNS = ['P@M', 'R@M', 'NDCG@M']\n",
    "    records = []\n",
    "    for query, bin_vec in bin_queries.items():\n",
    "        scaled = scaled_results[query]\n",
    "        M = len(bin_vec)\n",
    "        pm = precision_at_k(bin_vec, M)\n",
    "        rm = recall_at_k(bin_vec, M, M)\n",
    "        ndcg = ndcg_at_k(scaled, M)\n",
    "        records.append([pm, rm, ndcg])\n",
    "        \n",
    "    return pd.DataFrame.from_records(records, index=query_index, columns=COLUMNS)\n",
    "        \n",
    "metrics = evaluation_metric(bin_results, queries_index, scaled_results)\n",
    "metrics.head(10)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP resultante de todas las queries: 0.7209512864308784\n"
     ]
    }
   ],
   "source": [
    "def overall_map(bin_results):\n",
    "    matrix = [vector for key, vector in bin_results.items() ]\n",
    "    return mean_avg_precision(matrix)\n",
    "\n",
    "print(f'MAP resultante de todas las queries: {overall_map(bin_results)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}