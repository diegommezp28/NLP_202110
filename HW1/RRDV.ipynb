{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from xml.dom import minidom\n",
    "from xml.etree import cElementTree as ElementTree\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "import csv\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# Ranked Retrieval and Document Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', 'William Beaumont and the Human Digestion William Beaumont and the Human Digestion.  William Beaumont: Physiology of digestion Image Source.  On November 21, 1785, US-American surgeon William Beaumont was born. He became best known as “Father of Gastric Physiology” following his research on human digestion. William Beaumont was born in Lebanon, Connecticut and became a physician. He served as a surgeon’s mate in the Army during the War of 1812. He opened a private practice in Plattsburgh, New York, but rejoined the Army as a surgeon in 1819. Beaumont was stationed at Fort Mackinac on Mackinac Island in Michigan in the early 1820s when it existed to protect the interests of the American Fur Company. The fort became the refuge for a wounded 19-year-old French-Canadian fur trader named Alexis St. Martin when a shotgun went off by accident in the American Fur Company store at close range June 6th, 1822. St. Martin’s wound was quite serious because his stomach was perforated and several ribs were broken. Nobody really expected that the young man would survive but he really did. The skin around St. Martin’s wound fused to the hole in his stomach, leaving a permanent opening – a gastric fistula. [1] Beaumont quickly noticed that there was much research potential. Back then, not too much was known about the digestive system. In order to gain more information, Beaumont performed numerous experiments on St. Martin over a period of eight years. The experiments must have been really uncomfortable for the man, who was inserted bits of different foods tied to strings through the hole in his stomach, pulling them out periodically to observe digestion. Beaumont also removed gastric juice, examining it to better understand its nature. Beaumont became the “Father of Gastric Physiology” and his findings were published in the book “Experiments and Observations on the Gastric Juice and the Physiology of Digestion” in 1833. The work is now considered as the basis of much of the early knowledge on digestion. William Beaumont discovered that hydrochloric acid is the main chemical responsible for breaking down food and he suggested that another important digestive chemical, which is now known as pepsin. He suggested that digestion is a chemical process, not merely a mechanical one caused by stomach muscle movement. Also, Beaumont gave insights on how emotions, temperature, and physical activity can affect digestion. Beaumont’s famous patient, St. Martin, outlived the scientist even though his wound never completely healed. He had several children and died at the age of 83. [2] At yovisto, you may be interested in a video lecture on The Digestive System.')\n"
     ]
    }
   ],
   "source": [
    "def documentReader(path, queries = False):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    documents_path = os.path.join(os.getcwd(), path)\n",
    "    documentos = {}\n",
    "    for filename in os.listdir(documents_path):\n",
    "        file_path = os.path.join(documents_path, filename)\n",
    "        xmldoc = minidom.parse(file_path)\n",
    "        id = xmldoc.getElementsByTagName('public')[0].attributes['publicId'].value\n",
    "        title = '' if queries else xmldoc.getElementsByTagName('fileDesc')[0].attributes['title'].value\n",
    "        data = next(ElementTree.parse(file_path).iter('raw')).text\n",
    "        documentos[id] = (title + ' ' + data).replace(u'\\xa0', u' ').replace('\\n', ' ')\n",
    "\n",
    "    return documentos\n",
    "documentos = documentReader('docs/docs-raw-texts')\n",
    "NRO_DOCS = len(documentos)\n",
    "DOCS_IDs = list(documentos.keys())\n",
    "print(list(documentos.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('d001', ['William', 'Beaumont', 'Human', 'Digestion', 'William', 'Beaumont', 'Human', 'Digestion', 'William', 'Beaumont', 'Physiology', 'digestion', 'Image', 'Source', 'On', 'November', '21', '1785', 'surgeon', 'William', 'Beaumont', 'born', 'He', 'became', 'best', 'known', 'Father', 'Gastric', 'Physiology', 'following', 'research', 'human', 'digestion', 'William', 'Beaumont', 'born', 'Lebanon', 'Connecticut', 'became', 'physician', 'He', 'served', 'surgeon', 'mate', 'Army', 'War', '1812', 'He', 'opened', 'private', 'practice', 'Plattsburgh', 'New', 'York', 'rejoined', 'Army', 'surgeon', '1819', 'Beaumont', 'stationed', 'Fort', 'Mackinac', 'Mackinac', 'Island', 'Michigan', 'early', '1820s', 'existed', 'protect', 'interest', 'American', 'Fur', 'Company', 'The', 'fort', 'became', 'refuge', 'wounded', 'fur', 'trader', 'named', 'Alexis', 'Martin', 'shotgun', 'went', 'accident', 'American', 'Fur', 'Company', 'store', 'close', 'range', 'June', '6th', '1822', 'Martin', 'wound', 'quite', 'serious', 'stomach', 'perforated', 'several', 'rib', 'broken', 'Nobody', 'really', 'expected', 'young', 'man', 'would', 'survive', 'really', 'The', 'skin', 'around', 'Martin', 'wound', 'fused', 'hole', 'stomach', 'leaving', 'permanent', 'opening', 'gastric', 'fistula', '1', 'Beaumont', 'quickly', 'noticed', 'much', 'research', 'potential', 'Back', 'much', 'known', 'digestive', 'system', 'In', 'order', 'gain', 'information', 'Beaumont', 'performed', 'numerous', 'experiment', 'Martin', 'period', 'eight', 'year', 'The', 'experiment', 'must', 'really', 'uncomfortable', 'man', 'inserted', 'bit', 'different', 'food', 'tied', 'string', 'hole', 'stomach', 'pulling', 'periodically', 'observe', 'digestion', 'Beaumont', 'also', 'removed', 'gastric', 'juice', 'examining', 'better', 'understand', 'nature', 'Beaumont', 'became', 'Father', 'Gastric', 'Physiology', 'finding', 'published', 'book', 'Experiments', 'Observations', 'Gastric', 'Juice', 'Physiology', 'Digestion', '1833', 'The', 'work', 'considered', 'basis', 'much', 'early', 'knowledge', 'digestion', 'William', 'Beaumont', 'discovered', 'hydrochloric', 'acid', 'main', 'chemical', 'responsible', 'breaking', 'food', 'suggested', 'another', 'important', 'digestive', 'chemical', 'known', 'pepsin', 'He', 'suggested', 'digestion', 'chemical', 'process', 'merely', 'mechanical', 'one', 'caused', 'stomach', 'muscle', 'movement', 'Also', 'Beaumont', 'gave', 'insight', 'emotion', 'temperature', 'physical', 'activity', 'affect', 'digestion', 'Beaumont', 'famous', 'patient', 'Martin', 'outlived', 'scientist', 'even', 'though', 'wound', 'never', 'completely', 'healed', 'He', 'several', 'child', 'died', 'age', '83', '2', 'At', 'yovisto', 'may', 'interested', 'video', 'lecture', 'The', 'Digestive', 'System'])\n"
     ]
    }
   ],
   "source": [
    "def tokenization(documentos):\n",
    "    \"\"\"\n",
    "    :param documentos:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    nltk_stop_words_en = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    word_tok = {key: nltk.word_tokenize(doc) for key, doc in documentos.items()}\n",
    "    word_tok_sw = {key: [token for token in doc\n",
    "                         if token.isalnum() and token not in nltk_stop_words_en]\n",
    "                   for key, doc in word_tok.items()}\n",
    "    nltk_lemmaList = {key: [wordnet_lemmatizer.lemmatize(word) for word in doc] for key, doc in word_tok_sw.items()}\n",
    "\n",
    "    return nltk_lemmaList\n",
    "tokenized_docs = tokenization(documentos)\n",
    "print(list(tokenized_docs.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freq': 46, 'posting': [[1, 4], [15, 5], [28, 3], [35, 2], [55, 2], [56, 4], [69, 4], [88, 3], [91, 1], [92, 1], [95, 1], [98, 2], [102, 3], [106, 1], [109, 1], [111, 1], [129, 1], [136, 6], [138, 3], [147, 1], [175, 1], [179, 2], [180, 1], [189, 2], [190, 1], [191, 1], [197, 1], [212, 1], [230, 1], [241, 2], [254, 1], [257, 1], [266, 2], [272, 1], [273, 6], [274, 1], [289, 1], [291, 1], [294, 1], [299, 1], [300, 1], [309, 1], [310, 3], [320, 4], [323, 1], [330, 6]]}\n"
     ]
    }
   ],
   "source": [
    "def indexReader():\n",
    "    \"\"\"\n",
    "    Reads the inverted index created in the distributed_inverted_index.ipynb notebook\n",
    "    The path from where it reads the file is docs/inverted_index.pkl\n",
    "    :return: the inverted index, represented in a dictionary where the keys are the terms\n",
    "    and the values is also a dictionary that contains the frecuency of documents\n",
    "    that contain the term, and the posting. The posting is an array itself\n",
    "    that contains the document id, and the term's frequency in that document.\n",
    "    {'term': {'freq': df, 'posting':[[doc1, tf1],[doc2, tf2],...,[docn, tfn]}}\n",
    "    \"\"\"\n",
    "    with open('docs/inverted_index.pkl', 'rb') as index:\n",
    "        return pickle.load(index)\n",
    "\n",
    "invertedIndex = indexReader()\n",
    "print(invertedIndex['William'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             d001  d002  d003  d004  d005  d006  d007  d008  d009  d010  ...  \\\nČech          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \nŁukasiewicz   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \nŠufflay       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \nλ             0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \nπ             0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n\n             d322  d323  d324  d325  d326  d327  d328  d329  d330  d331  \nČech          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \nŁukasiewicz   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \nŠufflay       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \nλ             0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \nπ             0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[5 rows x 331 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d001</th>\n      <th>d002</th>\n      <th>d003</th>\n      <th>d004</th>\n      <th>d005</th>\n      <th>d006</th>\n      <th>d007</th>\n      <th>d008</th>\n      <th>d009</th>\n      <th>d010</th>\n      <th>...</th>\n      <th>d322</th>\n      <th>d323</th>\n      <th>d324</th>\n      <th>d325</th>\n      <th>d326</th>\n      <th>d327</th>\n      <th>d328</th>\n      <th>d329</th>\n      <th>d330</th>\n      <th>d331</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Čech</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Łukasiewicz</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Šufflay</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>λ</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>π</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 331 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidfWeightedVector(invertedIndex):\n",
    "    \"\"\"\n",
    "    Recibe el inverted index y lo usa para crear el weighted vector\n",
    "    :param invertedIndex: Inverted index calculada antes\n",
    "    :return: Matriz |V|x|D|. Donde |V| es el tamaño de mi vocabulario y |D| es el número de documentos.\n",
    "    Cada fila es la representación en tfidf de un término\n",
    "    \"\"\"\n",
    "\n",
    "    weightedVectorMatrix = []\n",
    "    index = []\n",
    "    for term, term_dict in invertedIndex.items():\n",
    "        weighted_vector = np.zeros(NRO_DOCS)\n",
    "        freq = term_dict['freq']\n",
    "        index.append(term)\n",
    "        for id, t_freq in term_dict['posting']:\n",
    "            tfidf = np.log(1 + t_freq) * np.log10(NRO_DOCS / freq)\n",
    "            weighted_vector[ id - 1] = tfidf\n",
    "\n",
    "        weightedVectorMatrix.append(weighted_vector)\n",
    "\n",
    "\n",
    "    weighted_vector_df = pd.DataFrame.from_records(data=weightedVectorMatrix, index=index, columns=DOCS_IDs)\n",
    "    return weighted_vector_df, index\n",
    "\n",
    "weighted_vector_df, term_index = tfidfWeightedVector(invertedIndex)\n",
    "weighted_vector_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz tfidf de dimension (18840, 331)\n"
     ]
    }
   ],
   "source": [
    "print(f'Matriz tfidf de dimension {weighted_vector_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def norma(v):\n",
    "    suma = sum(v[i]**2 for i in range(len(v)))\n",
    "    return math.sqrt(suma)\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    product = sum( v1[0][i]*v2[i][0] for i in range(len(v2)) )\n",
    "    return product\n",
    "\n",
    "def cosine_Similarity(doc_vec1, doc_vec2):\n",
    "    # print('.')\n",
    "    return (dot_product(doc_vec1, doc_vec2)) / (norma(doc_vec1.flatten()) * norma(doc_vec2.flatten()))\n",
    "\n",
    "def cosine_Similarity_normQ(query, doc):\n",
    "    return dot_product(query, doc) / norma(doc.flatten())\n",
    "\n",
    "# HAcer ejemplo a mano a ver si sirve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', ' Fabrication of music instruments')\n"
     ]
    }
   ],
   "source": [
    "queries = documentReader('docs/queries-raw-texts', True)\n",
    "print(list(queries.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('q01', ['Fabrication', 'music', 'instrument'])\n"
     ]
    }
   ],
   "source": [
    "tokenized_queries = tokenization(queries)\n",
    "print(list(tokenized_queries.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El término \"Fabrication\" de la query q01 no está en los docs\n",
      "El término \"Computers\" de la query q24 no está en los docs\n",
      "El término \"WWII\" de la query q25 no está en los docs\n",
      "El término \"Religious\" de la query q38 no está en los docs\n",
      "El término \"Personalities\" de la query q41 no está en los docs\n",
      "El término \"Campaign\" de la query q44 no está en los docs\n",
      "El término \"Friends\" de la query q45 no está en los docs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def vectorize_queries(queries, term_index):\n",
    "    \"\"\"\n",
    "    Vectoriza las queries tal forma que cada una sea un vector unitario con la misma dimensión del tamaño\n",
    "    de vocabulario encontrado en el corpus de los documentos.\n",
    "    :param queries: Diccionario con pares key, value. Donde key es el id de cada query y el value es la\n",
    "    tokenización de dicha query.\n",
    "    :param term_index: Lista con los ids de las queries. i.e. ['q01', 'q02', ...]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    vector_queries = []\n",
    "    queries_index = []\n",
    "    for id, query in queries.items():\n",
    "        queries_index.append(id)\n",
    "        query_vector = np.zeros(len(term_index)) #Vector de ceros de dimensión V\n",
    "        len_query = len(query)\n",
    "        for term in query:\n",
    "            try:\n",
    "                index = term_index.index(term)\n",
    "                query_vector[index] = 1 / math.sqrt(len_query) #Pone en 1 la dimensión del vector correpondiente al termino en term\n",
    "            except:\n",
    "                print(f'El término \"{term}\" de la query {id} no está en los docs')\n",
    "\n",
    "        vector_queries.append(query_vector)\n",
    "    return vector_queries, queries_index\n",
    "\n",
    "vector_queries, queries_index = vectorize_queries(tokenized_queries, term_index)\n",
    "\n",
    "# vector_queries[0][:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       0   01    1   10  100  1000  10000  101  102  1024  ...  élèves  \\\nq01  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0   0.0  ...     0.0   \nq02  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0   0.0  ...     0.0   \nq03  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0   0.0  ...     0.0   \nq04  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0   0.0  ...     0.0   \nq06  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0   0.0  ...     0.0   \n\n     élémentaire  émigré  émigrés  über  Čech  Łukasiewicz  Šufflay    λ    π  \nq01          0.0     0.0      0.0   0.0   0.0          0.0      0.0  0.0  0.0  \nq02          0.0     0.0      0.0   0.0   0.0          0.0      0.0  0.0  0.0  \nq03          0.0     0.0      0.0   0.0   0.0          0.0      0.0  0.0  0.0  \nq04          0.0     0.0      0.0   0.0   0.0          0.0      0.0  0.0  0.0  \nq06          0.0     0.0      0.0   0.0   0.0          0.0      0.0  0.0  0.0  \n\n[5 rows x 18840 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>01</th>\n      <th>1</th>\n      <th>10</th>\n      <th>100</th>\n      <th>1000</th>\n      <th>10000</th>\n      <th>101</th>\n      <th>102</th>\n      <th>1024</th>\n      <th>...</th>\n      <th>élèves</th>\n      <th>élémentaire</th>\n      <th>émigré</th>\n      <th>émigrés</th>\n      <th>über</th>\n      <th>Čech</th>\n      <th>Łukasiewicz</th>\n      <th>Šufflay</th>\n      <th>λ</th>\n      <th>π</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>q01</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q02</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q03</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q04</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q06</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 18840 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_queries = pd.DataFrame.from_records(data=vector_queries, index=queries_index, columns=term_index)\n",
    "matrix_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688776\n"
     ]
    }
   ],
   "source": [
    "print(matrix_queries.iloc[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q01 - q02 - q03 - q04 - q06 - q07 - q08 - q09 - q10 - q12 - q13 - q14 - q16 - q17 - q18 - q19 - q22 - q23 - q24 - q25 - q26 - q27 - q28 - q29 - q32 - q34 - q36 - q37 - q38 - q40 - q41 - q42 - q44 - q45 - q46 - 35\n"
     ]
    }
   ],
   "source": [
    "def getCosineSimilarity(queries, documents, query_index, docs_index):\n",
    "    \"\"\"\n",
    "    Recibe la matriz tfidf de documentos y la de queries y saca las matriz de similitud usando coseno como\n",
    "    métrica de similitud\n",
    "    :param queries: Matriz |Q|x|V| donde |V| es el tamaño del vocabulario y |Q| el número de queries.\n",
    "    Cada vector-fila es unitario y tiene 0 en todoas las columnas con términos que no hacen parte de la query\n",
    "    que representa la fila en cuestión.\n",
    "    :param documents: Matriz |V|x|D|, Donde |D| es el número de documentos. Cada fila es la representación tfidf de un\n",
    "    término.\n",
    "    :param query_index: Lista con los ids de las queries. i.e. ['q01', 'q02', ...]\n",
    "    :param docs_index: Lista con los ids de los docs. i.e.  ['d01', 'd02', ...]\n",
    "    :return:Retorna la matriz de similitud entre las queries y los documentos\n",
    "    \"\"\"\n",
    "\n",
    "    similarity_matrix = []\n",
    "\n",
    "    for query in query_index:\n",
    "        print(query, end=' - ')\n",
    "        row_query = queries.loc[[query]].values\n",
    "        query_doc_sim = []\n",
    "        for document in docs_index:\n",
    "            col_document = documents[[document]].values\n",
    "            cos_sim = cosine_Similarity_normQ(row_query, col_document)\n",
    "            query_doc_sim.append(cos_sim)\n",
    "\n",
    "        similarity_matrix.append(query_doc_sim)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = getCosineSimilarity(matrix_queries, weighted_vector_df, queries_index, DOCS_IDs)\n",
    "\n",
    "print(len(similarity_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ## Save cosine similarity Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "with open('docs/cos_sim_matrix', 'wb') as picklefile:\n",
    "    pickle.dump(similarity_matrix,picklefile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read cosine similarity Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "with open('docs/cos_sim_matrix', 'rb') as matrix:\n",
    "    similarity_matrix = pd.DataFrame.from_records(pickle.load(matrix), index=queries_index, columns=DOCS_IDs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "         d001      d002      d003      d004      d005      d006      d007  \\\nq01  0.000000  0.000000  0.000000  0.022011  0.000000  0.038817  0.000000   \nq02  0.008216  0.038387  0.005380  0.006699  0.010479  0.000000  0.017204   \nq03  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nq04  0.019206  0.000000  0.004159  0.000000  0.022856  0.013380  0.006650   \nq06  0.000000  0.000000  0.018593  0.033279  0.000000  0.000000  0.000000   \nq07  0.000000  0.000000  0.000000  0.134515  0.000000  0.000000  0.000000   \nq08  0.000000  0.000000  0.000000  0.000000  0.072756  0.011019  0.000000   \nq09  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nq10  0.011974  0.000000  0.004947  0.000000  0.000000  0.000000  0.000000   \nq12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n\n         d008      d009      d010  ...      d322      d323      d324  \\\nq01  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nq02  0.000000  0.000000  0.008788  ...  0.000000  0.008176  0.007667   \nq03  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nq04  0.006181  0.011784  0.057539  ...  0.000000  0.000000  0.004156   \nq06  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nq07  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nq08  0.000000  0.000000  0.000000  ...  0.000000  0.008476  0.000000   \nq09  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nq10  0.000000  0.008843  0.011303  ...  0.011416  0.012240  0.004943   \nq12  0.000000  0.000000  0.022922  ...  0.000000  0.000000  0.000000   \n\n         d325  d326      d327      d328      d329      d330      d331  \nq01  0.000000   0.0  0.000000  0.000000  0.024966  0.000000  0.000000  \nq02  0.000000   0.0  0.012593  0.005852  0.000000  0.006138  0.000000  \nq03  0.000000   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \nq04  0.000000   0.0  0.011717  0.000000  0.000000  0.029640  0.005930  \nq06  0.000000   0.0  0.000000  0.000000  0.210759  0.000000  0.000000  \nq07  0.000000   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \nq08  0.000000   0.0  0.000000  0.000000  0.012359  0.009073  0.000000  \nq09  0.000000   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \nq10  0.009777   0.0  0.014573  0.008529  0.012183  0.016901  0.007052  \nq12  0.000000   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n\n[10 rows x 331 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d001</th>\n      <th>d002</th>\n      <th>d003</th>\n      <th>d004</th>\n      <th>d005</th>\n      <th>d006</th>\n      <th>d007</th>\n      <th>d008</th>\n      <th>d009</th>\n      <th>d010</th>\n      <th>...</th>\n      <th>d322</th>\n      <th>d323</th>\n      <th>d324</th>\n      <th>d325</th>\n      <th>d326</th>\n      <th>d327</th>\n      <th>d328</th>\n      <th>d329</th>\n      <th>d330</th>\n      <th>d331</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>q01</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.022011</td>\n      <td>0.000000</td>\n      <td>0.038817</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.024966</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q02</th>\n      <td>0.008216</td>\n      <td>0.038387</td>\n      <td>0.005380</td>\n      <td>0.006699</td>\n      <td>0.010479</td>\n      <td>0.000000</td>\n      <td>0.017204</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.008788</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.008176</td>\n      <td>0.007667</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.012593</td>\n      <td>0.005852</td>\n      <td>0.000000</td>\n      <td>0.006138</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q03</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q04</th>\n      <td>0.019206</td>\n      <td>0.000000</td>\n      <td>0.004159</td>\n      <td>0.000000</td>\n      <td>0.022856</td>\n      <td>0.013380</td>\n      <td>0.006650</td>\n      <td>0.006181</td>\n      <td>0.011784</td>\n      <td>0.057539</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004156</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.011717</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.029640</td>\n      <td>0.005930</td>\n    </tr>\n    <tr>\n      <th>q06</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.018593</td>\n      <td>0.033279</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.210759</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q07</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.134515</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q08</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.072756</td>\n      <td>0.011019</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.008476</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012359</td>\n      <td>0.009073</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q09</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>q10</th>\n      <td>0.011974</td>\n      <td>0.000000</td>\n      <td>0.004947</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.008843</td>\n      <td>0.011303</td>\n      <td>...</td>\n      <td>0.011416</td>\n      <td>0.012240</td>\n      <td>0.004943</td>\n      <td>0.009777</td>\n      <td>0.0</td>\n      <td>0.014573</td>\n      <td>0.008529</td>\n      <td>0.012183</td>\n      <td>0.016901</td>\n      <td>0.007052</td>\n    </tr>\n    <tr>\n      <th>q12</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.022922</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 331 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve ordered docs per query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d254', 'd016', 'd153', 'd209', 'd186']\n"
     ]
    }
   ],
   "source": [
    "def retrieve_docs(similarity_matrix, query_index):\n",
    "    \"\"\"\n",
    "    Para cuada query se aplica el método de cosine similarity y se devuelve una lista ordenada con ids de docs\n",
    "    relevantes para esa query ordenados por el número del id.\n",
    "    :param similarity_matrix: Cosine similarity matrix calculada previamente\n",
    "    :param query_index: Lista con los ids de las queries. i.e. ['q01', 'q02', ...]\n",
    "    :return: El diccionario con pares key, value. Key = id del query. Value lista con resultados relevantes de docs\n",
    "    :según el cosine similarity.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    results_with_scores = {}\n",
    "    for query in query_index:\n",
    "        order = similarity_matrix.loc[[query]].sort_values(by=query, axis=1, ascending=False, inplace=False)\n",
    "        relevant = order.loc[:, (order != 0 ).any(axis=0)]\n",
    "        results[query] = relevant.columns.values.tolist()\n",
    "        results_with_scores[query] = relevant.to_dict(orient='list')\n",
    "    return results, results_with_scores\n",
    "\n",
    "results, results_with_scores = retrieve_docs(similarity_matrix, queries_index)\n",
    "print(results['q01'][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo escrito\n"
     ]
    }
   ],
   "source": [
    "def writeScoreFile(RRDV):\n",
    "    \"\"\"\n",
    "    Writes the RRI-queries_results.tsv that contains the score of each query\n",
    "    :param RRDV: Dictionary with the scores, {'qYY': {'dXXX': score1, 'dXXX': score2, ..., 'dXXX': score3 } }\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(os.getcwd(), 'docs/answer_files/RRDV-queries_results.tsv')\n",
    "    with open(file_path, 'wt') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        for query_id, scores in RRDV.items():\n",
    "            scores_list = \"\"\n",
    "            for doc, score in scores.items():\n",
    "                scores_list+= doc +\":\"+str(round(score[0],4))+\",\"\n",
    "            tsv_writer.writerow([query_id,scores_list[:-1]])\n",
    "\n",
    "\n",
    "writeScoreFile(results_with_scores)\n",
    "print(\"Archivo escrito\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d016': '5', 'd186': '4', 'd254': '5'}\n"
     ]
    }
   ],
   "source": [
    "def read_judgemnts_file():\n",
    "    \"\"\"\n",
    "    Lee el archivo de relevancia de los jueces\n",
    "    :return: Diccionario con pares key: value, donde el key es el id de cada query y el value\n",
    "    es otro doccionario con las ids de los docs relevantes para esa query ordenados en forma creciente.\n",
    "    \"\"\"\n",
    "    document_path = os.path.join(os.getcwd(), 'docs/relevance-judgments.tsv')\n",
    "    tsv_file = open(document_path)\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    relevance = {}\n",
    "    for row in read_tsv:\n",
    "        documents = row[1].split(',')\n",
    "        query_relevance = {pair.split(':')[0] : pair.split(':')[1] for pair in documents }\n",
    "        query_relevance = dict(sorted(query_relevance.items(), key=lambda item: item[0]))\n",
    "        relevance[row[0]] = query_relevance\n",
    "    return relevance\n",
    "\n",
    "\n",
    "relevance = read_judgemnts_file()\n",
    "print(relevance['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1]\n",
      "[5, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "def make_binary_result(results, relevant_res):\n",
    "    \"\"\"\n",
    "    Este método toma los resultados crudos obtenidos para las queries (Para cada query la lista de documentos ordenaos\n",
    "    por relevancia), devuelve 3 representaciones de estos resultados. La primera es la representacion binaria at K.\n",
    "    Que es del mismo tamaño que el número de documentos relevantes. La segunda es esta misma lista pero con la escala\n",
    "    dada por el archivo de evaluación. La tercera está destinada al cálculo del MAP, tiene la representación binaria\n",
    "    hasta que salgan todos los documentos relevantes o simplemente de todos los documentos, además en su segundo\n",
    "    componente tiene el número de documentos relevantes que deberían salir en los resultados según el archivo de\n",
    "    evaluación.\n",
    "    :param results: Diccionario con resultados crudos de cada query. Ej: {'q01': ['d254', 'd016', 'd153', ...]}\n",
    "    :param relevant_res: Las 3 representaciones antes mencionadas\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bin_relevant = {}\n",
    "    rel_scale_repr = {}\n",
    "    map_relevant_docs = {}\n",
    "    for query, relevant_docs in relevant_res.items():\n",
    "        bin_repr = []\n",
    "        scaled_repr = []\n",
    "        map_repr = []\n",
    "        M = len(relevant_docs)\n",
    "        for doc_id, rel_scale in relevant_docs.items():\n",
    "            bin = 1 if doc_id in results[query][:M] else 0\n",
    "            bin_repr.append(bin)\n",
    "            scaled_repr.append(bin * int(rel_scale))\n",
    "        i = 0\n",
    "        for doc_id in results[query]:\n",
    "            if i < M:\n",
    "                map_bin = 1 if doc_id in relevant_res[query] else 0\n",
    "                i += map_bin\n",
    "                map_repr.append(map_bin)\n",
    "        bin_relevant[query] = bin_repr\n",
    "        rel_scale_repr[query] = scaled_repr\n",
    "        map_relevant_docs[query] = [map_repr, M]\n",
    "    return bin_relevant, rel_scale_repr, map_relevant_docs\n",
    "\n",
    "bin_results, scaled_results, map_relevant_docs = make_binary_result(results, relevance)\n",
    "print(bin_results['q01'])\n",
    "print(scaled_results['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 5 documentos devueltos como relevantes para q01: \n",
      " ['d254', 'd016', 'd153', 'd209', 'd186']\n",
      "Documentos relevantes para q01 según jueces: \n",
      " {'d016': '5', 'd186': '4', 'd254': '5'}\n",
      "Representación binaria de q01, hasta el último doc relevante: \n",
      " [[1, 1, 0, 0, 1], 3]\n"
     ]
    }
   ],
   "source": [
    "print('Primeros 5 documentos devueltos como relevantes para q01: \\n', results['q01'][:5])\n",
    "print('Documentos relevantes para q01 según jueces: \\n' , relevance['q01'])\n",
    "print('Representación binaria de q01, hasta el último doc relevante: \\n' ,map_relevant_docs['q01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of IR metrics functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5961904761904762"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_at_k(relevance: list, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    l = np.array(relevance[:k]).sum()/k\n",
    "    return l\n",
    "\n",
    "def recall_at_k(relevance: list, nr_relevant: int, k: int):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    l = np.array(relevance[:k]).sum()/nr_relevant\n",
    "    return l\n",
    "\n",
    "def average_precision(relevance):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    length = len(relevance[0])\n",
    "    sum = 0\n",
    "    for i in range(length):\n",
    "        if relevance[0][i]:\n",
    "            sum += precision_at_k(relevance[0], i+1)\n",
    "    if np.array(relevance[0]).sum()==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum / relevance[1]\n",
    "\n",
    "def mean_avg_precision(l):\n",
    "    \"\"\"\n",
    "    DocString\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    mean = np.array([ average_precision(lista) for lista in l]).mean()\n",
    "    return mean\n",
    "\n",
    "mean_avg_precision([[[0, 1, 0, 1, 1, 1, 1], 5]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7424602308163405"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dcg_at_k(relevance, k: int):\n",
    "    \"\"\"\n",
    "    Calcula el DCG at K de un vector binario representando los resultados relevantes para una query.\n",
    "    :param relevance: Vector binario\n",
    "    :return: DCG at K de nuestra query\n",
    "    \"\"\"\n",
    "\n",
    "    sum = 0\n",
    "    i =  0\n",
    "    for rel_i in relevance[: k]:\n",
    "        i+= 1\n",
    "        sum += rel_i/np.log2(max(i, 2))\n",
    "\n",
    "    return sum\n",
    "\n",
    "dcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)\n",
    "\n",
    "def ndcg_at_k(relevance, k):\n",
    "    \"\"\"\n",
    "    Calcula el ndcg at k de un vector binario\n",
    "    :return: NDCG at K.\n",
    "    \"\"\"\n",
    "    rel_sorted = sorted(relevance, reverse=True)\n",
    "    max = dcg_at_k(rel_sorted, k)\n",
    "    real = dcg_at_k(relevance, k)\n",
    "\n",
    "    return real/ max\n",
    "\n",
    "\n",
    "ndcg_at_k([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(recall_at_k(bin_results['q01'], 3, 3))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Evaluation Metrics for each query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-d58954e71302>:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return real/ max\n"
     ]
    },
    {
     "data": {
      "text/plain": "             q01       q02      q03       q04      q06   q07      q08  \\\nP@M     0.666667  0.454545  1.00000  0.857143  1.00000  0.25  0.75000   \nR@M     0.666667  0.454545  1.00000  0.857143  1.00000  0.25  0.75000   \nNDCG@M  0.815465  0.536073  0.87422  0.933486  0.86393  1.00  0.84214   \n\n             q09       q10       q12  ...  q34       q36       q37       q38  \\\nP@M     0.833333  0.500000  0.750000  ...  1.0  0.400000  0.333333  0.125000   \nR@M     0.833333  0.500000  0.750000  ...  1.0  0.400000  0.333333  0.125000   \nNDCG@M  0.880115  0.642423  0.797833  ...  1.0  0.607282  1.000000  0.386853   \n\n             q40       q41       q42       q44       q45       q46  \nP@M     0.666667  0.857143  0.666667  0.700000  0.750000  0.500000  \nR@M     0.666667  0.857143  0.666667  0.700000  0.750000  0.500000  \nNDCG@M  0.915922  0.903509  0.894551  0.823107  0.970942  0.558244  \n\n[3 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q01</th>\n      <th>q02</th>\n      <th>q03</th>\n      <th>q04</th>\n      <th>q06</th>\n      <th>q07</th>\n      <th>q08</th>\n      <th>q09</th>\n      <th>q10</th>\n      <th>q12</th>\n      <th>...</th>\n      <th>q34</th>\n      <th>q36</th>\n      <th>q37</th>\n      <th>q38</th>\n      <th>q40</th>\n      <th>q41</th>\n      <th>q42</th>\n      <th>q44</th>\n      <th>q45</th>\n      <th>q46</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>P@M</th>\n      <td>0.666667</td>\n      <td>0.454545</td>\n      <td>1.00000</td>\n      <td>0.857143</td>\n      <td>1.00000</td>\n      <td>0.25</td>\n      <td>0.75000</td>\n      <td>0.833333</td>\n      <td>0.500000</td>\n      <td>0.750000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.400000</td>\n      <td>0.333333</td>\n      <td>0.125000</td>\n      <td>0.666667</td>\n      <td>0.857143</td>\n      <td>0.666667</td>\n      <td>0.700000</td>\n      <td>0.750000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>R@M</th>\n      <td>0.666667</td>\n      <td>0.454545</td>\n      <td>1.00000</td>\n      <td>0.857143</td>\n      <td>1.00000</td>\n      <td>0.25</td>\n      <td>0.75000</td>\n      <td>0.833333</td>\n      <td>0.500000</td>\n      <td>0.750000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.400000</td>\n      <td>0.333333</td>\n      <td>0.125000</td>\n      <td>0.666667</td>\n      <td>0.857143</td>\n      <td>0.666667</td>\n      <td>0.700000</td>\n      <td>0.750000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>NDCG@M</th>\n      <td>0.815465</td>\n      <td>0.536073</td>\n      <td>0.87422</td>\n      <td>0.933486</td>\n      <td>0.86393</td>\n      <td>1.00</td>\n      <td>0.84214</td>\n      <td>0.880115</td>\n      <td>0.642423</td>\n      <td>0.797833</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.607282</td>\n      <td>1.000000</td>\n      <td>0.386853</td>\n      <td>0.915922</td>\n      <td>0.903509</td>\n      <td>0.894551</td>\n      <td>0.823107</td>\n      <td>0.970942</td>\n      <td>0.558244</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 35 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation_metric(bin_queries, query_index, scaled_results):\n",
    "    \"\"\"\n",
    "\n",
    "    :param bin_queries: Diccionario con valores {query Key: vector}, donde el vector corresponde a una lista\n",
    "    con la representación binaria de un de los resultados encontrados para una query con relación a los dados\n",
    "    en el archivo de evaluación. Ej, para q01, los relevantes son: d186,d254,d016. El RRDV devuelve d254, d016,\n",
    "    d153. Por ende, la representación binaria de q01, en el orden del archivo de evaluación es: [0, 1, 1]\n",
    "    :param query_index: Lista con los ids de las queries. ['qo1', 'qo2', ...]\n",
    "    :param scaled_results: Representación escalada de los resultados de las queries usando la escala dada en el\n",
    "    archivo de evaluación. Ej, q01 pasa de [0, 1, 1] a [0, 5, 5]\n",
    "    :return: Un dataframe con el cálculo del P@M, r@M y NDCG@M para cada query\n",
    "    \"\"\"\n",
    "    COLUMNS = ['P@M', 'R@M', 'NDCG@M']\n",
    "    records = []\n",
    "    for query, bin_vec in bin_queries.items():\n",
    "        scaled = scaled_results[query]\n",
    "        M = len(bin_vec)\n",
    "        pm = precision_at_k(bin_vec, M)\n",
    "        rm = recall_at_k(bin_vec, M, M)\n",
    "        ndcg = ndcg_at_k(scaled, M)\n",
    "        records.append([pm, rm, ndcg])\n",
    "        \n",
    "    return pd.DataFrame.from_records(records, index=query_index, columns=COLUMNS)\n",
    "        \n",
    "metrics = evaluation_metric(bin_results, queries_index, scaled_results)\n",
    "metrics.transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP resultante de todas las queries: 0.6503449127718149\n"
     ]
    }
   ],
   "source": [
    "def overall_map(map_relevant_docs):\n",
    "    \"\"\"\n",
    "    Función que calcula el MAP de los resultados de las queries.\n",
    "    :param map_relevant_docs: Vector binario de las queries asegurandose de que aparezcan todos los documentos relevantes\n",
    "    :return: El Mean average precision de los resultados de las queries.\n",
    "    \"\"\"\n",
    "    matrix = [vector for key, vector in map_relevant_docs.items() ]\n",
    "    return mean_avg_precision(matrix)\n",
    "\n",
    "print(f'MAP resultante de todas las queries: {overall_map(map_relevant_docs)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}