{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Punto 4 - Italiano\n",
    "Context Q&A system about COVID in a general setting. Type: Transformer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "import string, re\n",
    "import torch\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "## Configuraciones generales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "do_fine_tuning_locally = False\n",
    "\n",
    "'''\n",
    "Se deben crear los directorios en caso de no existir\n",
    "'''\n",
    "\n",
    "lang = \"italian\"\n",
    "\n",
    "#HPC calculated files\n",
    "input_encodings_path = f\"data_hpc/{lang}/train_encoding_{lang}.pkl\"\n",
    "input_model_path = f\"data_hpc/{lang}/input_model_{lang}.pkl\"\n",
    "output_model_path = f\"data_hpc/{lang}/model_post_tunning_{lang}.pkl\"\n",
    "\n",
    "#Models path\n",
    "model_folder_path = f'models/{lang}/qna_english_custom'\n",
    "\n",
    "#Dataset\n",
    "dataset_path = f\"qna_database/{lang}/{lang}.json\"\n",
    "\n",
    "#BERT model name\n",
    "modelname = 'mrm8488/bert-italian-finedtuned-squadv1-it-alfa'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proceso de carga del Dataset traducido"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextos 940, Preguntas 940, Respuestas 940\n"
     ]
    }
   ],
   "source": [
    "contexts = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(dataset_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        doc = json.loads(line)\n",
    "        #print(doc)\n",
    "        #print(doc[\"context\"])\n",
    "        contexts.append(doc[\"context\"])\n",
    "        answers.append(doc[\"answer\"])\n",
    "        questions.append(doc[\"question\"])\n",
    "\n",
    "print(f\"Contextos {str(len(contexts))}, Preguntas {str(len(questions))}, Respuestas {str(len(answers))}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Separación en training y test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#Versión completa\n",
    "# num_docs = len(contexts)\n",
    "# ochenta = int(num_docs*0.8)\n",
    "#\n",
    "# train_contexts = contexts[0:ochenta]\n",
    "# train_questions = questions[0:ochenta]\n",
    "# train_answers = answers[0:ochenta]\n",
    "# test_contexts = contexts[ochenta+1:num_docs]\n",
    "# test_questions = questions[ochenta+1:num_docs]\n",
    "# test_answers = answers[ochenta+1:num_docs]\n",
    "\n",
    "#Verisón corta\n",
    "num_docs = 100\n",
    "ochenta = int(num_docs*0.8)\n",
    "\n",
    "train_contexts = contexts[0:ochenta]\n",
    "train_questions = questions[0:ochenta]\n",
    "train_answers = answers[0:ochenta]\n",
    "test_contexts = contexts[ochenta+1:num_docs]\n",
    "test_questions = questions[ochenta+1:num_docs]\n",
    "test_answers = answers[ochenta+1:num_docs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(train_contexts))\n",
    "print(len(test_contexts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aproximación 1 - Already Fine-Tuned BERT transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained(modelname)\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creación del pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pruebas Genéricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.4643324315547943,\n 'start': 605,\n 'end': 621,\n 'answer': 'variante inglese'}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"L’incidenza sull’intero territorio nazionale continua a diminuire e ha raggiunto valori che, attraverso l’attivazione di intense attività di tracciamento sistematico, possono consentire una gestione basata sul contenimento ovvero sull’identificazione dei casi e sul tracciamento dei loro contatti. La pressione sui servizi ospedalieri si conferma al di sotto della soglia critica in tutte le Regioni/PA e la stima dell’indice di trasmissibilità Rt medio calcolato sui casi sintomatici è stabilmente al di sotto della soglia epidemica.La prevalente circolazione in Italia della variante B.1.1.7 (nota come variante inglese) e la presenza di altre varianti che possono eludere parzialmente la risposta immunitaria, richiede tuttavia di continuare a monitorare con attenzione la situazione e mantenere cautela e gradualità nella gestione dell’epidemia.\"\n",
    "\n",
    "nlp({\n",
    "    'question': \"¿Cual'è la variante prevalente?\",\n",
    "    'context': context\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.9873538613319397,\n 'start': 168,\n 'end': 181,\n 'answer': '12 marzo 2021'}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Il Piano, elaborato da Ministero della Salute, Commissario Straordinario per l’Emergenza, Istituto Superiore di Sanità, Agenas e Aifa, è stato adottato con Decreto del 12 marzo 2021. Il 13 marzo 2021 è stato diffuso il Piano vaccinale del Commissario straordinario per l’esecuzione della campagna vaccinale nazionale. Elaborato in armonia con il Piano strategico nazionale del Ministero della Salute, fissa le linee operative per completare al più presto la campagna vaccinale.\"\n",
    "\n",
    "nlp({\n",
    "    'question': \"¿Quando si è adottato il Piano?\",\n",
    "    'context': context\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_prediction(qid, questions, contexts):\n",
    "    specific_question = questions[qid]\n",
    "    specific_context = contexts[qid]\n",
    "\n",
    "    answer = nlp({\n",
    "    'question': specific_question,\n",
    "    'context': specific_context\n",
    "    })\n",
    "    #print(answer)\n",
    "    return answer[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Métricas para Q&A\n",
    "#### F1 Score y Exact Match"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#Adaptado de: Evaluating QA: Metrics, Predictions, and the Null Response\n",
    "#https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "\n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "\n",
    "    return 2 * (prec * rec) / (prec + rec)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "### Dataset COVID-QA\n",
    "COVID-QA es un conjunto de datos de respuestas a preguntas que consta de 2,019 pares de preguntas / respuestas anotados por expertos biomédicos voluntarios en artículos científicos relacionados con COVID-19. Un total de 147 artículos científicos del conjunto de datos CORD-19 fueron anotados por 15 expertos.\n",
    "\n",
    "Tomado de: https://huggingface.co/datasets/covid_qa_deepset\n",
    "Traducido automaticamente al español"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# El formato del dataset tenía listas en vez de string e ints\n",
    "\n",
    "def ajustar_answers(answers):\n",
    "    for answer in answers:\n",
    "         answer['text'] = answer['text'][0]\n",
    "         answer['answer_start'] = int(answer['answer_start'][0])\n",
    "    return answers\n",
    "\n",
    "train_answers = ajustar_answers(train_answers)\n",
    "test_answers = ajustar_answers(test_answers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluación Aproximación 1\n",
    "Modelo ya Fine-Tuned para Q&A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Prueba Unitaria:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Quale invenzione tecnologica ha prodotto anticorpi che sono cloni di un'unica cellula madre?\n",
      "Prediction: ibridomi\n",
      "Answer: negli anni '70 con lo sviluppo della tecnologia degli ibridomi per produrre anticorpi monoclonali\n",
      "EM: 0 \t F1: 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "prediction = get_prediction(n, questions=test_questions, contexts=test_contexts)\n",
    "#print(prediction)\n",
    "answer = test_answers[n][\"text\"]\n",
    "#print(answer)\n",
    "\n",
    "em_score = compute_exact_match(prediction, answer)\n",
    "f1_score = compute_f1(prediction, answer)\n",
    "\n",
    "print(f\"Question: {test_questions[n]}\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"EM: {em_score} \\t F1: {f1_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Prueba con todos los datos de test:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def average_metrics(contexts, answers, questions):\n",
    "    if len(contexts)!= len(answers) or len(contexts)!= len(questions):\n",
    "        print(\"Hay un error en el tamaño de los arreglos\")\n",
    "        return\n",
    "    test_size = len(contexts)\n",
    "    em_average = 0\n",
    "    f1_average = 0\n",
    "    for n in range(test_size):\n",
    "        prediction = get_prediction(n, questions, contexts)\n",
    "        answer = answers[n][\"text\"]\n",
    "        em_score = compute_exact_match(prediction, answer)\n",
    "        f1_score = 1 if em_score == 1 else compute_f1(prediction, answer)\n",
    "        em_average += em_score\n",
    "        f1_average += f1_score\n",
    "    em_average_tot = em_average/test_size\n",
    "    f1_average_tot = f1_average/test_size\n",
    "    return em_average_tot, f1_average_tot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "em_average, f1_score = average_metrics(test_contexts, test_answers, test_questions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 0.25972826803851734 \n",
      "Average EM: 0.10526315789473684\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average F1: {f1_score} \\nAverage EM: {em_average}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aproximación 2 - Fine Tunnind with COVID-19 Q&A Questions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aproximación inspirada en\n",
    "https://gist.github.com/jamescalam/55daf50c8da9eb3a7c18de058bc139a3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#Basado en:\n",
    "\n",
    "def add_end_idx(answers, contexts):\n",
    "    count = 0\n",
    "    print(len(answers))\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "            count = count+1\n",
    "        else:\n",
    "            for n in range(4):\n",
    "                problema = True\n",
    "                if gold_text == context[start_idx+n:end_idx+n]:\n",
    "                    # this means the answer is off by 'n' tokens\n",
    "                    answer['answer_start'] = start_idx + n\n",
    "                    answer['answer_end'] = end_idx + n\n",
    "                    #print(\"entra4\")\n",
    "                    count = count+1\n",
    "                    problema = False\n",
    "                    break\n",
    "                if gold_text == context[start_idx-n:end_idx-n]:\n",
    "                    answer['answer_start'] = start_idx - n\n",
    "                    answer['answer_end'] = end_idx - n\n",
    "                    count = count+1\n",
    "                    problema = False\n",
    "                    break\n",
    "            if problema:\n",
    "                print(\"1\",gold_text)\n",
    "                print(\"2\",context[start_idx+n:end_idx+n])\n",
    "    print(count)\n",
    "\n",
    "add_end_idx(train_answers, train_contexts)\n",
    "add_end_idx(test_answers, test_contexts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Nuevamente se importa el modelo\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained(modelname)\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "\n",
    "def add_token_positions(encodings, answers):\n",
    "    # initialize lists to contain the token indices of answer start/end\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        # append start/end token position using char_to_token method\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        # end position cannot be found, char_to_token found space, so shift one token forward\n",
    "        go_back = 1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-go_back)\n",
    "            go_back +=1\n",
    "    # update our encodings object with the new token-based start/end positions\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "# apply function to our data\n",
    "add_token_positions(train_encodings, train_answers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings):\n",
    "            self.encodings = encodings\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "with open(input_encodings_path, \"wb\") as file:\n",
    "    pk.dump(train_dataset, file)\n",
    "\n",
    "with open(input_model_path, \"wb\") as file:\n",
    "    pk.dump(model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_hpc/italian/model_post_tunning_italian.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-44-4dbf65354f9e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     55\u001B[0m             \u001B[0mloop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_postfix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 57\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_model_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     58\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data_hpc/italian/model_post_tunning_italian.pkl'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Fine tune your model locally or excecute it with the HPC\n",
    "'''\n",
    "if do_fine_tuning_locally:\n",
    "\n",
    "    # setup GPU/CPU\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # move model over to detected device\n",
    "    model.to(device)\n",
    "    # activate training mode of model\n",
    "    model.train()\n",
    "    # initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
    "    optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    # initialize data loader for training data\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        # setup loop (we use tqdm for the progress bar)\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for batch in loop:\n",
    "            # initialize calculated gradients (from prev step)\n",
    "            optim.zero_grad()\n",
    "            # pull all the tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            # train model on batch and return outputs (incl. loss)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            start_positions=start_positions,\n",
    "                            end_positions=end_positions)\n",
    "            # extract loss\n",
    "            loss = outputs[0]\n",
    "            # calculate loss for every parameter that needs grad update\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            optim.step()\n",
    "            # print relevant info to progress bar\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "else:\n",
    "    with open(output_model_path, \"rb\") as file:\n",
    "        model = pk.load(file)\n",
    "\n",
    "\n",
    "model.save_pretrained(model_folder_path)\n",
    "tokenizer.save_pretrained(model_folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = BertForQuestionAnswering.from_pretrained(model_folder_path)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creación del pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = pipeline('question-answering', model=model2, tokenizer=tokenizer2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pruebas genéricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "context = \"Masks should be used as part of a comprehensive strategy of measures to suppress transmission and save lives; the use of a mask alone is not sufficient to provide an adequate level of protection against COVID-19. If COVID-19 is spreading in your community, stay safe by taking some simple precautions, such as physical distancing, wearing a mask, keeping rooms well ventilated, avoiding crowds, cleaning your hands, and coughing into a bent elbow or tissue. Check local advice where you live and work. Do it all! Make wearing a mask a normal part of being around other people. The appropriate use, storage and cleaning or disposal of masks are essential to make them as effective as possible.\"\n",
    "\n",
    "nlp({\n",
    "    'question': 'What precautions can you take to stay safe?',\n",
    "    'context': context\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Taken from: https://www.who.int/emergencies/diseases/novel-coronavirus-2019/covid-19-vaccines/advice\n",
    "\n",
    "context = \"The world is in the midst of a COVID-19 pandemic. As WHO and partners work together on the response -- tracking the pandemic, advising on critical interventions, distributing vital medical supplies to those in need--- they are racing to develop and deploy safe and effective vaccines. Vaccines save millions of lives each year. Vaccines work by training and preparing the body’s natural defences – the immune system – to recognize and fight off the viruses and bacteria they target. After vaccination, if the body is later exposed to those disease-causing germs, the body is immediately ready to destroy them, preventing illness. There are several safe and effective vaccines that prevent people from getting seriously ill or dying from COVID-19. This is one part of managing COVID-19, in addition to the main preventive measures of staying at least 1 metre away from others, covering a cough or sneeze in your elbow, frequently cleaning your hands, wearing a mask and avoiding poorly ventilated rooms or opening a window.\"\n",
    "\n",
    "nlp({\n",
    "    'question': 'What happens after vaccination?',\n",
    "    'context': context\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validación Aproximación 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " - Prueba de ejemplo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 3\n",
    "prediction = get_prediction(n, questions=test_questions, contexts=test_contexts)\n",
    "#print(prediction)\n",
    "answer = test_answers[n][\"text\"]\n",
    "#print(answer)\n",
    "\n",
    "em_score = compute_exact_match(prediction, answer)\n",
    "f1_score = 1 if em_score == 1 else compute_f1(prediction, answer)\n",
    "\n",
    "print(f\"Question: {test_questions[n]}\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"EM: {em_score} \\t F1: {f1_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def average_metrics(contexts, answers, questions):\n",
    "    if len(contexts)!= len(answers) or len(contexts)!= len(questions):\n",
    "        print(\"Hay un error en el tamaño de los arreglos\")\n",
    "        return\n",
    "    test_size = len(contexts)\n",
    "    em_average = 0\n",
    "    f1_average = 0\n",
    "    for n in range(test_size):\n",
    "        #print(n)\n",
    "        prediction = get_prediction(n, questions, contexts)\n",
    "        #print(\"Prediction: \",prediction)\n",
    "        answer = answers[n][\"text\"]\n",
    "        #print(\"Answer: \",answer)\n",
    "        em_score = compute_exact_match(prediction, answer)\n",
    "        f1_score = 1 if em_score == 1 else compute_f1(prediction, answer)\n",
    "        #print(f\"EM: {em_score} \\t F1: {f1_score}\")\n",
    "        em_average += em_score\n",
    "        f1_average += f1_score\n",
    "    em_average_tot = em_average/test_size\n",
    "    f1_average_tot = f1_average/test_size\n",
    "    return em_average_tot, f1_average_tot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "em_average, f1_score = average_metrics( test_contexts, test_answers, test_questions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Average F1: {f1_score} \\nAverage EM: {em_average}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}